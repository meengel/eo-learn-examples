{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63735c1a",
   "metadata": {},
   "source": [
    "# GEM ML Framework Demonstrator - Deforestation Detection\n",
    "In these notebooks, we will get a feeling of how the GEM ML framework can be used for the segmentation of deforested areas using Sentinel-2 imagery as input and the [TMF dataset](https://forobs.jrc.ec.europa.eu/TMF/) as a reference.\n",
    "The idea is to use a neural network (NN) model for the analysis.\n",
    "Thanks to the flexibility of the GEM ML framework, the model used can be replaced by changing the configuration only.\n",
    "We will have a look at the following notebooks separately:\n",
    "- 00_Configuration\n",
    "- 01_DataAcquisition\n",
    "- 02_DataNormalization\n",
    "- 03_TrainingValidationTesting\n",
    "- 04_Inference_Clouds\n",
    "- 04_Inference_Timeseries\n",
    "\n",
    "by Michael Engel (m.engel@tum.de) and Joana Reuss (joana.reuss@tum.de)\n",
    "\n",
    "-----------------------------------------------------------------------------------\n",
    "\n",
    "# Configuration\n",
    "Here, we define the configuration of our segmentation pipeline.\n",
    "Let's import all libraries we need for that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64be303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.ConfigME import Config\n",
    "import os\n",
    "import platform\n",
    "import datetime as dt\n",
    "from sentinelhub import SHConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0c8e6e",
   "metadata": {},
   "source": [
    "Now, we can initialize the configuration file with a proper name and identifiers for storing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb420b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    name = 'GEM-ML-Framework_DeforestationDetection', # name of the project\n",
    "    savename = 'DeforestationDetectionRun', # basic name to store stuff\n",
    "    savename_config = \"config.dill\" # name of configuration file\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b626e5d8",
   "metadata": {},
   "source": [
    "Our pipeline is defined by 4 notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5702ae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.file_DataAcquisition = \"01_DataAcquisition.ipynb\"\n",
    "config.file_DataNormalization = \"02_DataNormalization.ipynb\"\n",
    "config.file_TrainingValidationTesting = \"03_TrainingValidationTesting.ipynb\"\n",
    "config.file_showcase = \"04_Inference_Clouds.ipynb\"\n",
    "config.file_showcase2 = \"04_Inference_Timeseries.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd46ac78",
   "metadata": {},
   "source": [
    "Let's define the directories we are working with, i.e. in which directories to store our `EOPatches` and results.\n",
    "By that, we ensure that everything is only defined once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abb9fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% folder where data necessary for running the notebook is stored such as the geojson of the AOI\n",
    "config.dir_inputs = os.path.join(os.getcwd(),\"inputs\")\n",
    "config.dir_extra = os.path.join(os.getcwd(),\"extra\")\n",
    "\n",
    "#%% results\n",
    "config.basedir = os.path.join(os.getcwd(),config[\"savename\"])\n",
    "config.dir_results = os.path.join(config[\"basedir\"], \"results\")\n",
    "config.dir_checkpoints = os.path.join(config[\"dir_results\"], \"checkpoints\")\n",
    "config.dir_tensorboard = os.path.join(config[\"dir_results\"], \"tensorboard\")\n",
    "config.dir_imgs = os.path.join(config[\"dir_results\"], \"imgs\")\n",
    "config.dir_imgs_validation = os.path.join(config[\"dir_imgs\"],\"PredictionValidation\")\n",
    "\n",
    "#%% locations for collected data\n",
    "config.dir_data = os.path.join(config[\"basedir\"],\"data\")\n",
    "config.dir_train = os.path.join(config[\"dir_data\"], \"train\")\n",
    "config.dir_validation = os.path.join(config[\"dir_data\"], \"validation\")\n",
    "config.dir_test = os.path.join(config[\"dir_data\"], \"test\")\n",
    "config.dir_showcase = os.path.join(config[\"dir_data\"], \"showcase\")\n",
    "\n",
    "#%% locations for GeoTiffs\n",
    "config.dir_tiffs = os.path.join(config[\"dir_results\"],\"tiffs\")\n",
    "config.dir_tiffs_train = os.path.join(config[\"dir_tiffs\"],\"train\")\n",
    "config.dir_tiffs_validation = os.path.join(config[\"dir_tiffs\"],\"validation\")\n",
    "config.dir_tiffs_test = os.path.join(config[\"dir_tiffs\"],\"test\")\n",
    "config.dir_tiffs_showcase = os.path.join(config[\"dir_tiffs\"],\"showcase\")\n",
    "\n",
    "#%% caching\n",
    "config.dir_cache = os.path.join(os.getcwd(),\"cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6605c51e",
   "metadata": {},
   "source": [
    "Since we want to store some results of our showcase, we have to define some savenames for those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4283f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.savename_showcase_tiff = config[\"savename\"]+\"_showcase.tif\"\n",
    "config.savename_showcase_tiff_reproject = config[\"savename\"]+\"_showcase_reprojected.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75723287",
   "metadata": {},
   "source": [
    "Let's load our **credentials** for Sentinel Hub from storage.\n",
    "If you should not have stored your credentials on disk yet, you should have a lookt at this [notebook](https://gitlab.lrz.de/mkoerner/projects-and-proposals/projects/2020_GEM/howto-eo-learn/-/blob/main/1_Configuration/tutorial1_config.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b019bfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Sentinel Hub credentials\n",
    "config.SHconfig = SHConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb988f9",
   "metadata": {},
   "source": [
    "Here we define the parameters like the resolution and pixelwidth of our patches which will be fed to our model later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21b8485",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.patchpixelwidth = 256\n",
    "config.resolution = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371f690a",
   "metadata": {},
   "source": [
    "For the sake of completeness, we enable the user to apply some buffer to the AOIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8db43f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.AOIbuffer = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61de00f6",
   "metadata": {},
   "source": [
    "Further, we set some values for the desired maximum cloud coverage of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7275df",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.maxcc = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1221d3c4",
   "metadata": {},
   "source": [
    "Our reference is given by the [TMF dataset](https://forobs.jrc.ec.europa.eu/TMF/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592fcf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.path_reference = os.path.join(config[\"dir_inputs\"],\"JRC_TMF_AnnualChange_v2_2021_SAM_ID30_N0_W60.tif\").replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9624fa",
   "metadata": {},
   "source": [
    "The six original classes are contracted to four."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeceb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.class_water = 1\n",
    "config.class_forest = 2\n",
    "config.class_deforestation = 3\n",
    "config.class_indefinite = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a4d72f",
   "metadata": {},
   "source": [
    "We want to map our reference data to that simpler scheme.\n",
    "We combine deforested and TODO\n",
    "Accordingly, we need a labelmapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3748e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.labelmapping = {\n",
    "    1:config[\"class_forest\"],\n",
    "    2:config[\"class_deforestation\"],\n",
    "    3:config[\"class_deforestation\"],\n",
    "    4:config[\"class_forest\"],\n",
    "    5:config[\"class_water\"],\n",
    "    6:config[\"class_indefinite\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f88438",
   "metadata": {},
   "source": [
    "Further, we would like to incorporate the cloud cover in our reference.\n",
    "Accordingly, we define the desired class value for clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66b24ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.class_clouds = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2f5cb1",
   "metadata": {},
   "source": [
    "In a next step, we define our areas of interest - both spatially and temporally.\n",
    "Note, that our desired time interval for the classic ML pipeline (training, validation and testing) consists out of an integer and a date.\n",
    "That will be used for getting the first observation before or at our end-date meeting our requirements, e.g. our maximum allowed cloud coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d168aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.AOI_train = os.path.join(config[\"dir_inputs\"],\"AOI_train.geojson\")\n",
    "config.start_train = 1\n",
    "config.end_train = dt.datetime(year=2021,month=12,day=31,hour=23,minute=59,second=59)\n",
    "config.checktimedelta = dt.timedelta(days=365)\n",
    "\n",
    "config.AOI_validation = os.path.join(config[\"dir_inputs\"],\"AOI_validation.geojson\")\n",
    "config.start_validation = config[\"start_train\"]\n",
    "config.end_validation = config[\"end_train\"]\n",
    "\n",
    "config.AOI_test = os.path.join(config[\"dir_inputs\"],\"AOI_test.geojson\")\n",
    "config.start_test = config[\"start_train\"]\n",
    "config.end_test = config[\"end_train\"]\n",
    "\n",
    "config.AOI_showcase = os.path.join(config[\"dir_inputs\"],\"AOI_showcase.geojson\")\n",
    "config.start_showcase = dt.datetime(year=2022,month=10,day=1)\n",
    "config.end_showcase = dt.datetime(year=2020,month=10,day=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcbb03c",
   "metadata": {},
   "source": [
    "As we want to use both CPU and GPU, we have to define the number of threads and device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d2aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.threads = 1 if platform.system()==\"Windows\" else 5\n",
    "config.device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0e8f73",
   "metadata": {},
   "source": [
    "In the following, we define some general ML parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05ffde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.n_epochs = 128\n",
    "config.num_classes = 4\n",
    "config.batch_size = 8\n",
    "config.max_batch_size = 3\n",
    "config.checkpoint_bestloss = True\n",
    "config.checkpoint_bestmetric = True\n",
    "config.checkpoint_freq = 8\n",
    "config.eval_freq = 2\n",
    "config.seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb7ad9",
   "metadata": {},
   "source": [
    "We want to use the DeepLabV3Plus architecture as provided by [Pavel Yakubovskiy](https://segmentation-modelspytorch.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834077d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.module_model = \"segmentation_models_pytorch.DeepLabV3Plus\"\n",
    "config.kwargs_model = {\n",
    "    \"encoder_name\":\"resnet34\", # think of changing this default value!\n",
    "    \"encoder_depth\":5,\n",
    "    \"encoder_weights\":\"imagenet\", # think of changing this default value!\n",
    "    \"encoder_output_stride\":16, # think of changing this default value!\n",
    "    \"decoder_channels\":256, # think of changing this default value!\n",
    "    \"decoder_atrous_rates\":(12, 24, 36), # think of changing this default value!\n",
    "    \"in_channels\":6,\n",
    "    \"classes\":config[\"num_classes\"],\n",
    "    \"activation\":None, # think of changing this default value!\n",
    "    \"upsampling\":4, # think of changing this default value!\n",
    "    \"aux_params\":None, # think of changing this default value!\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8723295",
   "metadata": {},
   "source": [
    "Of course, we want to store our trained model to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c055adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model_savename = config[\"savename\"]\n",
    "config.model_savename_bestloss = config[\"model_savename\"]+\"_bestloss\"\n",
    "config.model_savename_bestmetric = config[\"model_savename\"]+\"_bestmetric\"\n",
    "config.model_savename_inference = config[\"savename\"]+\"_inference\"\n",
    "config.model_savename_inference_bestloss = config[\"model_savename_inference\"]+\"_bestloss\"\n",
    "config.model_savename_inference_bestmetric = config[\"model_savename_inference\"]+\"_bestmetric\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0a7c15",
   "metadata": {},
   "source": [
    "Here, we will use the [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) as a classic.\n",
    "We will not apply reduction since we would like to apply our mask manually in the training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e195b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.module_loss = \"torch.nn.CrossEntropyLoss\"\n",
    "config.kwargs_loss = {\n",
    "    \"weight\":None, # change\n",
    "    \"size_average\":None,\n",
    "    \"ignore_index\":-100,\n",
    "    \"reduce\":None,\n",
    "    \"reduction\":\"none\",\n",
    "    \"label_smoothing\":0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1605e6",
   "metadata": {},
   "source": [
    "We will use the standard [Adam Optimizer](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cd8ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.module_optimizer = \"torch.optim.Adam\"\n",
    "config.kwargs_optimizer = {\n",
    "    \"lr\":0.007,\n",
    "    \"betas\":(0.9, 0.999),\n",
    "    \"eps\":1e-08,\n",
    "    \"weight_decay\":1e-06,\n",
    "    \"amsgrad\":False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682087f7",
   "metadata": {},
   "source": [
    "For evaluation, we need some metrics.\n",
    "We will use the standard Accuracy and Cohen Kappa.\n",
    "We emphasize that you could use an arbitrary amount of metrics by expanding that list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ea222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.module_metric = [\"../utils/metrics.accuracy\", \"../utils/metrics.cohen_kappa\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74d5579",
   "metadata": {},
   "source": [
    "For the data normalisation, we use the `QuantileScaler_eolearn_tdigest` as established by TUM.\n",
    "Hence, we need to define the savenames and corresponding parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fcdb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.savename_tdigest = config[\"savename\"]+\"_TDigest.npy\" \n",
    "config.savename_scaler = config[\"savename\"]+\"_QuantileScaler.dill\" \n",
    "\n",
    "config.scaler_minquantile = 0.02 # minquantile\n",
    "config.scaler_maxquantile = 0.98 # maxquantile\n",
    "config.scaler_valmin = 0 # corresponding value for minquantile\n",
    "config.scaler_valmax = 1 # corresponding value for maxquantile\n",
    "\n",
    "config.scaler_nanval = [0,0,0,0,0,0] # value to replace nans with\n",
    "config.scaler_infval = [0,0,0,0,0,0] # value to replace infs with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f90f9f",
   "metadata": {},
   "source": [
    "Finally, we may not forget to store our configuration file to disk and apply some checking routines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe795d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%% saving and checking\n",
    "#%%% check directories\n",
    "config.checkdir()\n",
    "#%%% check files\n",
    "config.checkfile()\n",
    "#%%% check modules\n",
    "config.checkmodule()\n",
    "#%%% save config\n",
    "file = config.save()\n",
    "file2 = config.save(os.path.join(config[\"dir_results\"],config[\"savename_config\"])) # saving to results folder\n",
    "#%% print config\n",
    "# config.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f978b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
