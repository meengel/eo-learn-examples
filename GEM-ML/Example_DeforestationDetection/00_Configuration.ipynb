{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63735c1a",
   "metadata": {},
   "source": [
    "# GEM ML Framework Demonstrator - Deforestation Detection\n",
    "In these notebooks, we provide an in-depth example of how the GEM ML framework can be used for segmenting deforested areas using Sentinel-2 imagery as input and the [TMF dataset](https://forobs.jrc.ec.europa.eu/TMF/) as a reference.\n",
    "The idea is to use a neural network (NN) model for the analysis.\n",
    "Thanks to the flexibility of the GEM ML framework, we can easily substitute the model in the future by adjusting only the configuration file.\n",
    "We will have a look at the following notebooks separately:\n",
    "- 00_Configuration\n",
    "- 01_DataAcquisition\n",
    "- 02_DataNormalization\n",
    "- 03_TrainingValidationTesting\n",
    "- 04_Inference_Clouds\n",
    "\n",
    "Authors: Michael Engel (m.engel@tum.de) and Joana Reuss (joana.reuss@tum.de)\n",
    "\n",
    "-----------------------------------------------------------------------------------\n",
    "\n",
    "# Configuration\n",
    "Here, we define the configuration of our segmentation pipeline.\n",
    "Let's import all libraries we need for that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64be303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.ConfigME import Config\n",
    "import os\n",
    "import platform\n",
    "import datetime as dt\n",
    "from sentinelhub import SHConfig\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a89888",
   "metadata": {},
   "source": [
    "## Configuration pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0c8e6e",
   "metadata": {},
   "source": [
    "We initialize the configuration file with a proper name and identifiers for storing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb420b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    name = 'GEM-ML-Framework_DeforestationDetection', # name of the project\n",
    "    savename = 'DeforestationDetectionRun', # basic name to store stuff\n",
    "    savename_config = \"config.dill\" # name of configuration file\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b626e5d8",
   "metadata": {},
   "source": [
    "Our pipeline is defined by 4 notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5702ae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.file_DataAcquisition = \"01_DataAcquisition.ipynb\"\n",
    "config.file_DataNormalization = \"02_DataNormalization.ipynb\"\n",
    "config.file_TrainingValidationTesting = \"03_TrainingValidationTesting.ipynb\"\n",
    "config.file_showcase = \"04_Inference_Clouds.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd46ac78",
   "metadata": {},
   "source": [
    "Let's define the directories we are working with, i.e. in which directories to store our `EOPatches` and results.\n",
    "By that, we ensure that everything is defined only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abb9fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% folder where data necessary for running the notebook is stored such as the geojson of the AOI\n",
    "config.dir_inputs = os.path.join(os.getcwd(),\"inputs\")\n",
    "config.dir_extra = os.path.join(os.getcwd(),\"extra\")\n",
    "\n",
    "#%% results\n",
    "config.basedir = os.path.join(os.getcwd(),config[\"savename\"])\n",
    "config.dir_results = os.path.join(config[\"basedir\"], \"results\")\n",
    "config.dir_checkpoints = os.path.join(config[\"dir_results\"], \"checkpoints\")\n",
    "config.dir_tensorboard = os.path.join(config[\"dir_results\"], \"tensorboard\")\n",
    "config.dir_imgs = os.path.join(config[\"dir_results\"], \"imgs\")\n",
    "config.dir_imgs_validation = os.path.join(config[\"dir_imgs\"],\"PredictionValidation\")\n",
    "\n",
    "#%% locations for collected data\n",
    "config.dir_data = os.path.join(config[\"basedir\"],\"data\")\n",
    "config.dir_train = os.path.join(config[\"dir_data\"], \"train\")\n",
    "config.dir_validation = os.path.join(config[\"dir_data\"], \"validation\")\n",
    "config.dir_test = os.path.join(config[\"dir_data\"], \"test\")\n",
    "config.dir_showcase = os.path.join(config[\"dir_data\"], \"showcase\")\n",
    "\n",
    "#%% locations for GeoTiffs\n",
    "config.dir_tiffs = os.path.join(config[\"dir_results\"],\"tiffs\")\n",
    "config.dir_tiffs_train = os.path.join(config[\"dir_tiffs\"],\"train\")\n",
    "config.dir_tiffs_validation = os.path.join(config[\"dir_tiffs\"],\"validation\")\n",
    "config.dir_tiffs_test = os.path.join(config[\"dir_tiffs\"],\"test\")\n",
    "config.dir_tiffs_showcase = os.path.join(config[\"dir_tiffs\"],\"showcase\")\n",
    "\n",
    "#%% caching\n",
    "config.dir_cache = os.path.join(os.getcwd(),\"cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6605c51e",
   "metadata": {},
   "source": [
    "We're defining some `tif`-filenames in order to store some results of our showcase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4283f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.savename_showcase_tiff = config[\"savename\"]+\"_showcase.tif\"\n",
    "config.savename_showcase_tiff_post = config[\"savename\"]+\"_showcase_postprocessed.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1221d3c4",
   "metadata": {},
   "source": [
    "## Reference data configuration\n",
    "\n",
    "Our reference is obtained from the [TMF dataset](https://forobs.jrc.ec.europa.eu/TMF/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592fcf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.path_reference = os.path.join(config[\"dir_inputs\"],\"JRC_TMF_AnnualChange_v2_2021_SAM_ID30_N0_W60.tif\").replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9624fa",
   "metadata": {},
   "source": [
    "The six original classes are aggreagted to the following four:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeceb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.class_water = 1\n",
    "config.class_forest = 2\n",
    "config.class_deforestation = 3\n",
    "config.class_indefinite = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a4d72f",
   "metadata": {},
   "source": [
    "The simpler class scheme above was obtained by joining the following initially provided classes:\n",
    "- `1: Undisturbed tropical moist forest` and `4:Tropical moist forest regrowth`\n",
    "- `2: Degraded tropical moist forest` and `3: Deforested land`\n",
    "\n",
    "We want to map our reference data in accordance to the simpler mapping scheme. Therefore, we apply the following label mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3748e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.labelmapping = {\n",
    "    1:config[\"class_forest\"],\n",
    "    2:config[\"class_deforestation\"],\n",
    "    3:config[\"class_deforestation\"],\n",
    "    4:config[\"class_forest\"],\n",
    "    5:config[\"class_water\"],\n",
    "    6:config[\"class_indefinite\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f88438",
   "metadata": {},
   "source": [
    "Further, we would like to incorporate the cloud cover in our reference.\n",
    "Accordingly, we define the desired class value for clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66b24ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.class_clouds = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694523fa",
   "metadata": {},
   "source": [
    "Our new reference labels ask for a unique and nice colormap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f524e71",
   "metadata": {},
   "outputs": [],
   "source": [
    " config.cmap_reference = ListedColormap([\n",
    "     \"white\", # clouds\n",
    "     \"blue\", # water\n",
    "     \"darkgreen\", # forest\n",
    "     \"orange\", # deforestation\n",
    "     \"black\" # indefinite\n",
    " ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66627698",
   "metadata": {},
   "source": [
    "## Configuration for acquiring Sentinel data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cd87d7",
   "metadata": {},
   "source": [
    "In case you did not store your credentials on disk in advance, take a look at the following [notebook](https://gitlab.lrz.de/mkoerner/projects-and-proposals/projects/2020_GEM/howto-eo-learn/-/blob/main/1_Configuration/tutorial1_config.ipynb).\n",
    "\n",
    "Loading Sentinel Hub **credentials** from storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cb4118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Sentinel Hub credentials\n",
    "config.SHconfig = SHConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d908c2d",
   "metadata": {},
   "source": [
    "Here we define parameters like the resolution and pixel width of our patches which will later be fed to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d82ab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.patchpixelwidth = 256\n",
    "config.resolution = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace94247",
   "metadata": {},
   "source": [
    "For the sake of completeness, we enable the user to apply some buffer to the AOIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04777beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.AOIbuffer = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d70a28",
   "metadata": {},
   "source": [
    "Further, we set a value for our data's desired maximum cloud coverage (in percentage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc9af2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.maxcc = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2f5cb1",
   "metadata": {},
   "source": [
    "We have defined our areas of interest (AOIs) for train, validation and test, separately (both spatially and temporally) and saved them within `geojson`-files. We can now easily point to these files and assign their location to a configuration parameter.\n",
    "\n",
    "We choose the 2021-12-31 as our cutoff date (for train, validation and test) and obtain the closest (`config.start_train = 1`) date ahead of the cutoff date with the maximum allowed cloud coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d168aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.AOI_train = os.path.join(config[\"dir_inputs\"],\"AOI_train.geojson\")\n",
    "config.start_train = 1\n",
    "config.end_train = dt.datetime(year=2021,month=12,day=31,hour=23,minute=59,second=59)\n",
    "config.checktimedelta = dt.timedelta(days=365)\n",
    "\n",
    "config.AOI_validation = os.path.join(config[\"dir_inputs\"],\"AOI_validation.geojson\")\n",
    "config.start_validation = config[\"start_train\"]\n",
    "config.end_validation = config[\"end_train\"]\n",
    "\n",
    "config.AOI_test = os.path.join(config[\"dir_inputs\"],\"AOI_test.geojson\")\n",
    "config.start_test = config[\"start_train\"]\n",
    "config.end_test = config[\"end_train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652c478d",
   "metadata": {},
   "source": [
    "Furthermore, we have defined showcase AOI used for inference for which we acquire data from the year 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d473d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.AOI_showcase = os.path.join(config[\"dir_inputs\"],\"AOI_showcase.geojson\")\n",
    "config.start_showcase = dt.datetime(year=2022,month=10,day=1)\n",
    "config.end_showcase = dt.datetime(year=2022,month=11,day=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31f8165",
   "metadata": {},
   "source": [
    "## Configuration for ML pipeline and training setup\n",
    "\n",
    "In the following, we define some general ML parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcbb03c",
   "metadata": {},
   "source": [
    "As we want to use both CPU and GPU, we have to define the number of threads and device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d2aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.threads = 1 if platform.system()==\"Windows\" else 5\n",
    "config.device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05ffde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.n_epochs = 128\n",
    "config.num_classes = 4\n",
    "config.batch_size = 12\n",
    "config.max_batch_size = 3\n",
    "config.checkpoint_bestloss = True\n",
    "config.checkpoint_bestmetric = True\n",
    "config.checkpoint_freq = 8\n",
    "config.eval_freq = 2\n",
    "config.seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb7ad9",
   "metadata": {},
   "source": [
    "We use the DeepLabV3Plus architecture as provided by [Pavel Yakubovskiy](https://segmentation-modelspytorch.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834077d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.module_model = \"segmentation_models_pytorch.DeepLabV3Plus\"\n",
    "config.kwargs_model = {\n",
    "    \"encoder_name\":\"resnet34\", # think of changing this default value!\n",
    "    \"encoder_depth\":5,\n",
    "    \"encoder_weights\":\"imagenet\", # think of changing this default value!\n",
    "    \"encoder_output_stride\":16, # think of changing this default value!\n",
    "    \"decoder_channels\":256, # think of changing this default value!\n",
    "    \"decoder_atrous_rates\":(12, 24, 36), # think of changing this default value!\n",
    "    \"in_channels\":6,\n",
    "    \"classes\":config[\"num_classes\"],\n",
    "    \"activation\":None, # think of changing this default value!\n",
    "    \"upsampling\":4, # think of changing this default value!\n",
    "    \"aux_params\":None, # think of changing this default value!\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8723295",
   "metadata": {},
   "source": [
    "Storing our trained model to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c055adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model_savename = config[\"savename\"]\n",
    "config.model_savename_bestloss = config[\"model_savename\"]+\"_bestloss\"\n",
    "config.model_savename_bestmetric = config[\"model_savename\"]+\"_bestmetric\"\n",
    "config.model_savename_inference = config[\"savename\"]+\"_inference\"\n",
    "config.model_savename_inference_bestloss = config[\"model_savename_inference\"]+\"_bestloss\"\n",
    "config.model_savename_inference_bestmetric = config[\"model_savename_inference\"]+\"_bestmetric\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0a7c15",
   "metadata": {},
   "source": [
    "We will use the classic [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
    "We will not apply loss reduction since we would like to apply our mask manually in the training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e195b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.module_loss = \"torch.nn.CrossEntropyLoss\"\n",
    "config.kwargs_loss = {\n",
    "    \"weight\":None, # change\n",
    "    \"size_average\":None,\n",
    "    \"ignore_index\":-100,\n",
    "    \"reduce\":None,\n",
    "    \"reduction\":\"none\",\n",
    "    \"label_smoothing\":0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1605e6",
   "metadata": {},
   "source": [
    "We will use the standard [Adam Optimizer](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cd8ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.module_optimizer = \"torch.optim.Adam\"\n",
    "config.kwargs_optimizer = {\n",
    "    \"lr\":0.007,\n",
    "    \"betas\":(0.9, 0.999),\n",
    "    \"eps\":1e-08,\n",
    "    \"weight_decay\":1e-06,\n",
    "    \"amsgrad\":False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682087f7",
   "metadata": {},
   "source": [
    "For evaluation, we need some metrics.\n",
    "We will use the standard Accuracy and Cohen Kappa.\n",
    "We emphasize that you could use an arbitrary amount of metrics by expanding this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ea222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.module_metric = [\"../utils/metrics.accuracy\", \"../utils/metrics.cohen_kappa\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36a16c4",
   "metadata": {},
   "source": [
    "## Configuration for Data Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74d5579",
   "metadata": {},
   "source": [
    "For the data normalization, we use the `QuantileScaler_eolearn_tdigest` as established by TUM.\n",
    "Hence, we need to define the filenames and corresponding parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fcdb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.savename_tdigest = config[\"savename\"]+\"_TDigest.npy\" \n",
    "config.savename_scaler = config[\"savename\"]+\"_QuantileScaler.dill\" \n",
    "\n",
    "config.scaler_minquantile = 0.02 # minquantile\n",
    "config.scaler_maxquantile = 0.98 # maxquantile\n",
    "config.scaler_valmin = 0 # corresponding value for minquantile\n",
    "config.scaler_valmax = 1 # corresponding value for maxquantile\n",
    "\n",
    "config.scaler_nanval = [0,0,0,0,0,0] # value to replace nans with\n",
    "config.scaler_infval = [0,0,0,0,0,0] # value to replace infs with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec83fefc",
   "metadata": {},
   "source": [
    "## Final configuration setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f90f9f",
   "metadata": {},
   "source": [
    "Finally, store our configuration file on disk and apply some checking routines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe795d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%% saving and checking\n",
    "#%%% check directories\n",
    "config.checkdir()\n",
    "#%%% check files\n",
    "config.checkfile()\n",
    "#%%% check modules\n",
    "config.checkmodule()\n",
    "#%%% save config\n",
    "file = config.save()\n",
    "file2 = config.save(os.path.join(config[\"dir_results\"],config[\"savename_config\"])) # saving to results folder\n",
    "#%% print config\n",
    "# config.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f978b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
