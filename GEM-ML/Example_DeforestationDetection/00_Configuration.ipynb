{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63735c1a",
   "metadata": {},
   "source": [
    "# GEM ML Framework Demonstrator - Deforestation Detection\n",
    "In these notebooks, we provide an in-depth example of how the GEM ML framework can be used for segmenting deforested areas using Sentinel-2 imagery as input and the [TMF dataset](https://forobs.jrc.ec.europa.eu/TMF/) as a reference.\n",
    "The idea is to use a neural network (NN) model for the analysis.\n",
    "Thanks to the flexibility of the GEM ML framework, we can easily substitute the model in the future by adjusting only the configuration file.\n",
    "We will have a look at the following notebooks separately:\n",
    "- 00_Configuration\n",
    "- 01_DataAcquisition\n",
    "- 02_DataNormalization\n",
    "- 03_TrainingValidationTesting\n",
    "- 04_Inference_Clouds\n",
    "\n",
    "Authors: Michael Engel (m.engel@tum.de) and Joana Reuss (joana.reuss@tum.de)\n",
    "\n",
    "-----------------------------------------------------------------------------------\n",
    "\n",
    "# Configuration\n",
    "Here, we define the configuration of our segmentation pipeline.\n",
    "Let's import all libraries we need for that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64be303e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorporating libs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/anaconda3/envs/eolearn_water/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import os\n",
    "import platform\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sentinelhub import SHConfig\n",
    "from torch.cuda import is_available as cuda_available\n",
    "\n",
    "from libs.ConfigME import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a89888",
   "metadata": {},
   "source": [
    "## Configuration pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0c8e6e",
   "metadata": {},
   "source": [
    "We initialize the configuration file with a proper name and identifiers for storing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb420b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    name = 'GEM-ML-Framework_DeforestationDetection', # name of the project\n",
    "    savename = 'DeforestationDetectionRun', # basic name to store stuff\n",
    "    savename_config = \"config.dill\" # name of configuration file\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b626e5d8",
   "metadata": {},
   "source": [
    "Our pipeline is defined by 4 notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5702ae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.file_DataAcquisition = \"01_DataAcquisition.ipynb\"\n",
    "config.file_DataNormalization = \"02_DataNormalization.ipynb\"\n",
    "config.file_TrainingValidationTesting = \"03_TrainingValidationTesting.ipynb\"\n",
    "config.file_showcase = \"04_Inference_Clouds.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd46ac78",
   "metadata": {},
   "source": [
    "Let's define the directories we are working with, i.e. in which directories to store our `EOPatches` and results.\n",
    "By that, we ensure that everything is defined only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5abb9fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% folder where data necessary for running the notebook is stored such as the geojson of the AOI\n",
    "config.dir_inputs = os.path.join(os.getcwd(),\"inputs\")\n",
    "config.dir_extra = os.path.join(os.getcwd(),\"extra\")\n",
    "\n",
    "#%% results\n",
    "config.basedir = os.path.join(os.getcwd(),config[\"savename\"])\n",
    "config.dir_results = os.path.join(config[\"basedir\"], \"results\")\n",
    "config.dir_checkpoints = os.path.join(config[\"dir_results\"], \"checkpoints\")\n",
    "config.dir_tensorboard = os.path.join(config[\"dir_results\"], \"tensorboard\")\n",
    "config.dir_imgs = os.path.join(config[\"dir_results\"], \"imgs\")\n",
    "config.dir_imgs_validation = os.path.join(config[\"dir_imgs\"],\"PredictionValidation\")\n",
    "\n",
    "#%% locations for collected data\n",
    "config.dir_data = os.path.join(config[\"basedir\"],\"data\")\n",
    "config.dir_train = os.path.join(config[\"dir_data\"], \"train\")\n",
    "config.dir_validation = os.path.join(config[\"dir_data\"], \"validation\")\n",
    "config.dir_test = os.path.join(config[\"dir_data\"], \"test\")\n",
    "config.dir_showcase = os.path.join(config[\"dir_data\"], \"showcase\")\n",
    "\n",
    "#%% locations for GeoTiffs\n",
    "config.dir_tiffs = os.path.join(config[\"dir_results\"],\"tiffs\")\n",
    "config.dir_tiffs_train = os.path.join(config[\"dir_tiffs\"],\"train\")\n",
    "config.dir_tiffs_validation = os.path.join(config[\"dir_tiffs\"],\"validation\")\n",
    "config.dir_tiffs_test = os.path.join(config[\"dir_tiffs\"],\"test\")\n",
    "config.dir_tiffs_showcase = os.path.join(config[\"dir_tiffs\"],\"showcase\")\n",
    "\n",
    "#%% caching\n",
    "config.dir_cache = os.path.join(os.getcwd(),\"cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6605c51e",
   "metadata": {},
   "source": [
    "We're defining some `tif`-filenames in order to store some results of our showcase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4283f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.savename_showcase_tiff = config[\"savename\"]+\"_showcase.tif\"\n",
    "config.savename_showcase_tiff_post = config[\"savename\"]+\"_showcase_postprocessed.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1221d3c4",
   "metadata": {},
   "source": [
    "## Reference data configuration\n",
    "\n",
    "Our reference is obtained from the [TMF dataset](https://forobs.jrc.ec.europa.eu/TMF/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "592fcf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.path_reference = os.path.join(config[\"dir_inputs\"],\"JRC_TMF_AnnualChange_v1_2021_SAM_ID30_N0_W60.tif\").replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9624fa",
   "metadata": {},
   "source": [
    "The six original classes are aggreagted to the following four:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edeceb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.class_water = 1\n",
    "config.class_forest = 2\n",
    "config.class_deforestation = 3\n",
    "config.class_indefinite = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a4d72f",
   "metadata": {},
   "source": [
    "The simpler class scheme above was obtained by joining the following initially provided classes:\n",
    "- `1: Undisturbed tropical moist forest` and `4:Tropical moist forest regrowth`\n",
    "- `2: Degraded tropical moist forest` and `3: Deforested land`\n",
    "\n",
    "We want to map our reference data in accordance to the simpler mapping scheme. Therefore, we apply the following label mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f3748e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.labelmapping = {\n",
    "    1:config[\"class_forest\"],\n",
    "    2:config[\"class_deforestation\"],\n",
    "    3:config[\"class_deforestation\"],\n",
    "    4:config[\"class_forest\"],\n",
    "    5:config[\"class_water\"],\n",
    "    6:config[\"class_indefinite\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f88438",
   "metadata": {},
   "source": [
    "Further, we would like to incorporate the cloud cover in our reference.\n",
    "Accordingly, we define the desired class value for clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a66b24ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.class_clouds = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694523fa",
   "metadata": {},
   "source": [
    "Our new reference labels ask for a unique and nice colormap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f524e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.cmap_reference = ListedColormap([\n",
    "     \"white\", # clouds\n",
    "     \"blue\", # water\n",
    "     \"darkgreen\", # forest\n",
    "     \"orange\", # deforestation\n",
    "     \"black\" # indefinite\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66627698",
   "metadata": {},
   "source": [
    "## Configuration for acquiring Sentinel data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cd87d7",
   "metadata": {},
   "source": [
    "In case you did not store your credentials on disk in advance, take a look at the following [notebook](https://gitlab.lrz.de/mkoerner/projects-and-proposals/projects/2020_GEM/howto-eo-learn/-/blob/main/1_Configuration/tutorial1_config.ipynb).\n",
    "\n",
    "Loading Sentinel Hub **credentials** from storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33cb4118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Sentinel Hub credentials\n",
    "config.SHconfig = SHConfig()\n",
    "if not config[\"SHconfig\"].sh_client_id or not config[\"SHconfig\"].sh_client_secret:\n",
    "    print(\"Warning! To use Process API, please provide the credentials (OAuth client ID and client secret).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d908c2d",
   "metadata": {},
   "source": [
    "Here we define parameters like the resolution and pixel width of our patches which will later be fed to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d82ab1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.patchpixelwidth = 256\n",
    "config.resolution = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace94247",
   "metadata": {},
   "source": [
    "For the sake of completeness, we enable the user to apply some buffer to the AOIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04777beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.AOIbuffer = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d70a28",
   "metadata": {},
   "source": [
    "Further, we set a value for our data's desired maximum cloud coverage (in percentage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dc9af2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.maxcc = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2f5cb1",
   "metadata": {},
   "source": [
    "We have defined our areas of interest (AOIs) for train, validation and test, separately (both spatially and temporally) and saved them within `geojson`-files. We can now easily point to these files and assign their location to a configuration parameter.\n",
    "\n",
    "We choose the 2021-12-31 as our cutoff date (for train, validation and test) and obtain the closest (`config.start_train = 1`) date ahead of the cutoff date with the maximum allowed cloud coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d168aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.AOI_train = os.path.join(config[\"dir_inputs\"],\"AOI_train.geojson\")\n",
    "config.start_train = 1\n",
    "config.end_train = dt.datetime(year=2021,month=12,day=31,hour=23,minute=59,second=59)\n",
    "config.checktimedelta = dt.timedelta(days=365)\n",
    "\n",
    "config.AOI_validation = os.path.join(config[\"dir_inputs\"],\"AOI_validation.geojson\")\n",
    "config.start_validation = config[\"start_train\"]\n",
    "config.end_validation = config[\"end_train\"]\n",
    "\n",
    "config.AOI_test = os.path.join(config[\"dir_inputs\"],\"AOI_test.geojson\")\n",
    "config.start_test = config[\"start_train\"]\n",
    "config.end_test = config[\"end_train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652c478d",
   "metadata": {},
   "source": [
    "Furthermore, we have defined showcase AOI used for inference for which we acquire data from the year 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1d473d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.AOI_showcase = os.path.join(config[\"dir_inputs\"],\"AOI_showcase.geojson\")\n",
    "config.start_showcase = dt.datetime(year=2022,month=10,day=1)\n",
    "config.end_showcase = dt.datetime(year=2022,month=11,day=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31f8165",
   "metadata": {},
   "source": [
    "## Configuration for ML pipeline and training setup\n",
    "\n",
    "In the following, we define some general ML parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcbb03c",
   "metadata": {},
   "source": [
    "As we want to use both CPU and GPU, we have to define the number of threads and device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06d2aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.threads = 1 if platform.system()==\"Windows\" else 5\n",
    "config.device = \"cuda\" if cuda_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a05ffde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.n_epochs = 64\n",
    "config.num_classes = 5\n",
    "config.batch_size = 12\n",
    "config.max_batch_size = 4\n",
    "config.checkpoint_bestloss = True\n",
    "config.checkpoint_bestmetric = True\n",
    "config.checkpoint_freq = 8\n",
    "config.eval_freq = 2\n",
    "config.seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb7ad9",
   "metadata": {},
   "source": [
    "We use the DeepLabV3Plus architecture as provided by [Pavel Yakubovskiy](https://segmentation-modelspytorch.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "834077d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.module_model = \"segmentation_models_pytorch.DeepLabV3Plus\"\n",
    "config.kwargs_model = {\n",
    "    \"encoder_name\":\"resnet34\", # think of changing this default value!\n",
    "    \"encoder_depth\":5,\n",
    "    \"encoder_weights\":\"imagenet\", # think of changing this default value!\n",
    "    \"encoder_output_stride\":16, # think of changing this default value!\n",
    "    \"decoder_channels\":256, # think of changing this default value!\n",
    "    \"decoder_atrous_rates\":(12, 24, 36), # think of changing this default value!\n",
    "    \"in_channels\":6,\n",
    "    \"classes\":config[\"num_classes\"],\n",
    "    \"activation\":None, # think of changing this default value!\n",
    "    \"upsampling\":4, # think of changing this default value!\n",
    "    \"aux_params\":None, # think of changing this default value!\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8723295",
   "metadata": {},
   "source": [
    "Storing our trained model to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c055adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model_savename = config[\"savename\"]\n",
    "config.model_savename_bestloss = config[\"model_savename\"]+\"_bestloss\"\n",
    "config.model_savename_bestmetric = config[\"model_savename\"]+\"_bestmetric\"\n",
    "config.model_savename_inference = config[\"savename\"]+\"_inference\"\n",
    "config.model_savename_inference_bestloss = config[\"model_savename_inference\"]+\"_bestloss\"\n",
    "config.model_savename_inference_bestmetric = config[\"model_savename_inference\"]+\"_bestmetric\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0a7c15",
   "metadata": {},
   "source": [
    "We will use the classic [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
    "We will not apply loss reduction since we would like to apply our mask manually in the training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e195b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.module_loss = \"torch.nn.CrossEntropyLoss\"\n",
    "config.kwargs_loss = {\n",
    "    \"weight\":None, # change\n",
    "    \"size_average\":None,\n",
    "    \"ignore_index\":-100,\n",
    "    \"reduce\":None,\n",
    "    \"reduction\":\"none\",\n",
    "    \"label_smoothing\":0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1605e6",
   "metadata": {},
   "source": [
    "We will use the standard [Adam Optimizer](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43cd8ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.module_optimizer = \"torch.optim.Adam\"\n",
    "config.kwargs_optimizer = {\n",
    "    \"lr\":0.007,\n",
    "    \"betas\":(0.9, 0.999),\n",
    "    \"eps\":1e-08,\n",
    "    \"weight_decay\":1e-06,\n",
    "    \"amsgrad\":False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682087f7",
   "metadata": {},
   "source": [
    "For evaluation, we need some metrics.\n",
    "We will use the standard Accuracy and Cohen Kappa.\n",
    "We emphasize that you could use an arbitrary amount of metrics by expanding this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9ea222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.module_metric = [\"../utils/metrics.accuracy\", \"../utils/metrics.cohen_kappa\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36a16c4",
   "metadata": {},
   "source": [
    "## Configuration for Data Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74d5579",
   "metadata": {},
   "source": [
    "For the data normalization, we use the `QuantileScaler_eolearn_tdigest` as established by TUM.\n",
    "Hence, we need to define the filenames and corresponding parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0fcdb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.savename_tdigest = config[\"savename\"]+\"_TDigest.npy\" \n",
    "config.savename_scaler = config[\"savename\"]+\"_QuantileScaler.dill\" \n",
    "\n",
    "config.scaler_minquantile = 0.02 # minquantile\n",
    "config.scaler_maxquantile = 0.98 # maxquantile\n",
    "config.scaler_valmin = 0 # corresponding value for minquantile\n",
    "config.scaler_valmax = 1 # corresponding value for maxquantile\n",
    "\n",
    "config.scaler_nanval = [0,0,0,0,0,0] # value to replace nans with\n",
    "config.scaler_infval = [0,0,0,0,0,0] # value to replace infs with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec83fefc",
   "metadata": {},
   "source": [
    "## Final configuration setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f90f9f",
   "metadata": {},
   "source": [
    "Finally, store our configuration file on disk and apply some checking routines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbe795d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CHECK DIRECTORY\n",
      "check key 9\t\t succeeded : dir_inputs : /home/michael/Documents/GEM/TUM-Git/eo-learn-examples/GEM-ML/Example_DeforestationDetection/inputs\n",
      "check key 10\t\t succeeded : dir_extra : /home/michael/Documents/GEM/TUM-Git/eo-learn-examples/GEM-ML/Example_DeforestationDetection/extra\n",
      "check key 12\t\t succeeded : dir_results : /home/michael/Documents/GEM/TUM-Git/eo-learn-examples/GEM-ML/Example_DeforestationDetection/DeforestationDetectionRun/results\n",
      "check key 13\t\t succeeded : dir_checkpoints : /home/michael/Documents/GEM/TUM-Git/eo-learn-examples/GEM-ML/Example_DeforestationDetection/DeforestationDetectionRun/results/checkpoints\n",
      "check key 14\t\t succeeded : dir_tensorboard : /home/michael/Documents/GEM/TUM-Git/eo-learn-examples/GEM-ML/Example_DeforestationDetection/DeforestationDetectionRun/results/tensorboard\n",
      "check key 15\t\t succeeded : dir_imgs : /home/michael/Documents/GEM/TUM-Git/eo-learn-examples/GEM-ML/Example_DeforestationDetection/DeforestationDetectionRun/results/imgs\n",
      "check key 16\t\t succeeded : dir_imgs_validation : /home/michael/Documents/GEM/TUM-Git/eo-learn-examples/GEM-ML/Example_DeforestationDetection/DeforestationDetectionRun/results/imgs/PredictionValidation\n",
      "check key 17\t\t succeeded : dir_data : /home/michael/Documents/GEM/TUM-Git/eo-learn-examples/GEM-ML/Example_DeforestationDetection/DeforestationDetectionRun/data\n",
      "check key 18\t\t succeeded : dir_train : /home/michael/Documents/GEM/TUM-Git/eo-learn-examples/GEM-ML/Example_DeforestationDetection/DeforestationDetectionRun/data/train\n",
      "check key 19\t\t succeeded : dir_validation : /home/michael/Documents/GEM/TUM-Git/eo-learn-examples/GEM-ML/Example_DeforestationDetection/DeforestationDetectionRun/data/validation\n",
      "check key 20\t\t succeeded : dir_test : /home/michael/Documents/GEM/TUM-Git/eo-learn-examples/GEM-ML/Example_DeforestationDetection/DeforestationDetectionRun/data/test\n",
      "check key 21\t\t succeeded : dir_showcase : /home/michael/Documents/GEM/TUM-Git/eo-learn-examples/GEM-ML/Example_DeforestationDetection/DeforestationDetectionRun/data/showcase\n",
      "check key 22\t\t succeeded : dir_tiffs : /home/michael/Documents/GEM/TUM-Git/eo-learn-examples/GEM-ML/Example_DeforestationDetection/DeforestationDetectionRun/results/tiffs\n",
      "check key 23\t\t succeeded : dir_tiffs_train : /home/michael/Documents/GEM/TUM-Git/eo-learn-examples/GEM-ML/Example_DeforestationDetection/DeforestationDetectionRun/results/tiffs/train\n",
      "check key 24\t\t succeeded : dir_tiffs_validation : /home/michael/Documents/GEM/TUM-Git/eo-learn-examples/GEM-ML/Example_DeforestationDetection/DeforestationDetectionRun/results/tiffs/validation\n",
      "check key 25\t\t succeeded : dir_tiffs_test : /home/michael/Documents/GEM/TUM-Git/eo-learn-examples/GEM-ML/Example_DeforestationDetection/DeforestationDetectionRun/results/tiffs/test\n",
      "check key 26\t\t succeeded : dir_tiffs_showcase : /home/michael/Documents/GEM/TUM-Git/eo-learn-examples/GEM-ML/Example_DeforestationDetection/DeforestationDetectionRun/results/tiffs/showcase\n",
      "check key 27\t\t succeeded : dir_cache : /home/michael/Documents/GEM/TUM-Git/eo-learn-examples/GEM-ML/Example_DeforestationDetection/cache\n",
      "\n",
      "CHECK FILE\n",
      "check key 5\t\t succeeded : file_DataAcquisition : 01_DataAcquisition.ipynb\n",
      "check key 6\t\t succeeded : file_DataNormalization : 02_DataNormalization.ipynb\n",
      "check key 7\t\t succeeded : file_TrainingValidationTesting : 03_TrainingValidationTesting.ipynb\n",
      "check key 8\t\t succeeded : file_showcase : 04_Inference_Clouds.ipynb\n",
      "\n",
      "CHECK MODULE\n",
      "check key 67\t\t succeeded : module_model : segmentation_models_pytorch.DeepLabV3Plus\n",
      "check key 75\t\t succeeded : module_loss : torch.nn.CrossEntropyLoss\n",
      "check key 77\t\t succeeded : module_optimizer : torch.optim.Adam\n",
      "check key 79\t\t succeeded : module_metric : ['../utils/metrics.accuracy', '../utils/metrics.cohen_kappa']\n"
     ]
    }
   ],
   "source": [
    "#%% saving and checking\n",
    "#%%% check directories\n",
    "config.checkdir()\n",
    "#%%% check files\n",
    "config.checkfile()\n",
    "#%%% check modules\n",
    "config.checkmodule()\n",
    "#%%% save config\n",
    "file = config.save()\n",
    "file2 = config.save(os.path.join(config[\"dir_results\"],config[\"savename_config\"])) # saving to results folder\n",
    "#%% print config\n",
    "# config.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24f978b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
