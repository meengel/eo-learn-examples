{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4a6f409",
   "metadata": {},
   "source": [
    "# GEM ML Framework Demonstrator - Deforestation Detection\n",
    "In these notebooks, we provide an in-depth example of how the GEM ML framework can be used for segmenting deforested areas using Sentinel-2 imagery as input and the [TMF dataset](https://forobs.jrc.ec.europa.eu/TMF/) as a reference.\n",
    "The idea is to use a neural network (NN) model for the analysis.\n",
    "Thanks to the flexibility of the GEM ML framework, we can easily substitute the model in the future by adjusting only the configuration file.\n",
    "We will have a look at the following notebooks separately:\n",
    "- 00_Configuration\n",
    "- 01_DataAcquisition\n",
    "- 02_DataNormalization\n",
    "- 03_TrainingValidationTesting\n",
    "- 04_Inference_Clouds\n",
    "\n",
    "Authors: Michael Engel (m.engel@tum.de) and Joana Reuss (joana.reuss@tum.de)\n",
    "\n",
    "-----------------------------------------------------------------------------------\n",
    "\n",
    "# Data Normalization\n",
    "We want to normalize our data by using the often-used quantile scaling.\n",
    "In order to receive the data distribution of the whole dataset, we merge the T-Digests we've created in the previous script for each `EOPatch`.\n",
    "Based on that, we will store the desired quantiles for data normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbf9523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import platform\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import time\n",
    "import natsort\n",
    "\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "from tensorboardX import SummaryWriter\n",
    "from tensorboard import notebook\n",
    "\n",
    "from sentinelhub import SHConfig, BBox, CRS, DataCollection, UtmZoneSplitter, DataCollection\n",
    "from eolearn.core import FeatureType, EOPatch, MergeEOPatchesTask, MapFeatureTask, MergeFeatureTask, ZipFeatureTask, LoadTask, EONode, EOWorkflow, EOExecutor, OverwritePermission, SaveTask\n",
    "from eolearn.io import SentinelHubDemTask, ExportToTiffTask, SentinelHubInputTask, SentinelHubEvalscriptTask, get_available_timestamps, ImportFromTiffTask\n",
    "from eolearn.mask import CloudMaskTask, JoinMasksTask\n",
    "from eolearn.features.feature_manipulation import SpatialResizeTask\n",
    "from eolearn.features.utils import ResizeMethod, ResizeLib\n",
    "\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon,Point\n",
    "import folium\n",
    "from folium import plugins as foliumplugins\n",
    "\n",
    "from libs.ConfigME import Config, importME\n",
    "from libs.MergeTDigests import mergeTDigests\n",
    "from libs.QuantileScaler_eolearn import QuantileScaler_eolearn_tdigest\n",
    "from libs.Dataset_eolearn import Dataset_eolearn\n",
    "from libs import AugmentME\n",
    "from libs import ExecuteME\n",
    "\n",
    "from tasks.TDigestTask import TDigestTask\n",
    "from tasks.PickIdxTask import PickIdxTask\n",
    "from tasks.SaveValidTask import SaveValidTask\n",
    "from tasks.PyTorchTasks import ModelForwardTask\n",
    "\n",
    "from utils.rasterio_reproject import rasterio_reproject\n",
    "from utils.transforms import batchify, predict, mover, Torchify\n",
    "from utils.parse_time_interval_observations import parse_time_interval_observations\n",
    "\n",
    "print(\"Working Directory:\",os.getcwd())\n",
    "print(\"Environment:\",os.environ['CONDA_DEFAULT_ENV'])\n",
    "print(\"Executable:\",sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842f1f36",
   "metadata": {},
   "source": [
    "# Config\n",
    "First, we load our configuration file which provides all information we need throughout the script and linuxify our paths (if you are working on a Windows machine) as the eo-learn filesystem manager does not support backslashes for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6c3f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% load configuration file\n",
    "config = Config.LOAD(\"config.dill\")\n",
    "\n",
    "#%% linuxify\n",
    "config.linuxify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b800cdc0",
   "metadata": {},
   "source": [
    "# Merge T-Digests\n",
    "Before we can normalize our dataset, we need to access our data's distribution.\n",
    "The T-Digests can approximate cumulative distribution functions (CDF) without having the whole dataset in memory.\n",
    "Accordingly, we can approximate the desired quantiles for normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ab3001",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "tdigest = mergeTDigests(\n",
    "    paths = [os.path.join(config[\"dir_train\"],dir_) for dir_ in os.listdir(config[\"dir_train\"])],\n",
    "    feature = (FeatureType.SCALAR_TIMELESS, 'tdigest_data'),\n",
    "    threads = 0 if platform.system()==\"Windows\" else config[\"threads\"],\n",
    "    checkthreads = True,\n",
    "    bequiet = False\n",
    ")\n",
    "print(f\"Merging of T-Digests took {time.time()-start:.2f}s using {config['threads']} thread(s)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d1c5cd",
   "metadata": {},
   "source": [
    "# Analyze T-Digests\n",
    "\n",
    "__Sentinel-2 bands__: We are looking at the bands 2, 3, 4, 8, 11 and 12 of Sentinel-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa0e5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [\"B02\",\"B03\",\"B04\",\"B08\",\"B11\",\"B12\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd8a27d",
   "metadata": {},
   "source": [
    "__Visualization__: Let's compute some quantiles for plotting the CDFs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbf23c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiless = []\n",
    "xs = []\n",
    "cdfs = []\n",
    "for i in range(len(bands)):\n",
    "    quantiless.append(np.array([tdigest[i].percentile(_) for _ in np.linspace(0,100,100)]))\n",
    "    cdfs.append(np.array([tdigest[i].cdf(_) for _ in quantiless[-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334a93e7",
   "metadata": {},
   "source": [
    "Let's have a look at the resulting CDFs!\n",
    "For clarity, we look at a 96% interval, namely from 2% to 98% of our ordered dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c41c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cidx = 2\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "for i, band in enumerate(bands):\n",
    "    plt.plot(quantiless[i][cidx:-cidx],cdfs[i][cidx:-cidx],label=band)\n",
    "\n",
    "plt.xlabel(\"Reflectance\")\n",
    "plt.ylabel(\"CDF\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "for i, band in enumerate(bands):\n",
    "    plt.hist(quantiless[i][cidx:-cidx],bins=int(np.sqrt(96)*1.5),ec=None,alpha=0.6,label=band)\n",
    "plt.xlabel(\"Reflectance\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b62dad",
   "metadata": {},
   "source": [
    "We see that the respective bands are distributed within different ranges.\n",
    "Hence, it is crucial for machine learning to normalize all of them.\n",
    "For that purpose, we store the T-Digest on disk for later use in our ML pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e5c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(config[\"dir_results\"],config[\"savename_tdigest\"]),tdigest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd62742",
   "metadata": {},
   "source": [
    "# Quantile Scaling\n",
    "As discussed, we want to apply quantile scaling to our data.\n",
    "We already merged the separate T-Digests to one and stored the result on disk.\n",
    "Note that only the training samples have been used for that.\n",
    "\n",
    "Since PyTorch asks for inputs having shape `[batch_size x channels x timestamps x height x width]`, we need to reshape the data features accordingly.\n",
    "Fortunately, the __`QuantileScaler_eolearn_tdigest`__ can handle this by setting `transform=True`.\n",
    "\n",
    "However, for our current use case, we do not need a temporal component - neither for the input data nor the reference.\n",
    "Hence, we will use the class __`Torchify`__ as provided within the __`Dataset_eolearn`__ module.\n",
    "It allows us to squeeze the temporal dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13711bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler = QuantileScaler_eolearn_tdigest(\n",
    "    tdigestarray = tdigest,\n",
    "    minquantile = config[\"scaler_minquantile\"],\n",
    "    maxquantile = config[\"scaler_maxquantile\"],\n",
    "    nanval = config[\"scaler_nanval\"],\n",
    "    infval = config[\"scaler_infval\"],\n",
    "    valmin = config[\"scaler_valmin\"],\n",
    "    valmax = config[\"scaler_valmax\"],\n",
    "    transform = Torchify(1),\n",
    "    savename = os.path.join(config[\"dir_results\"],config[\"savename_scaler\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6d7a99",
   "metadata": {},
   "source": [
    "__Let's see whether it worked!__\n",
    "\n",
    "First, we have to transform our quantiles.\n",
    "Note that this transformation is a little hacky because we have neither height nor width as we would with our `EOPatches`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113eed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = np.stack(quantiless,axis=-1)\n",
    "quantiles_transformed = Scaler(quantiles).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fe3dbb",
   "metadata": {},
   "source": [
    "Let's visualize our numeric window in the distribution of our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a0540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "for i, band in enumerate(bands):\n",
    "    plt.plot(quantiles_transformed[cidx:-cidx,i],cdfs[i][cidx:-cidx],label=band)\n",
    "plt.hlines([Scaler.minquantile,Scaler.maxquantile],Scaler.valmin,Scaler.valmax,colors='r',linestyles='--')\n",
    "plt.vlines([Scaler.valmin,Scaler.valmax],Scaler.minquantile,Scaler.maxquantile,colors='r',linestyles='--')\n",
    "\n",
    "plt.xlabel(\"Normalized Reflectance\")\n",
    "plt.ylabel(\"CDF\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "hists = []\n",
    "for i, band in enumerate(bands):\n",
    "    hists.append(plt.hist(quantiles_transformed[cidx:-cidx,i],bins=int(np.sqrt(96)*1.5),ec=None,alpha=0.6,label=band))\n",
    "plt.vlines([Scaler.valmin,Scaler.valmax],0,np.max([hist[0].max() for hist in hists]),colors='r',linestyles='--')\n",
    "\n",
    "plt.xlabel(\"Normalized Reflectance\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0081b010",
   "metadata": {},
   "source": [
    "Down the river, we have to use our scaler again.\n",
    "Hence, we store it to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59943a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
