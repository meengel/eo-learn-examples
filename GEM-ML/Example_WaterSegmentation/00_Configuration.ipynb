{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63735c1a",
   "metadata": {},
   "source": [
    "# GEM ML Framework Demonstrator - Water Segmentation\n",
    "In these notebooks, we will get a feeling of how the GEM ML framework can be used for the segmentation of water bodies using Sentinel-1 imagery as input and Sentinel-2 based normalized difference water index (NDWI) as a reference.\n",
    "The idea is to use a neural network (NN) model for the analysis.\n",
    "Thanks to the flexibility of the GEM ML framework, the model used can be replaced by changing the configuration only.\n",
    "We will have a look at the following notebooks separately:\n",
    "- 00_Configuration\n",
    "- 01_DataAcquisition\n",
    "- 02_DataNormalization\n",
    "- 03_TrainingValidationTesting\n",
    "- 04_PyTorchTasks_ModelForwardTask\n",
    "\n",
    "by Michael Engel (m.engel@tum.de)\n",
    "\n",
    "-----------------------------------------------------------------------------------\n",
    "\n",
    "# Configuration\n",
    "Here, we define the configuration of our segmentation pipeline.\n",
    "Let's import all libraries we need for that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64be303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import os\n",
    "import platform\n",
    "\n",
    "from sentinelhub import SHConfig\n",
    "from torch.cuda import is_available as cuda_available\n",
    "\n",
    "from libs.ConfigME import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0c8e6e",
   "metadata": {},
   "source": [
    "Now, we can initialize the configuration file with a proper name and identifiers for storing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb420b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    name = 'GEM-ML-Framework_WaterSegmentation', # name of the project\n",
    "    savename = 'WaterSegmentationRun', # basic name to store stuff\n",
    "    savename_config = \"config.dill\" # name of configuration file\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b626e5d8",
   "metadata": {},
   "source": [
    "Our pipeline is defined by 4 notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5702ae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.file_DataAcquisition = \"01_DataAcquisition.ipynb\"\n",
    "config.file_DataNormalization = \"02_DataNormalization.ipynb\"\n",
    "config.file_TrainingValidationTesting = \"03_TrainingValidationTesting.ipynb\"\n",
    "config.file_PyTorchTasks_ModelForwardTask = \"04_PyTorchTasks_ModelForwardTask.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd46ac78",
   "metadata": {},
   "source": [
    "Let's define the directories we are working with, i.e. in which directories to store our `EOPatches` and results.\n",
    "By that, we ensure that everything is only defined once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abb9fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% folder where data necessary for running the notebook is stored such as the geojson of the AOI\n",
    "config.dir_inputs = os.path.join(os.getcwd(),\"inputs\")\n",
    "config.dir_extra = os.path.join(os.getcwd(),\"extra\")\n",
    "\n",
    "#%% results\n",
    "config.basedir = os.path.join(os.getcwd(),config[\"savename\"])\n",
    "config.dir_results = os.path.join(config[\"basedir\"], \"results\")\n",
    "config.dir_checkpoints = os.path.join(config[\"dir_results\"], \"checkpoints\")\n",
    "config.dir_tensorboard = os.path.join(config[\"dir_results\"], \"tensorboard\")\n",
    "config.dir_imgs = os.path.join(config[\"dir_results\"], \"imgs\")\n",
    "config.dir_imgs_validation = os.path.join(config[\"dir_imgs\"],\"PredictionValidation\")\n",
    "\n",
    "#%% locations for collected data\n",
    "config.dir_data = os.path.join(config[\"basedir\"],\"data\")\n",
    "config.dir_train = os.path.join(config[\"dir_data\"], \"train\")\n",
    "config.dir_validation = os.path.join(config[\"dir_data\"], \"validation\")\n",
    "config.dir_test = os.path.join(config[\"dir_data\"], \"test\")\n",
    "config.dir_showcase = os.path.join(config[\"dir_data\"], \"showcase\")\n",
    "\n",
    "#%% locations for GeoTiffs\n",
    "config.dir_tiffs = os.path.join(config[\"dir_results\"],\"tiffs\")\n",
    "config.dir_tiffs_train = os.path.join(config[\"dir_tiffs\"],\"train\")\n",
    "config.dir_tiffs_validation = os.path.join(config[\"dir_tiffs\"],\"validation\")\n",
    "config.dir_tiffs_test = os.path.join(config[\"dir_tiffs\"],\"test\")\n",
    "config.dir_tiffs_showcase = os.path.join(config[\"dir_tiffs\"],\"showcase\")\n",
    "\n",
    "#%% caching\n",
    "config.dir_cache = os.path.join(os.getcwd(),\"cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75723287",
   "metadata": {},
   "source": [
    "Let's load our **credentials** for Sentinel Hub from storage.\n",
    "If you don't your credentialshave stored on disk yet, you should have a look at this [notebook](https://sentinelhub-py.readthedocs.io/en/latest/configure.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b019bfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Sentinel Hub credentials\n",
    "config.SHconfig = SHConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb988f9",
   "metadata": {},
   "source": [
    "Here we define the parameters like the resolution and pixelwidth of our patches which will be fed to our model later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21b8485",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.patchpixelwidth = 256\n",
    "config.resolution = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61de00f6",
   "metadata": {},
   "source": [
    "Further, we set some values for the desired maximum cloud coverage of our reference observations and the maximum allowed time period our input data could be apart of that reference date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7275df",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.maxcc = 0.5\n",
    "config.datatimedelta = dt.timedelta(days=1,hours=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2f5cb1",
   "metadata": {},
   "source": [
    "In a next step, we define our areas of interest - both spatially and temporally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d168aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.AOI_train = os.path.join(config[\"dir_inputs\"],\"PakistanFlood_train.json\")\n",
    "config.start_train = dt.datetime(year=2022,month=8,day=30)\n",
    "config.end_train = dt.datetime(year=2022,month=9,day=1)\n",
    "\n",
    "config.AOI_validation = os.path.join(config[\"dir_inputs\"],\"PakistanFlood_validation.json\")\n",
    "config.start_validation = config[\"start_train\"]\n",
    "config.end_validation = config[\"end_train\"]\n",
    "\n",
    "config.AOI_test = os.path.join(config[\"dir_inputs\"],\"PakistanFlood_test.json\")\n",
    "config.start_test = config[\"start_train\"]\n",
    "config.end_test = config[\"end_train\"]\n",
    "\n",
    "config.AOI_showcase = os.path.join(config[\"dir_inputs\"],\"NigeriaFlood.json\")\n",
    "config.end_showcase = dt.datetime(year=2022,month=11,day=7)\n",
    "config.end_showcase = dt.datetime(year=2020,month=9,day=7) # KhotanRiver\n",
    "config.checktimedelta_showcase = dt.timedelta(days=80)\n",
    "config.n_observations_showcase = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d25486",
   "metadata": {},
   "source": [
    "In order to prevent overlapping training, validation and testing regions, we erode our AOIs by half the patchwidth in meter.\n",
    "Hence, we set a buffer value used for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0612f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.AOIbuffer = -config[\"patchpixelwidth\"]*config[\"resolution\"]/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e62cc9",
   "metadata": {},
   "source": [
    "Since we want to store some results of our showcase, we have to define some savenames for those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dd4156",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.savename_showcase_tiff = \"NigeriaFlood_WaterMask.tif\"\n",
    "config.savename_showcase_tiff_reproject = \"NigeriaFlood_WaterMask_reprojected.tif\"\n",
    "config.savename_showcase_GradientShap_tiff = \"NigeriaFlood_GradientShap.tif\"\n",
    "config.savename_showcase_GradientShap_tiff_reproject = \"NigeriaFlood_GradientShap_reprojected.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcbb03c",
   "metadata": {},
   "source": [
    "As we want to use both CPU and GPU, we have to define the number of threads and device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d2aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.threads = 1 if platform.system()==\"Windows\" else 5\n",
    "config.device = \"cuda\" if cuda_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0e8f73",
   "metadata": {},
   "source": [
    "In the following, we define some general ML parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05ffde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.n_epochs = 32\n",
    "config.num_classes = 2\n",
    "config.batch_size = 16\n",
    "config.max_batch_size = 6\n",
    "config.checkpoint_bestloss = True\n",
    "config.checkpoint_freq = 8\n",
    "config.eval_freq = 2\n",
    "config.seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb7ad9",
   "metadata": {},
   "source": [
    "We want to use the DeepLabV3Plus architecture as provided by [Pavel Yakubovskiy](https://segmentation-modelspytorch.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834077d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.module_model = \"segmentation_models_pytorch.DeepLabV3Plus\"\n",
    "config.kwargs_model = {\n",
    "    \"encoder_name\":\"resnet34\", # think of changing this default value!\n",
    "    \"encoder_depth\":5, # think of changing this default value!\n",
    "    \"encoder_weights\":\"imagenet\", # think of changing this default value!\n",
    "    \"encoder_output_stride\":16, # think of changing this default value!\n",
    "    \"decoder_channels\":256, # think of changing this default value!\n",
    "    \"decoder_atrous_rates\":(12, 24, 36), # think of changing this default value!\n",
    "    \"in_channels\":2,\n",
    "    \"classes\":config[\"num_classes\"],\n",
    "    \"activation\":None, # think of changing this default value!\n",
    "    \"upsampling\":4, # think of changing this default value!\n",
    "    \"aux_params\":None, # think of changing this default value!\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8723295",
   "metadata": {},
   "source": [
    "Of course, we want to store our trained model to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c055adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model_savename = config[\"savename\"]\n",
    "config.model_savename_bestloss = config[\"model_savename\"]+\"_bestloss\"\n",
    "config.model_savename_inference = config[\"savename\"]+\"_inference\"\n",
    "config.model_savename_inference_bestloss = config[\"model_savename_inference\"]+\"_bestloss\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0a7c15",
   "metadata": {},
   "source": [
    "Here, we will use the [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) as a classic.\n",
    "We will not apply reduction since we would like to apply our mask manually in the training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e195b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.module_loss = \"torch.nn.CrossEntropyLoss\"\n",
    "config.kwargs_loss = {\n",
    "    \"weight\":None,\n",
    "    \"size_average\":None,\n",
    "    \"ignore_index\":-100,\n",
    "    \"reduce\":None,\n",
    "    \"reduction\":\"none\",\n",
    "    \"label_smoothing\":0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1605e6",
   "metadata": {},
   "source": [
    "We will use the standard [Adam Optimizer](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cd8ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.module_optimizer = \"torch.optim.Adam\"\n",
    "config.kwargs_optimizer = {\n",
    "    \"lr\":0.007,\n",
    "    \"betas\":(0.9, 0.999),\n",
    "    \"eps\":1e-08,\n",
    "    \"weight_decay\":1e-06,\n",
    "    \"amsgrad\":False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682087f7",
   "metadata": {},
   "source": [
    "For evaluation, we need some metrics.\n",
    "We will use the standard Accuracy and Cohen Kappa.\n",
    "We emphasize that you could use an arbitrary amount of metrics by expanding that list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ea222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.module_metric = [\"../utils/metrics.accuracy\", \"../utils/metrics.cohen_kappa\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74d5579",
   "metadata": {},
   "source": [
    "For the data normalisation, we use the `QuantileScaler_eolearn_tdigest` as established by TUM.\n",
    "Hence, we need to define the savenames and corresponding parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fcdb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.savename_tdigest = config[\"savename\"]+\"_TDigest.npy\" \n",
    "config.savename_scaler = config[\"savename\"]+\"_QuantileScaler.dill\" \n",
    "\n",
    "config.scaler_minquantile = 0.01 # minquantile\n",
    "config.scaler_maxquantile = 0.96 # maxquantile\n",
    "config.scaler_valmin = 0 # corresponding value for minquantile\n",
    "config.scaler_valmax = 1 # corresponding value for maxquantile\n",
    "\n",
    "config.scaler_nanval = [0,0] # value to replace nans with\n",
    "config.scaler_infval = [0,0] # value to replace infs with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f90f9f",
   "metadata": {},
   "source": [
    "Finally, we may not forget to store our configuration file to disk and apply some checking routines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe795d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%% saving and checking\n",
    "#%%% check directories\n",
    "config.checkdir()\n",
    "#%%% check files\n",
    "config.checkfile()\n",
    "#%%% check modules\n",
    "config.checkmodule()\n",
    "#%%% save config\n",
    "file = config.save()\n",
    "file2 = config.save(os.path.join(config[\"dir_results\"],config[\"savename_config\"])) # saving to results folder\n",
    "#%% print config\n",
    "# config.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f978b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
