{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63735c1a",
   "metadata": {},
   "source": [
    "# GEM ML Framework Demonstrator - Water Segmentation\n",
    "In these notebooks, we will get a feeling of how the GEM ML framework can be used for the segmentation of water bodies using Sentinel-1 imagery as input and Sentinel-2 based normalized difference water index (NDWI) as a reference.\n",
    "The idea is to use a neural network (NN) model for the analysis.\n",
    "Thanks to the flexibility of the GEM ML framework, the model used can be replaced by changing the configuration only.\n",
    "We will have a look at the following notebooks separately:\n",
    "- 00_Configuration\n",
    "- 01_DataAcquisition\n",
    "- 02_DataNormalization\n",
    "- 03_TrainingValidationTesting\n",
    "- 04_PyTorchTasks_ModelForwardTask\n",
    "- 05_PyTorchTasks_FeatureAttributionTasks (yet to come)\n",
    "- 06_PyTorchTasks_UncertaintyQuantificationTasks (yet to come)\n",
    "- 07_PyTorchTasks_DimensionalityReductionTasks (yet to come)\n",
    "\n",
    "by Michael Engel (m.engel@tum.de)\n",
    "\n",
    "-----------------------------------------------------------------------------------\n",
    "\n",
    "# Configuration\n",
    "Here, we define the configuration of our segmentation pipeline.\n",
    "Let's import all libraries we need for that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64be303e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skryp\\miniconda3\\envs\\eolearn_water\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ConfigME import Config\n",
    "import os\n",
    "import platform\n",
    "import datetime as dt\n",
    "from sentinelhub import SHConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0c8e6e",
   "metadata": {},
   "source": [
    "Now, we can initialize the configuration file with a proper name and identifiers for storing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb420b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    name = 'GEM-ML-Framework_WaterSegmentation', # name of the project\n",
    "    savename = 'WaterSegmentationRun', # basic name to store stuff\n",
    "    savename_config = \"config.dill\" # name of configuration file\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b626e5d8",
   "metadata": {},
   "source": [
    "Our pipeline is defined by 4 notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5702ae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.file_DataAcquisition = \"01_DataAcquisition.ipynb\"\n",
    "config.file_DataNormalization = \"02_DataNormalization.ipynb\"\n",
    "config.file_TrainingValidationTesting = \"03_TrainingValidationTesting.ipynb\"\n",
    "config.file_PyTorchTasks_ModelForwardTask = \"04_PyTorchTasks_ModelForwardTask.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd46ac78",
   "metadata": {},
   "source": [
    "Let's define the directories we are working with, i.e. in which directories to store our `EOPatches` and results.\n",
    "By that, we ensure that everything is only defined once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5abb9fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% folder where data necessary for running the notebook is stored such as the geojson of the AOI\n",
    "config.dir_inputs = os.path.join(os.getcwd(),\"inputs\")\n",
    "config.dir_extra = os.path.join(os.getcwd(),\"extra\")\n",
    "\n",
    "#%% results\n",
    "config.basedir = os.path.join(os.getcwd(),config[\"savename\"])\n",
    "config.dir_results = os.path.join(config[\"basedir\"], \"results\")\n",
    "config.dir_checkpoints = os.path.join(config[\"dir_results\"], \"checkpoints\")\n",
    "config.dir_tensorboard = os.path.join(config[\"dir_results\"], \"tensorboard\")\n",
    "config.dir_imgs = os.path.join(config[\"dir_results\"], \"imgs\")\n",
    "config.dir_imgs_validation = os.path.join(config[\"dir_imgs\"],\"PredictionValidation\")\n",
    "\n",
    "#%% locations for collected data\n",
    "config.dir_data = os.path.join(config[\"basedir\"],\"data\")\n",
    "config.dir_train = os.path.join(config[\"dir_data\"], \"train\")\n",
    "config.dir_validation = os.path.join(config[\"dir_data\"], \"validation\")\n",
    "config.dir_test = os.path.join(config[\"dir_data\"], \"test\")\n",
    "config.dir_showcase = os.path.join(config[\"dir_data\"], \"showcase\")\n",
    "\n",
    "#%% locations for GeoTiffs\n",
    "config.dir_tiffs = os.path.join(config[\"dir_results\"],\"tiffs\")\n",
    "config.dir_tiffs_train = os.path.join(config[\"dir_tiffs\"],\"train\")\n",
    "config.dir_tiffs_validation = os.path.join(config[\"dir_tiffs\"],\"validation\")\n",
    "config.dir_tiffs_test = os.path.join(config[\"dir_tiffs\"],\"test\")\n",
    "config.dir_tiffs_showcase = os.path.join(config[\"dir_tiffs\"],\"showcase\")\n",
    "\n",
    "#%% lovations for movies\n",
    "config.dir_movies = os.path.join(config[\"dir_results\"],\"movies\")\n",
    "config.dir_movies_showcase = os.path.join(config[\"dir_movies\"],\"showcase\")\n",
    "\n",
    "config.dir_cache = os.path.join(os.getcwd(),\"cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75723287",
   "metadata": {},
   "source": [
    "Let's load our **credentials** for Sentinel Hub from storage.\n",
    "If you should not have stored your credentials on disk yet, you should have a lookt at this [notebook](https://gitlab.lrz.de/mkoerner/projects-and-proposals/projects/2020_GEM/howto-eo-learn/-/blob/main/1_Configuration/tutorial1_config.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b019bfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Sentinel Hub credentials\n",
    "config.SHconfig = SHConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb988f9",
   "metadata": {},
   "source": [
    "Here we define the parameters like the resolution and pixelwidth of our patches which will be fed to our model later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c21b8485",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.patchpixelwidth = 256\n",
    "config.resolution = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61de00f6",
   "metadata": {},
   "source": [
    "Further, we set some values for the desired maximum cloud coverage of our reference observations and the maximum allowed time period our input data could be apart of that reference date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b7275df",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.maxcc = 0.5\n",
    "config.datatimedelta = dt.timedelta(days=1,hours=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2f5cb1",
   "metadata": {},
   "source": [
    "In a next step, we define our areas of interest - both spatially and temporally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d168aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.AOI_train = os.path.join(config[\"dir_inputs\"],\"PakistanFlood_train.json\")\n",
    "config.start_train = dt.datetime(year=2022,month=8,day=30)\n",
    "config.end_train = dt.datetime(year=2022,month=9,day=1)\n",
    "\n",
    "config.AOI_validation = os.path.join(config[\"dir_inputs\"],\"PakistanFlood_validation.json\")\n",
    "config.start_validation = config[\"start_train\"]\n",
    "config.end_validation = config[\"end_train\"]\n",
    "\n",
    "config.AOI_test = os.path.join(config[\"dir_inputs\"],\"PakistanFlood_test.json\")\n",
    "config.start_test = config[\"start_train\"]\n",
    "config.end_test = config[\"end_train\"]\n",
    "\n",
    "config.AOI_showcase = os.path.join(config[\"dir_inputs\"],\"NigeriaFlood.json\")\n",
    "config.end_showcase = dt.datetime(year=2022,month=11,day=7)\n",
    "config.end_showcase = dt.datetime(year=2020,month=9,day=7) # KhotanRiver\n",
    "config.checktimedelta_showcase = dt.timedelta(days=80)\n",
    "config.n_observations_showcase = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d25486",
   "metadata": {},
   "source": [
    "In order to prevent overlapping training, validation and testing regions, we erode our AOIs by half the patchwidth in meter.\n",
    "Hence, we set a buffer value used for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0612f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.AOIbuffer = -config[\"patchpixelwidth\"]*config[\"resolution\"]/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e62cc9",
   "metadata": {},
   "source": [
    "Since we want to store some results of our showcase, we have to define some savenames for those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17dd4156",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.savename_showcase_tiff = \"NigeriaFlood_WaterMask.tif\"\n",
    "config.savename_showcase_tiff_reproject = \"NigeriaFlood_WaterMask_reprojected.tif\"\n",
    "config.savename_showcase_GradientShap_tiff = \"NigeriaFlood_GradientShap.tif\"\n",
    "config.savename_showcase_GradientShap_tiff_reproject = \"NigeriaFlood_GradientShap_reprojected.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcbb03c",
   "metadata": {},
   "source": [
    "As we want to use both CPU and GPU, we have to define the number of threads and device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06d2aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.threads = 1 if platform.system()==\"Windows\" else 5\n",
    "config.device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0e8f73",
   "metadata": {},
   "source": [
    "In the following, we define some general ML parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a05ffde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.n_epochs = 32\n",
    "config.num_classes = 2\n",
    "config.batch_size = 16\n",
    "config.max_batch_size = 6\n",
    "config.checkpoint_bestloss = True\n",
    "config.checkpoint_freq = 8\n",
    "config.eval_freq = 2\n",
    "config.seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb7ad9",
   "metadata": {},
   "source": [
    "We want to use the DeepLabV3Plus architecture as provided by [Pavel Yakubovskiy](https://segmentation-modelspytorch.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "834077d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.module_model = \"segmentation_models_pytorch.DeepLabV3Plus\"\n",
    "config.kwargs_model = {\n",
    "    \"encoder_name\":\"resnet34\", # think of changing this default value!\n",
    "    \"encoder_depth\":5, # think of changing this default value!\n",
    "    \"encoder_weights\":\"imagenet\", # think of changing this default value!\n",
    "    \"encoder_output_stride\":16, # think of changing this default value!\n",
    "    \"decoder_channels\":256, # think of changing this default value!\n",
    "    \"decoder_atrous_rates\":(12, 24, 36), # think of changing this default value!\n",
    "    \"in_channels\":2,\n",
    "    \"classes\":config[\"num_classes\"],\n",
    "    \"activation\":None, # think of changing this default value!\n",
    "    \"upsampling\":4, # think of changing this default value!\n",
    "    \"aux_params\":None, # think of changing this default value!\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8723295",
   "metadata": {},
   "source": [
    "Of course, we want to store our trained model to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c055adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model_savename = config[\"savename\"]\n",
    "config.model_savename_bestloss = config[\"model_savename\"]+\"_bestloss\"\n",
    "config.model_savename_inference = config[\"savename\"]+\"_inference\"\n",
    "config.model_savename_inference_bestloss = config[\"model_savename_inference\"]+\"_bestloss\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0a7c15",
   "metadata": {},
   "source": [
    "Here, we will use the [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) as a classic.\n",
    "We will not apply reduction since we would like to apply our mask manually in the training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e195b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.module_loss = \"torch.nn.CrossEntropyLoss\"\n",
    "config.kwargs_loss = {\n",
    "    \"weight\":None,\n",
    "    \"size_average\":None,\n",
    "    \"ignore_index\":-100,\n",
    "    \"reduce\":None,\n",
    "    \"reduction\":\"none\",\n",
    "    \"label_smoothing\":0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1605e6",
   "metadata": {},
   "source": [
    "We will use the standard [Adam Optimizer](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43cd8ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.module_optimizer = \"torch.optim.Adam\"\n",
    "config.kwargs_optimizer = {\n",
    "    \"lr\":0.007,\n",
    "    \"betas\":(0.9, 0.999),\n",
    "    \"eps\":1e-08,\n",
    "    \"weight_decay\":1e-06,\n",
    "    \"amsgrad\":False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682087f7",
   "metadata": {},
   "source": [
    "For evaluation, we need some metrics.\n",
    "We will use the standard Accuracy and Cohen Kappa.\n",
    "We emphasize that you could use an arbitrary amount of metrics by expanding that list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9ea222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.module_metric = [\"../utils/metrics.accuracy\", \"../utils/metrics.cohen_kappa\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74d5579",
   "metadata": {},
   "source": [
    "For the data normalisation, we use the `QuantileScaler_eolearn_tdigest` as established by TUM.\n",
    "Hence, we need to define the savenames and corresponding parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0fcdb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.savename_tdigest = config[\"savename\"]+\"_TDigest.npy\" \n",
    "config.savename_scaler = config[\"savename\"]+\"_QuantileScaler.dill\" \n",
    "\n",
    "config.scaler_minquantile = 0.01 # minquantile\n",
    "config.scaler_maxquantile = 0.96 # maxquantile\n",
    "config.scaler_valmin = 0 # corresponding value for minquantile\n",
    "config.scaler_valmax = 1 # corresponding value for maxquantile\n",
    "\n",
    "config.scaler_nanval = [0,0] # value to replace nans with\n",
    "config.scaler_infval = [0,0] # value to replace infs with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f90f9f",
   "metadata": {},
   "source": [
    "Finally, we may not forget to store our configuration file to disk and apply some checking routines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbe795d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CHECK DIRECTORY\n",
      "check key 9\t\t succeeded : dir_inputs : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\inputs\n",
      "check key 10\t\t succeeded : dir_extra : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\extra\n",
      "check key 12\t\t succeeded : dir_results : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\results\n",
      "check key 13\t\t succeeded : dir_checkpoints : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\results\\checkpoints\n",
      "check key 14\t\t succeeded : dir_tensorboard : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\results\\tensorboard\n",
      "check key 15\t\t succeeded : dir_imgs : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\results\\imgs\n",
      "check key 16\t\t succeeded : dir_imgs_validation : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\results\\imgs\\PredictionValidation\n",
      "check key 17\t\t succeeded : dir_data : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\data\n",
      "check key 18\t\t succeeded : dir_train : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\data\\train\n",
      "check key 19\t\t succeeded : dir_validation : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\data\\validation\n",
      "check key 20\t\t succeeded : dir_test : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\data\\test\n",
      "check key 21\t\t succeeded : dir_showcase : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\data\\showcase\n",
      "check key 22\t\t succeeded : dir_tiffs : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\results\\tiffs\n",
      "check key 23\t\t succeeded : dir_tiffs_train : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\results\\tiffs\\train\n",
      "check key 24\t\t succeeded : dir_tiffs_validation : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\results\\tiffs\\validation\n",
      "check key 25\t\t succeeded : dir_tiffs_test : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\results\\tiffs\\test\n",
      "check key 26\t\t succeeded : dir_tiffs_showcase : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\results\\tiffs\\showcase\n",
      "check key 27\t\t succeeded : dir_movies : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\results\\movies\n",
      "check key 28\t\t succeeded : dir_movies_showcase : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\results\\movies\\showcase\n",
      "check key 29\t\t succeeded : dir_cache : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\cache\n",
      "\n",
      "CHECK FILE\n",
      "check key 5\t\t succeeded : file_DataAcquisition : 01_DataAcquisition.ipynb\n",
      "check key 6\t\t succeeded : file_DataNormalization : 02_DataNormalization.ipynb\n",
      "check key 7\t\t succeeded : file_TrainingValidationTesting : 03_TrainingValidationTesting.ipynb\n",
      "check key 8\t\t succeeded : file_PyTorchTasks_ModelForwardTask : 04_PyTorchTasks_ModelForwardTask.ipynb\n",
      "\n",
      "CHECK MODULE\n",
      "check key 63\t\t succeeded : module_model : segmentation_models_pytorch.DeepLabV3Plus\n",
      "check key 69\t\t succeeded : module_loss : torch.nn.CrossEntropyLoss\n",
      "check key 71\t\t succeeded : module_optimizer : torch.optim.Adam\n",
      "check key 73\t\t succeeded : module_metric : ['../utils/metrics.accuracy', '../utils/metrics.cohen_kappa']\n",
      "\n",
      "Configuration File WaterSegmentationRun\n",
      "0\t\tname : GEM-ML-Framework_WaterSegmentation\n",
      "1\t\ttimestamp : 2023-01-17-00-09-59-128141\n",
      "2\t\tsavename : WaterSegmentationRun\n",
      "3\t\tsavename_config : config.dill\n",
      "4\t\tenvname : WaterSegmentationRun\n",
      "5\t\tfile_DataAcquisition : 01_DataAcquisition.ipynb\n",
      "6\t\tfile_DataNormalization : 02_DataNormalization.ipynb\n",
      "7\t\tfile_TrainingValidationTesting : 03_TrainingValidationTesting.ipynb\n",
      "8\t\tfile_PyTorchTasks_ModelForwardTask : 04_PyTorchTasks_ModelForwardTask.ipynb\n",
      "9\t\tdir_inputs : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\inputs\n",
      "10\t\tdir_extra : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\extra\n",
      "11\t\tbasedir : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\n",
      "12\t\tdir_results : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\results\n",
      "13\t\tdir_checkpoints : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\results\\checkpoints\n",
      "14\t\tdir_tensorboard : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\results\\tensorboard\n",
      "15\t\tdir_imgs : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\results\\imgs\n",
      "16\t\tdir_imgs_validation : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\results\\imgs\\PredictionValidation\n",
      "17\t\tdir_data : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\data\n",
      "18\t\tdir_train : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\data\\train\n",
      "19\t\tdir_validation : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\data\\validation\n",
      "20\t\tdir_test : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\data\\test\n",
      "21\t\tdir_showcase : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\data\\showcase\n",
      "22\t\tdir_tiffs : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\results\\tiffs\n",
      "23\t\tdir_tiffs_train : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\results\\tiffs\\train\n",
      "24\t\tdir_tiffs_validation : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\results\\tiffs\\validation\n",
      "25\t\tdir_tiffs_test : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\results\\tiffs\\test\n",
      "26\t\tdir_tiffs_showcase : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\results\\tiffs\\showcase\n",
      "27\t\tdir_movies : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\results\\movies\n",
      "28\t\tdir_movies_showcase : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\WaterSegmentationRun\\results\\movies\\showcase\n",
      "29\t\tdir_cache : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\cache\n",
      "30\t\tSHconfig : {\n",
      "  \"instance_id\": \"\",\n",
      "  \"sh_client_id\": \"8875ecbf-f359-4b04-bf21-41ddd5556eb7\",\n",
      "  \"sh_client_secret\": \"m|7.<&NUvHwu#(4G<B3j>>_ZuW@P+GztP|h9i(1{\",\n",
      "  \"sh_base_url\": \"https://services.sentinel-hub.com\",\n",
      "  \"sh_auth_base_url\": \"https://services.sentinel-hub.com\",\n",
      "  \"geopedia_wms_url\": \"https://service.geopedia.world\",\n",
      "  \"geopedia_rest_url\": \"https://www.geopedia.world/rest\",\n",
      "  \"aws_access_key_id\": \"\",\n",
      "  \"aws_secret_access_key\": \"\",\n",
      "  \"aws_session_token\": \"\",\n",
      "  \"aws_metadata_url\": \"https://roda.sentinel-hub.com\",\n",
      "  \"aws_s3_l1c_bucket\": \"sentinel-s2-l1c\",\n",
      "  \"aws_s3_l2a_bucket\": \"sentinel-s2-l2a\",\n",
      "  \"opensearch_url\": \"http://opensearch.sentinel-hub.com/resto/api/collections/Sentinel2\",\n",
      "  \"max_wfs_records_per_query\": 100,\n",
      "  \"max_opensearch_records_per_query\": 500,\n",
      "  \"max_download_attempts\": 4,\n",
      "  \"download_sleep_time\": 5.0,\n",
      "  \"download_timeout_seconds\": 120.0,\n",
      "  \"number_of_download_processes\": 1\n",
      "}\n",
      "31\t\tpatchpixelwidth : 256\n",
      "32\t\tresolution : 20\n",
      "33\t\tmaxcc : 0.5\n",
      "34\t\tdatatimedelta : 1 day, 12:00:00\n",
      "35\t\tAOI_train : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\inputs\\PakistanFlood_train.json\n",
      "36\t\tstart_train : 2022-08-30 00:00:00\n",
      "37\t\tend_train : 2022-09-01 00:00:00\n",
      "38\t\tAOI_validation : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\inputs\\PakistanFlood_validation.json\n",
      "39\t\tstart_validation : 2022-08-30 00:00:00\n",
      "40\t\tend_validation : 2022-09-01 00:00:00\n",
      "41\t\tAOI_test : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\inputs\\PakistanFlood_test.json\n",
      "42\t\tstart_test : 2022-08-30 00:00:00\n",
      "43\t\tend_test : 2022-09-01 00:00:00\n",
      "44\t\tAOI_showcase : D:\\OneDrive\\Offiziell\\Promotion\\Code\\Git\\eo-learn-examples\\GEM-ML\\Example_WaterSegmentation\\inputs\\NigeriaFlood.json\n",
      "45\t\tend_showcase : 2020-09-07 00:00:00\n",
      "46\t\tchecktimedelta_showcase : 80 days, 0:00:00\n",
      "47\t\tn_observations_showcase : 8\n",
      "48\t\tAOIbuffer : -2560.0\n",
      "49\t\tsavename_showcase_tiff : NigeriaFlood_WaterMask.tif\n",
      "50\t\tsavename_showcase_tiff_reproject : NigeriaFlood_WaterMask_reprojected.tif\n",
      "51\t\tsavename_showcase_GradientShap_tiff : NigeriaFlood_GradientShap.tif\n",
      "52\t\tsavename_showcase_GradientShap_tiff_reproject : NigeriaFlood_GradientShap_reprojected.tif\n",
      "53\t\tthreads : 1\n",
      "54\t\tdevice : cuda\n",
      "55\t\tn_epochs : 32\n",
      "56\t\tnum_classes : 2\n",
      "57\t\tbatch_size : 16\n",
      "58\t\tmax_batch_size : 6\n",
      "59\t\tcheckpoint_bestloss : True\n",
      "60\t\tcheckpoint_freq : 8\n",
      "61\t\teval_freq : 2\n",
      "62\t\tseed : 42\n",
      "63\t\tmodule_model : segmentation_models_pytorch.DeepLabV3Plus\n",
      "64\t\tkwargs_model : {'encoder_name': 'resnet34', 'encoder_depth': 5, 'encoder_weights': 'imagenet', 'encoder_output_stride': 16, 'decoder_channels': 256, 'decoder_atrous_rates': (12, 24, 36), 'in_channels': 2, 'classes': 2, 'activation': None, 'upsampling': 4, 'aux_params': None}\n",
      "65\t\tmodel_savename : WaterSegmentationRun\n",
      "66\t\tmodel_savename_bestloss : WaterSegmentationRun_bestloss\n",
      "67\t\tmodel_savename_inference : WaterSegmentationRun_inference\n",
      "68\t\tmodel_savename_inference_bestloss : WaterSegmentationRun_inference_bestloss\n",
      "69\t\tmodule_loss : torch.nn.CrossEntropyLoss\n",
      "70\t\tkwargs_loss : {'weight': None, 'size_average': None, 'ignore_index': -100, 'reduce': None, 'reduction': 'none', 'label_smoothing': 0.0}\n",
      "71\t\tmodule_optimizer : torch.optim.Adam\n",
      "72\t\tkwargs_optimizer : {'lr': 0.007, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 1e-06, 'amsgrad': False}\n",
      "73\t\tmodule_metric : ['../utils/metrics.accuracy', '../utils/metrics.cohen_kappa']\n",
      "74\t\tsavename_tdigest : WaterSegmentationRun_TDigest.npy\n",
      "75\t\tsavename_scaler : WaterSegmentationRun_QuantileScaler.dill\n",
      "76\t\tscaler_minquantile : 0.01\n",
      "77\t\tscaler_maxquantile : 0.96\n",
      "78\t\tscaler_valmin : 0\n",
      "79\t\tscaler_valmax : 1\n",
      "80\t\tscaler_nanval : [0, 0]\n",
      "81\t\tscaler_infval : [0, 0]\n"
     ]
    }
   ],
   "source": [
    "#%% saving and checking\n",
    "#%%% check directories\n",
    "config.checkdir()\n",
    "#%%% check files\n",
    "config.checkfile()\n",
    "#%%% check modules\n",
    "config.checkmodule()\n",
    "#%%% save config\n",
    "file = config.save()\n",
    "file2 = config.save(os.path.join(config[\"dir_results\"],config[\"savename_config\"])) # saving to results folder\n",
    "#%% print config\n",
    "config.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f978b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
