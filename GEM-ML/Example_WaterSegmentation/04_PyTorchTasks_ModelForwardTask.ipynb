{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f84f86f",
   "metadata": {},
   "source": [
    "# GEM ML Framework Demonstrator - Water Segmentation\n",
    "In these notebooks, we will get a feeling of how the GEM ML framework can be used for the segmentation of water bodies using Sentinel-1 imagery as input and Sentinel-2 based normalized difference water index (NDWI) as a reference.\n",
    "The idea is to use a neural network (NN) model for the analysis.\n",
    "Thanks to the flexibility of the GEM ML framework, the model used can be replaced by changing the configuration only.\n",
    "We will have a look at the following notebooks separately:\n",
    "- 00_Configuration\n",
    "- 01_DataAcquisition\n",
    "- 02_DataNormalization\n",
    "- 03_TrainingValidationTesting\n",
    "- 04_PyTorchTasks_ModelForwardTask\n",
    "\n",
    "by Michael Engel (m.engel@tum.de)\n",
    "\n",
    "-----------------------------------------------------------------------------------\n",
    "\n",
    "# PyTorchTasks - ModelForwardTask\n",
    "In this notebook, we see, how the GEM ML Framework can support decision making such as for flood disasters.\n",
    "The scenario is a flood event where no reference data is available as too many clouds occured.\n",
    "Hence, we need a fast and reliable map of the water body!\n",
    "For that purpose, a fast inference pipeline is necessary.\n",
    "The `PyTorchTasks` provide the `ModelForwardTask` for that purpose.\n",
    "It enables the users to integrate an already trained PyTorch-model into their eo-learn workflows.\n",
    "The management of GPU/CPU shifting is done by the ExecuteME package we provide for that purpose.\n",
    "In general, we do recommend to do this in common Python scripts as jupyter notebooks do not support the spawn method for parallelization which PyTorch-objects ask for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c981409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import torch\n",
    "\n",
    "from folium import plugins as foliumplugins\n",
    "from shapely.geometry import Polygon\n",
    "from sentinelhub import DataCollection, UtmZoneSplitter\n",
    "\n",
    "from libs.ConfigME import Config\n",
    "from libs.QuantileScaler_eolearn import QuantileScaler_eolearn_tdigest\n",
    "from libs import AugmentME\n",
    "from libs import ExecuteME\n",
    "from utils.rasterio_reproject import rasterio_reproject\n",
    "from utils.transforms import predict\n",
    "from utils.parse_time_interval_observations import parse_time_interval_observations\n",
    "from tasks.PyTorchTasks import ModelForwardTask\n",
    "\n",
    "from eolearn.core import EONode, EOWorkflow, FeatureType, OverwritePermission, SaveTask\n",
    "from eolearn.io import ExportToTiffTask, SentinelHubInputTask\n",
    "\n",
    "print(\"Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2484bf33",
   "metadata": {},
   "source": [
    "# Config\n",
    "First, we load our configuration file which provides all information we need throughout the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267b86b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% load configuration file\n",
    "config = Config.LOAD(\"config.dill\")\n",
    "config.linuxify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4838c8b3",
   "metadata": {},
   "source": [
    "# Area of Interest\n",
    "Let's load the geojson of our area of interests for decision making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565d166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% load geojson files\n",
    "aoi_showcase = gpd.read_file(config['AOI_showcase'])\n",
    "\n",
    "#%% find best suitable crs and transform to it\n",
    "crs_showcase = aoi_showcase.estimate_utm_crs()\n",
    "aoi_showcase = aoi_showcase.to_crs(crs_showcase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee204fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% calculate and print size\n",
    "aoi_showcase_shape = aoi_showcase.geometry.values[0]\n",
    "aoi_showcase_width = aoi_showcase_shape.bounds[2]-aoi_showcase_shape.bounds[0]\n",
    "aoi_showcase_height = aoi_showcase_shape.bounds[3]-aoi_showcase_shape.bounds[1]\n",
    "print(f\"Dimension of the showcase area is {aoi_showcase_width:.0f} x {aoi_showcase_height:.0f} m2\")\n",
    "\n",
    "#%% create a splitter to obtain a list of bboxes\n",
    "bbox_splitter_showcase = UtmZoneSplitter([aoi_showcase_shape], aoi_showcase.crs, config[\"patchpixelwidth\"]*config[\"resolution\"])\n",
    "\n",
    "bbox_list_showcase = np.array(bbox_splitter_showcase.get_bbox_list())\n",
    "info_list_showcase = np.array(bbox_splitter_showcase.get_info_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5473a46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% determine number of coordinate reference systems\n",
    "crss = [bbox_._crs for bbox_ in bbox_list_showcase]\n",
    "crss_unique = np.array(list(dict.fromkeys(crss)))\n",
    "n_crss = len(crss_unique)\n",
    "\n",
    "#%% sort geometries and indices by crs and store to disk\n",
    "geometries = [[] for i in range(n_crss)]\n",
    "idxs = [[] for i in range(n_crss)]\n",
    "idxs_x = [[] for i in range(n_crss)]\n",
    "idxs_y = [[] for i in range(n_crss)]\n",
    "for i,info in enumerate(info_list_showcase):\n",
    "    idx_ = np.argmax(crss_unique==bbox_list_showcase[i]._crs)\n",
    "\n",
    "    geometries[idx_].append(Polygon(bbox_list_showcase[i].get_polygon())) # geometries sorted by crs\n",
    "    idxs[idx_].append(info[\"index\"]) # idxs sorted by crs\n",
    "    idxs_x[idx_].append(info[\"index_x\"]) # idxs_x sorted by crs\n",
    "    idxs_y[idx_].append(info[\"index_y\"]) # idxs_y sorted by crs\n",
    "\n",
    "tiles = []\n",
    "for i in range(n_crss):\n",
    "    #%%% build dataframe of our areas of interest (and each crs)\n",
    "    tiles.append(\n",
    "        gpd.GeoDataFrame(\n",
    "            {\"index\": idxs[i], \"index_x\": idxs_x[i], \"index_y\": idxs_y[i]},\n",
    "            crs=\"EPSG:\"+crss_unique[i]._value_,\n",
    "            geometry=geometries[i]\n",
    "        )\n",
    "    )\n",
    "    #%%% save dataframes to shapefiles\n",
    "    tiles[-1].to_file(os.path.join(config[\"dir_results\"],f\"grid_aoi_showcase_{i}_EPSG{str(crss_unique[i]._value_)}.gpkg\"), driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2caa372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% print amount of patches\n",
    "print(\"Total number of tiles:\",len(bbox_list_showcase))\n",
    "\n",
    "#%% visualize using folium\n",
    "aoi_folium = aoi_showcase.to_crs(\"EPSG:4326\")\n",
    "location = [aoi_folium.centroid.y,aoi_folium.centroid.x]\n",
    "\n",
    "mapwindow = folium.Map(location=location, tiles='Stamen Terrain', zoom_start=8)\n",
    "\n",
    "#%%% add aois\n",
    "#%%%% train\n",
    "mapwindow.add_child(\n",
    "    folium.features.Choropleth(\n",
    "        aoi_folium.to_json(),\n",
    "        fill_color=\"royalblue\",\n",
    "        nan_fill_color=\"royalblue\",\n",
    "        fill_opacity=0,\n",
    "        nan_fill_opacity=0.5,\n",
    "        line_color=\"royalblue\",\n",
    "        line_weight=1,\n",
    "        line_opacity=0.6,\n",
    "        smooth_factor=5,\n",
    "        name=f\"showcase area\"\n",
    "    )\n",
    ")\n",
    "\n",
    "#%%% add grids in color\n",
    "for t_,tiles_ in enumerate(tiles):\n",
    "    cp = folium.features.Choropleth(\n",
    "            tiles_.to_crs(\"EPSG:4326\").to_json(),\n",
    "            fill_color=\"royalblue\",\n",
    "            nan_fill_color=\"black\",\n",
    "            fill_opacity=0,\n",
    "            nan_fill_opacity=0.5,\n",
    "            line_color=\"royalblue\",\n",
    "            line_weight=0.5,\n",
    "            line_opacity=0.6,\n",
    "            smooth_factor=5,\n",
    "            name=f\"showcase grid EPSG:{crss_unique[t_]._value_}\"\n",
    "        ).add_to(mapwindow)\n",
    "\n",
    "    # display index next to cursor\n",
    "    folium.GeoJsonTooltip(\n",
    "        ['index'],\n",
    "        aliases=['Index:'],\n",
    "        labels=False,\n",
    "        style=\"background-color:rgba(0,101,189,0.4); border:2px solid white; color:white;\",\n",
    "        ).add_to(cp.geojson)\n",
    "\n",
    "#%%% add some controls\n",
    "folium.LayerControl().add_to(mapwindow)\n",
    "foliumplugins.Fullscreen(force_separate_button=True).add_to(mapwindow)\n",
    "\n",
    "#%%% save, render and display\n",
    "mapwindow.save(os.path.join(config[\"dir_results\"],'gridmap_showcase.html'))\n",
    "mapwindow.render()\n",
    "mapwindow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcd25ec",
   "metadata": {},
   "source": [
    "# Showcase Tasks\n",
    "Let's define our `EOTasks`.\n",
    "\n",
    "## Input Tasks\n",
    "Of course, we have to start with our input tasks which are the same as for the training, validation and testing procedure.\n",
    "Only, we skip the checking and the reference (as the area is too cloudy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4cdb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Sentinel-Hub-Input-Task\n",
    "task_data = SentinelHubInputTask(\n",
    "    data_collection = DataCollection.SENTINEL1_IW,\n",
    "    size = None,\n",
    "    resolution = config[\"resolution\"],\n",
    "    bands_feature = (FeatureType.DATA, \"data\"),\n",
    "    bands = None,\n",
    "    additional_data = (FeatureType.MASK, \"dataMask\", \"dmask_data\"),\n",
    "    evalscript = None,\n",
    "    maxcc = None,\n",
    "    time_difference = dt.timedelta(hours=1),\n",
    "    cache_folder = config[\"dir_cache\"],\n",
    "    max_threads = config[\"threads\"],\n",
    "    config = config[\"SHconfig\"],\n",
    "    bands_dtype = np.float32,\n",
    "    single_scene = False,\n",
    "    mosaicking_order = \"mostRecent\",\n",
    "    aux_request_args = None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caff44ea",
   "metadata": {},
   "source": [
    "## PyTorch Tasks\n",
    "As discussed, we want to respond to the disaster immediately.\n",
    "That means, we want to use our trained, validated and tested model for prediction!\n",
    "Fortunately, TUM established the `PyTorchTask` as a base class for many PyTorch related `EOTasks` like the `ModelForwardTask`, the `LayerGradCamTask` or the `GradientShapTask`, for example.\n",
    "In this notebook, we focus on the `ModelForwardTask`.\n",
    "\n",
    "### Model\n",
    "As a first step, however, we need to load our Scaler as built in [02_DataNormalization]() again and implement a functionality for returning the prediction of our model as the forward does return the logits and not the final prediction.\n",
    "By that, we ensure that the input feature is fed to our model and the water mask is returned as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e0d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler = QuantileScaler_eolearn_tdigest.LOAD(os.path.join(config[\"dir_results\"],config[\"savename_scaler\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3e972e",
   "metadata": {},
   "source": [
    "As a second, we load our best model using the `BaseClass` by AugmentME.\n",
    "Further, we set it to evaluation mode and tell it to share its memory for being deployed on multiple CPUs.\n",
    "It is important to load the model to the `CPU` as you get in trouble with the parallelization of ExecuteME otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c95f68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AugmentME.BaseClass(mode=\"torch\")\n",
    "model.load(os.path.join(config[\"dir_results\"],config[\"model_savename_bestloss\"]),device=\"cpu\")\n",
    "model.eval()\n",
    "model.share_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5978c8",
   "metadata": {},
   "source": [
    "### ModelForwardTask\n",
    "Now, it is time to define the `ModelForwardTask` which does the computation for us!\n",
    "As for all `EOTasks` we choose the in- and output features.\n",
    "The `in_feature` is fed to the model whereas its result is stored in the `out_feature`.\n",
    "In order to properly normalize the data downloaded we have to insert our scaler for `in_transform`.\n",
    "Since we are interested in the predicted water mask, we have to insert our prediction transform for `out_transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c19daf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_model = ModelForwardTask(\n",
    "    in_feature = (FeatureType.DATA,\"data\"),\n",
    "    out_feature = (FeatureType.MASK,\"model_output\"),\n",
    "    model = model,\n",
    "\n",
    "    in_transform = Scaler,\n",
    "    out_transform = predict,\n",
    "    in_torchtype = torch.FloatTensor,\n",
    "    batch_size = config[\"max_batch_size\"],\n",
    "\n",
    "    maxtries=3,\n",
    "    timeout=22,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0160f27f",
   "metadata": {},
   "source": [
    "## Export Tiffs and Saving Tasks\n",
    "Of course, we want to export the model output as a GeoTiff such that others can have a look at it using common GIS software.\n",
    "We can use the [`ExportToTiffTask`](https://eo-learn.readthedocs.io/en/latest/reference/eolearn.io.raster_io.html#eolearn.io.raster_io.ExportToTiffTask) for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12d0bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_tiff = ExportToTiffTask(\n",
    "    feature = (FeatureType.MASK,\"model_output\"),\n",
    "    folder = config[\"dir_tiffs_showcase\"],\n",
    "    date_indices = None,\n",
    "    band_indices = None,\n",
    "    crs = None,\n",
    "    fail_on_missing = True,\n",
    "    compress = \"deflate\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a68cf7",
   "metadata": {},
   "source": [
    "Finally, we want to store the resulting patches, of course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb358599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% save EOPatches\n",
    "task_save = SaveTask(\n",
    "    path = config[\"dir_data\"],\n",
    "    filesystem = None,\n",
    "    config = config[\"SHconfig\"],\n",
    "    overwrite_permission = OverwritePermission.OVERWRITE_PATCH,\n",
    "    compress_level = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590fc9b2",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "As usually, we start defining our nodes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9386477c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% input nodes\n",
    "node_data = EONode(\n",
    "    task = task_data,\n",
    "    inputs = [],\n",
    "    name = \"load Sentinel-1 data\"\n",
    ")\n",
    "\n",
    "#%% inference node\n",
    "node_model = EONode(\n",
    "    task = task_model,\n",
    "    inputs = [node_data],\n",
    "    name = \"predict water mask\"\n",
    ")\n",
    "\n",
    "#%% export and save\n",
    "node_tiff = EONode(\n",
    "    task = task_tiff,\n",
    "    inputs = [node_model],\n",
    "    name = \"export GeoTiff of model output\"\n",
    ")\n",
    "\n",
    "node_save = EONode(\n",
    "    task = task_save,\n",
    "    inputs = [node_tiff],\n",
    "    name = \"save EOPatch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0819005",
   "metadata": {},
   "source": [
    "Finally, we can define our workflow from endnode!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56870be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = EOWorkflow.from_endnodes(node_save)\n",
    "#workflow.dependency_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5183819c",
   "metadata": {},
   "source": [
    "# Execution\n",
    "We want to execute our workflow in parallel.\n",
    "This can be done using the package ExecuteME.\n",
    "\n",
    "In the following, we have to ensure the entry point by asking the file defining the subprocesses to be the main file since PyTorch models demand the spawn start method for subprocesses.\n",
    "Hence, we do recommend to do this in common Python scripts as jupyter notebooks ask you to clarify the entry point in every cell.\n",
    "Still, the parallelization does not work in jupyter notebooks but you may let it run using one worker.\n",
    "\n",
    "## Workflow Arguments\n",
    "On a first stage, we have to define the standard workflow arguments, both temporal and spatially.\n",
    "Note that we only want to download the data which does not exist on our device.\n",
    "Hence, we check for existence first and assign arguments afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b684889",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':  \n",
    "    #%% define workflow arguments\n",
    "    workflow_args = []\n",
    "    bbox_list_ = bbox_list_showcase\n",
    "    for i in range(len(bbox_list_)):\n",
    "        print(f\"\\rChecking workflow args {i+1}/{len(bbox_list_)}\",end=\"\\r\")\n",
    "        try:\n",
    "            #%%% query available timestamps\n",
    "            timeinterval = parse_time_interval_observations(\n",
    "                time_interval = (config[\"n_observations_showcase\"],config[\"end_showcase\"]),\n",
    "                bbox = bbox_list_[i],\n",
    "                data_collection = DataCollection.SENTINEL1_IW,\n",
    "                check_timedelta = config[\"checktimedelta_showcase\"],\n",
    "                include_borders = True,\n",
    "                time_difference = dt.timedelta(seconds=0),\n",
    "                maxcc = None,\n",
    "                config = config[\"SHconfig\"]\n",
    "            )\n",
    "            timeintervalstring = f\"{timeinterval[0].strftime(r'%Y-%m-%dT%H-%M-%S_%Z')}--{timeinterval[1].strftime(r'%Y-%m-%dT%H-%M-%S_%Z')}\"\n",
    "            dir_ = f\"showcase/eopatch_{i}_{timeintervalstring}\"\n",
    "            if not os.path.exists(os.path.join(config[\"dir_data\"],dir_)):### and False: ### \n",
    "                workflow_args.append(\n",
    "                    {\n",
    "                        node_data: {\"bbox\":bbox_list_[i],\"time_interval\":timeinterval},\n",
    "                        node_tiff: {\"filename\": f\"water_{i}_{timeintervalstring}\"},\n",
    "                        node_save: {\"eopatch_folder\":dir_}\n",
    "                    }\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(e,timeinterval)\n",
    "    print()\n",
    "\n",
    "    print(f\"Number of downloads/calculations: {len(workflow_args)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05bd64f",
   "metadata": {},
   "source": [
    "## Devices\n",
    "Second, we have to initialize a multiprocessing queue containing the names of our devices!\n",
    "By that we could use an arbitrary amount of GPUs.\n",
    "Of course, it is possible, to stay on the CPU by setting the config.device accordingly.\n",
    "\n",
    "The `PyTorchTasks` are designed for features containing multiple timestamps to be analyzed.\n",
    "Accordingly, the `batch_size` parameter of the `ModelForwardTask` refers to the timestamps, i.e. the first dimension of a feature array.\n",
    "If you do not have multiple timestamps, you may insert some kind of `batch_size` for one device by defining `batch_size x available_devices` devices or in particular `batch_size` times the device you want to use multiple times.\n",
    "Please be careful doing that since there is an additional cost of initialising the model per patch then.\n",
    "That is, the model is not shared between multiple `EOPatches`.\n",
    "Still, that behavior is beneficial if some analysis using the `ModelUncertaintyTask` is to be done.\n",
    "Here, it is necessary to deploy the model multiple times, anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69d6090",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':  \n",
    "    devices = ExecuteME.Devices([config[\"device\"]],multiprocessing_context=\"spawn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2556f405",
   "metadata": {},
   "source": [
    "In a next step, we will define the multiprocessing-type-keyword-arguments which have to be given to our tasks separately.\n",
    "These keyword-arguments have to be shared between the processes as the list of available devices should be known by the different workes and, hence, be shared or provided separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e604f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':  \n",
    "    mpkwargs = {\n",
    "        node_model: {\"devices\":devices},\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b0d3b",
   "metadata": {},
   "source": [
    "## Run\n",
    "Now, it's time to let it run!\n",
    "Please notice that we insert a 0 for `threads` since jupyter notebooks do not allow for the spawn method.\n",
    "In a Python script, you may choose as many threads as you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b8c4fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':  \n",
    "    start_multi = time.time()\n",
    "    results_multi = ExecuteME.execute(\n",
    "        fun = workflow.execute,\n",
    "        kwargslist = workflow_args,\n",
    "        mpkwargs = mpkwargs,\n",
    "        kwargsmode = None,\n",
    "        resultsqueue = None,\n",
    "        NoReturn = True,\n",
    "        timeout = 1,\n",
    "        threads = 0,#config[\"threads\"],\n",
    "        checkthreads = True,\n",
    "        multiprocessing_context = \"spawn\",\n",
    "        multiprocessing_mode = \"std\",\n",
    "        bequiet = False\n",
    "    )\n",
    "    time_multi = time.time()-start_multi\n",
    "\n",
    "    #%%% results\n",
    "    print(f\"Time Multi:\\t\\t{time_multi}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3a05e9",
   "metadata": {},
   "source": [
    "## Downloaded Data\n",
    "Let's have a look how many `EOPatches` got stored to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ffd9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of showcasedownloads: {len(workflow_args)}\")\n",
    "print(f\"Number of stored showcase EOPatches: {len(os.listdir(config['dir_showcase']))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b65752",
   "metadata": {},
   "source": [
    "We finally made it!\n",
    "Everything is ready for being analysed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c511794",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "As a first analysis step, we want to merge all of our computed GeoTiffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3364cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.importME(\"../utils/RasterME_merge.raster_merge\")(\n",
    "    inputfiles = [os.path.join(config[\"dir_tiffs_showcase\"],dir_) for dir_ in os.listdir(config[\"dir_tiffs_showcase\"]) if \"water\" in dir_.split(\"_\")],\n",
    "    outputfile = os.path.join(config[\"dir_results\"],config[\"savename_showcase_tiff\"]),\n",
    "    format_option = 'COMPRESS=Deflate',\n",
    "    sparse = True,\n",
    "    #nmax_files = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4c35fd",
   "metadata": {},
   "source": [
    "For the purpose of visualization, rather often, we need our results in EPSG:4326.\n",
    "Accordingly, we reproject it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd93d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rasterio_reproject(\n",
    "    inputfile = os.path.join(config[\"dir_results\"],config[\"savename_showcase_tiff\"]),\n",
    "    outputfile = os.path.join(config[\"dir_results\"],config[\"savename_showcase_tiff_reproject\"]),\n",
    "    crs_target = 'EPSG:4326',\n",
    "    compression = \"deflate\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112b249e",
   "metadata": {},
   "source": [
    "Let's have a look at the water mask on our map!\n",
    "As additional layers, we use some WMTS-layers we [defined in our Sentinel-Hub configuration](TODO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45578099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% visualize using folium\n",
    "#%%% predefine\n",
    "aoi_folium = aoi_showcase.to_crs(\"EPSG:4326\")\n",
    "location = [aoi_folium.centroid.y,aoi_folium.centroid.x]\n",
    "\n",
    "riofile = rasterio.open(os.path.join(config[\"dir_results\"],config[\"savename_showcase_tiff_reproject\"]))\n",
    "img = riofile.read().transpose(1,2,0)\n",
    "maxwateridx = np.argmax(np.sum(img,axis=(0,1)))\n",
    "img = img[...,[maxwateridx]]\n",
    "img = np.concatenate([0/255*img,101/255*img,189/255*img,0.3*img],axis=-1)\n",
    "\n",
    "#%%% initialize window\n",
    "mapwindow = folium.Map(location=location, tiles='OpenStreetMap', zoom_start=10)\n",
    "\n",
    "#%%% add WMTS layer\n",
    "#%%%% Sentinel-2 True Color\n",
    "wms1 = folium.WmsTileLayer(\n",
    "    f'https://services.sentinel-hub.com/ogc/wms/cea3abac-212c-45de-a69a-c6d613fb372e?Time={config[\"end_showcase\"].strftime(\"%Y-%m-%d\")}',\n",
    "    name='Sentinel-2 True Color',\n",
    "    styles='',\n",
    "    fmt='image/jpg',\n",
    "    transparent=True,\n",
    "    layers='TRUE_COLOR_VISUALIZATION,DATE',\n",
    "    overlay = True,\n",
    "    control = True,\n",
    "    show = False\n",
    ").add_to(mapwindow)\n",
    "\n",
    "#%%%% Sentinel-2 SWIR\n",
    "wms2 = folium.WmsTileLayer(\n",
    "    f'https://services.sentinel-hub.com/ogc/wms/cea3abac-212c-45de-a69a-c6d613fb372e?Time={config[\"end_showcase\"].strftime(\"%Y-%m-%d\")}',\n",
    "    name='Sentinel-2 SWIR',\n",
    "    styles='',\n",
    "    fmt='image/jpg',\n",
    "    transparent=True,\n",
    "    layers='SWIR_VISUALIZATION,DATE',\n",
    "    overlay = True,\n",
    "    control = True,\n",
    "    show = False\n",
    ").add_to(mapwindow)\n",
    "\n",
    "#%%%% Sentinel-1\n",
    "wms3 = folium.WmsTileLayer(\n",
    "    f'https://services.sentinel-hub.com/ogc/wms/cea3abac-212c-45de-a69a-c6d613fb372e?Time={config[\"end_showcase\"].strftime(\"%Y-%m-%d\")}',\n",
    "    name='Sentinel-1',\n",
    "    styles='',\n",
    "    fmt='image/jpg',\n",
    "    transparent=True,\n",
    "    layers='SENTINEL-1_IW_VIS2,DATE',\n",
    "    overlay = True,\n",
    "    control = True,\n",
    "    show = False\n",
    ").add_to(mapwindow)\n",
    "\n",
    "#%%%% Add WmsTileLayers to time control.\n",
    "time = foliumplugins.TimestampedWmsTileLayers(\n",
    "    data=[wms1,wms2,wms3],\n",
    "    transition_time=24*3600*1000,\n",
    "    loop=False,\n",
    "    auto_play=False,\n",
    "    period='P1D',\n",
    "    time_interval=False,\n",
    "    name=None\n",
    ").add_to(mapwindow)\n",
    "\n",
    "\n",
    "#%%% add water mask to map\n",
    "folium.raster_layers.ImageOverlay(\n",
    "    image = img,\n",
    "    bounds = [[riofile.bounds.bottom,riofile.bounds.left],\n",
    "              [riofile.bounds.top,riofile.bounds.right]\n",
    "             ],\n",
    "    origin = 'upper',\n",
    "    colormap = None,\n",
    "    mercator_project = True,\n",
    "    pixelated = True,\n",
    "    name = \"WaterMask\",\n",
    "    overlay = True,\n",
    "    control = True,\n",
    "    show = True,\n",
    "    opacity = 0.3\n",
    ").add_to(mapwindow)\n",
    "\n",
    "#%%% add some controls\n",
    "folium.LayerControl().add_to(mapwindow)\n",
    "foliumplugins.Fullscreen(force_separate_button=True).add_to(mapwindow)\n",
    "\n",
    "#%%% save, render and display\n",
    "mapwindow.save(os.path.join(config[\"dir_results\"],'showcase.html'))\n",
    "mapwindow.render()\n",
    "mapwindow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d51318",
   "metadata": {},
   "source": [
    "Now you know how to use the `ModelForwardTask`! :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
