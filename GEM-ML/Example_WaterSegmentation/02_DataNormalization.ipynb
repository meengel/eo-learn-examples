{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4a6f409",
   "metadata": {},
   "source": [
    "# GEM ML Framework Demonstrator - Water Segmentation\n",
    "In these notebooks, we will get a feeling of how the GEM ML framework can be used for the segmentation of water bodies using Sentinel-1 imagery as input and Sentinel-2 based normalized difference water index (NDWI) as a reference.\n",
    "The idea is to use a neural network (NN) model for the analysis.\n",
    "Thanks to the flexibility of the GEM ML framework, the model used can be replaced by changing the configuration only.\n",
    "We will have a look at the following notebooks separately:\n",
    "- 00_Configuration\n",
    "- 01_DataAcquisition\n",
    "- 02_DataNormalization\n",
    "- 03_TrainingValidationTesting\n",
    "- 04_PyTorchTasks_ModelForwardTask\n",
    "\n",
    "by Michael Engel (m.engel@tum.de)\n",
    "\n",
    "-----------------------------------------------------------------------------------\n",
    "\n",
    "# Data Normalization\n",
    "Here, we want to normalize our data by common quantile scaling.\n",
    "To do so, we will merge the T-Digests of each `EOPatch` from our training set.\n",
    "Based on that, we will store the desired quantiles for data normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbf9523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from libs.ConfigME import Config\n",
    "from libs.MergeTDigests import mergeTDigests\n",
    "from libs.QuantileScaler_eolearn import QuantileScaler_eolearn_tdigest\n",
    "from utils.transforms import Torchify\n",
    "\n",
    "from eolearn.core import FeatureType\n",
    "\n",
    "print(\"Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842f1f36",
   "metadata": {},
   "source": [
    "# Config\n",
    "First, we load our configuration file which provides all information we need throughout the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6c3f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% load configuration file\n",
    "config = Config.LOAD(\"config.dill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b800cdc0",
   "metadata": {},
   "source": [
    "# Merge T-Digests\n",
    "Before we can do the normalization of our dataset, we need to access the distribution of the data.\n",
    "The T-Digests can approximate cumulative distribution functions (CDF) without having the whole dataset in memory.\n",
    "Accordingly, we can approximate the desired quantiles for normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ab3001",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "tdigest = mergeTDigests(\n",
    "    paths = [os.path.join(config[\"dir_train\"],dir_) for dir_ in os.listdir(config[\"dir_train\"])],\n",
    "    feature = (FeatureType.SCALAR_TIMELESS, 'tdigest_data'),\n",
    "    threads = 0 if platform.system()==\"Windows\" else config[\"threads\"],\n",
    "    checkthreads = True,\n",
    "    bequiet = False\n",
    ")\n",
    "print(f\"Merging of T-Digests took {time.time()-start:.2f}s using {config['threads']} thread(s)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d1c5cd",
   "metadata": {},
   "source": [
    "# Analyse T-Digests\n",
    "Let's compute some quantiles for plotting the CDFs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbf23c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantilesVV = np.array([tdigest[0].percentile(_) for _ in np.linspace(0,100,100)])\n",
    "xVV = np.linspace(quantilesVV[0],quantilesVV[-1],100)\n",
    "cdfVV = np.array([tdigest[0].cdf(_) for _ in quantilesVV])\n",
    "\n",
    "quantilesVH = np.array([tdigest[1].percentile(_) for _ in np.linspace(0,100,100)])\n",
    "xVH = np.linspace(quantilesVH[0],quantilesVH[-1],100)\n",
    "cdfVH = np.array([tdigest[1].cdf(_) for _ in quantilesVH])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334a93e7",
   "metadata": {},
   "source": [
    "Let's have a look at the resulting CDFs!\n",
    "For the sake of clarity, we will have a look at a 96%-interval, namely from the 2% to the 98% quantile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c41c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.plot(quantilesVV[2:-2],cdfVV[2:-2],\"b\",label=\"Sentinel-1 VV\")\n",
    "plt.plot(quantilesVH[2:-2],cdfVH[2:-2],\"m\",label=\"Sentinel-1 VH\")\n",
    "\n",
    "plt.xlabel(\"Backscatter\")\n",
    "plt.ylabel(\"CDF\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(quantilesVV[2:-2],bins=int(np.sqrt(96)*1.5),fc=\"b\",ec=None,alpha=0.6,label=\"Sentinel-1 VV\")\n",
    "plt.hist(quantilesVH[2:-2],bins=int(np.sqrt(96)*1.5),fc=\"m\",ec=None,alpha=0.6,label=\"Sentinel-1 VH\")\n",
    "plt.xlabel(\"Backscatter\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b62dad",
   "metadata": {},
   "source": [
    "We see that the input bands live in different ranges.\n",
    "Hence, it is crucial for machine learning to normalize both.\n",
    "For that purpose, we store the T-Digest to disk for later usage in our ML pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e5c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(config[\"dir_results\"],config[\"savename_tdigest\"]),tdigest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd62742",
   "metadata": {},
   "source": [
    "# Quantile Scaling\n",
    "As discussed, we want to apply quantile scaling to our data.\n",
    "We already merged the separate T-Digests to one and stored the result to disk.\n",
    "Note that only the training samples have been used for that.\n",
    "\n",
    "Since PyTorch asks for the shape `[batch_size x channels x timestamps x height x width]`, we need to reshape the data features accordingly.\n",
    "Fortunately, the `QuantileScaler_eolearn_tdigest` can handle this by setting `transform=True`.\n",
    "However, we do not need a temporal component - neither for the input data nor the reference.\n",
    "Hence, we will use the class `Torchify` itself as provided from the `Dataset_eolearn` package which allows to squeeze the temporal dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13711bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler = QuantileScaler_eolearn_tdigest(\n",
    "    tdigestarray = tdigest,\n",
    "    minquantile = config[\"scaler_minquantile\"],\n",
    "    maxquantile = config[\"scaler_maxquantile\"],\n",
    "    nanval = config[\"scaler_nanval\"],\n",
    "    infval = config[\"scaler_infval\"],\n",
    "    valmin = config[\"scaler_valmin\"],\n",
    "    valmax = config[\"scaler_valmax\"],\n",
    "    transform = Torchify(1),\n",
    "    savename = os.path.join(config[\"dir_results\"],config[\"savename_scaler\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6d7a99",
   "metadata": {},
   "source": [
    "Let's see whether it works!\n",
    "First, we have to transform our quantiles.\n",
    "Note that this transformation is a bit hacky as we do not have height nor width as we would for our `EOPatches`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113eed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = np.stack((quantilesVV,quantilesVH),axis=-1)\n",
    "quantiles_transformed = Scaler(quantiles).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fe3dbb",
   "metadata": {},
   "source": [
    "Let's visualise our numeric window in the distribution of our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a0540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.plot(quantiles_transformed[2:-2,0],cdfVV[2:-2],\"b\",label=\"Sentinel-1 VV\")\n",
    "plt.plot(quantiles_transformed[2:-2,1],cdfVH[2:-2],\"m\",label=\"Sentinel-1 VH\")\n",
    "plt.hlines([Scaler.minquantile,Scaler.maxquantile],Scaler.valmin,Scaler.valmax,colors='r',linestyles='--')\n",
    "plt.vlines([Scaler.valmin,Scaler.valmax],Scaler.minquantile,Scaler.maxquantile,colors='r',linestyles='--')\n",
    "\n",
    "plt.xlabel(\"Normalized Backscatter\")\n",
    "plt.ylabel(\"CDF\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "histVV = plt.hist(quantiles_transformed[2:-2,0],bins=int(np.sqrt(96)*1.5),fc=\"b\",ec=None,alpha=0.6,label=\"Sentinel-1 VV\")\n",
    "histVH = plt.hist(quantiles_transformed[2:-2,1],bins=int(np.sqrt(96)*1.5),fc=\"m\",ec=None,alpha=0.6,label=\"Sentinel-1 VH\")\n",
    "plt.vlines([Scaler.valmin,Scaler.valmax],0,np.max([histVV[0].max(),histVH[0].max()]),colors='r',linestyles='--')\n",
    "\n",
    "plt.xlabel(\"Normalized Backscatter\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0081b010",
   "metadata": {},
   "source": [
    "Down the river, we have to use our scaler again.\n",
    "Hence, we store it to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59943a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65a670a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
