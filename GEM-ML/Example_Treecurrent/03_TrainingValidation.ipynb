{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f84f86f",
   "metadata": {},
   "source": [
    "# Training and Validation \n",
    "In this notebook, we will train and validate the model of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c981409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory: /home/ldbv/treecurrent\n",
      "Environment: treecurrent2\n",
      "Executable: /home/ldbv/anaconda3/envs/treecurrent2/bin/python\n"
     ]
    }
   ],
   "source": [
    "### Michael Engel ### 2022-04-25 ### main.ipynb ###\n",
    "### adapted by Niklas Eisl, Colin Moldenhauer, 2022/23 ###\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import platform\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import natsort\n",
    "\n",
    "import torch\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from eolearn.core import FeatureType\n",
    "\n",
    "from libs.ConfigME import Config, importME, get_most_recent_config\n",
    "from libs.QuantileScaler_eolearn import QuantileScaler_eolearn_tdigest\n",
    "from libs.Dataset_eolearn import Dataset_eolearn\n",
    "from libs import AugmentME\n",
    "\n",
    "print(\"Working Directory:\",os.getcwd())\n",
    "print(\"Environment:\",os.environ['CONDA_DEFAULT_ENV'])\n",
    "print(\"Executable:\",sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2484bf33",
   "metadata": {},
   "source": [
    "# Config\n",
    "First, we load our configuration file which provides all information we need throughout the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6449852a",
   "metadata": {
    "pycharm": {
     "name": "#%% load configuration file\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded config: config_Treecurrent_2023-01-26-17-34-04-553268.dill\n"
     ]
    }
   ],
   "source": [
    "config_name = get_most_recent_config(\".\", pattern=\"config_.*[.]dill\", mode=\"m\")\n",
    "config = Config.LOAD(config_name)\n",
    "print(\"loaded config:\", config_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacabf47",
   "metadata": {},
   "source": [
    "# Batch Size\n",
    "As we deal with high dimensional data and several time stamps, it is important to choose a reasonably low batch size. A too small batch size on the other hand will result in highly stochastic gradients. We have found a batch size of 6 to work well for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd709875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen batch_size: 6\n"
     ]
    }
   ],
   "source": [
    "bs = config['batch_size']\n",
    "print(f'Chosen batch_size: {bs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeeeccb",
   "metadata": {},
   "source": [
    "# Quantile Scaling\n",
    "As discussed in the second notebook, we want to apply quantile scaling to our data.\n",
    "We load the scaler that we have already defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36e5a8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler = QuantileScaler_eolearn_tdigest.LOAD(os.path.join(config[\"dir_results\"],config[\"savename_scaler\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35f34c",
   "metadata": {},
   "source": [
    "# Dataloader\n",
    "First, we need to get the paths for all samples within our training and validation datasets, respectively. More specifically, we create a list of paths that will then be passed to the `Dataset_eolearn` class which prepares the data in a way such that the dataloader can load it into the batches that we use during training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8ba8cac",
   "metadata": {
    "pycharm": {
     "name": "#%% training samples\n"
    }
   },
   "outputs": [],
   "source": [
    "paths_train = [os.path.join(config[\"dir_train\"], file).replace(\"\\\\\",\"/\") for file in os.listdir(config[\"dir_train\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2f763b2",
   "metadata": {
    "pycharm": {
     "name": "#%% validation samples\n"
    }
   },
   "outputs": [],
   "source": [
    "paths_validation = [os.path.join(config[\"dir_val\"], file).replace(\"\\\\\",\"/\") for file in os.listdir(config[\"dir_val\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa4709a",
   "metadata": {},
   "source": [
    "Now, we are ready to define our datasets using the `Dataset_eolearn` class!\n",
    "\n",
    "Remember that PyTorch asks for the shape `[batch_size x channels x timestamps x height x width]`.\n",
    "The `Quantile\n",
    "_eolearn_tdigest` handles this by setting `transform=Torchify(1)`.\n",
    "For the reference and the mask, we use the `Torchify` class as provided from the `Dataset_eolearn` package, too.\n",
    "\n",
    "So befor we initialize the Datasets, let's briefly have a look at the `Torchify` class. In a nutshell, this class handles our final transforms such that Pytorch can use the data for training. This includes rearranging of dimensions and removing of `NaN` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def torchify(array):\n",
    "    return np.moveaxis(array, -1, 0)\n",
    "\n",
    "def nan_to_value(array, value=0):\n",
    "    nan_loc = np.isnan(array)\n",
    "    array[nan_loc] = value\n",
    "    return array\n",
    "\n",
    "\n",
    "class Torchify():\n",
    "    def __init__(self,squeeze=False, nanvalue=0):\n",
    "        self.squeeze = squeeze\n",
    "        self.nanvalue = nanvalue\n",
    "    def __call__(self,array):\n",
    "        array_ = torchify(array)\n",
    "        array_ = nan_to_value(array_, value=self.nanvalue)\n",
    "\n",
    "        if self.squeeze==True:\n",
    "            return array_.squeeze()\n",
    "        elif type(self.squeeze)==int:\n",
    "            return array_.squeeze(self.squeeze)\n",
    "        else:\n",
    "            return array_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% torchify\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0328d8fe",
   "metadata": {
    "pycharm": {
     "name": "#%% training dataset\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_train = Dataset_eolearn(\n",
    "    paths = paths_train,\n",
    "    feature_data = (FeatureType.DATA, \"data\"),\n",
    "    feature_reference = (FeatureType.DATA, \"reference\"),\n",
    "    feature_mask = (FeatureType.MASK, \"mask_reference\"),\n",
    "\n",
    "    transform_data = Scaler,\n",
    "    transform_reference = Torchify(squeeze=1, nanvalue=0),\n",
    "    transform_mask = Torchify(squeeze=1, nanvalue=0),\n",
    "    \n",
    "    return_idx = False,\n",
    "    return_path = False,\n",
    "\n",
    "    torchdevice = None,\n",
    "    torchtype_data = torch.FloatTensor,\n",
    "    torchtype_reference = torch.FloatTensor,\n",
    "    torchtype_mask = torch.FloatTensor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a31b0fe",
   "metadata": {
    "pycharm": {
     "name": "#%% validation dataset\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_validation = Dataset_eolearn(\n",
    "    paths = paths_validation,\n",
    "    feature_data = (FeatureType.DATA, \"data\"),\n",
    "    feature_reference = (FeatureType.DATA, \"reference\"),\n",
    "    feature_mask = (FeatureType.MASK,\"mask_reference\"),\n",
    "\n",
    "    transform_data = Scaler,\n",
    "    transform_reference = Torchify(squeeze=1, nanvalue=0),\n",
    "    transform_mask = Torchify(squeeze=1, nanvalue=0),\n",
    "    \n",
    "    return_idx = False,\n",
    "    return_path = False,\n",
    "\n",
    "    torchdevice = None,\n",
    "    torchtype_data = torch.FloatTensor,\n",
    "    torchtype_reference = torch.FloatTensor,\n",
    "    torchtype_mask = torch.FloatTensor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cec2844",
   "metadata": {},
   "source": [
    "Let's test our datasets! \n",
    "\n",
    "As we can see, each batch of our input data `x` consists of \n",
    "- 6 samples, \n",
    "- 6 channels (where the channels correpond to the downloaded bands `B02`, `B03`, `B04`, `B08`, `B8A` and `B11`),\n",
    "- 8 consecutive time stamps\n",
    "- and a spatial resolution of `256x256` for each patch.\n",
    "\n",
    "The corresponding reference `y` collapses the channel and timestamp dimesions and we end up with\n",
    "- 6 samples\n",
    "- and a spatial resolution of `256x256` for each patch, where all values are in the range `[-1,1]` to represent the NDVI index.\n",
    "\n",
    "The mask has the same shape as the reference `y` with binary values to filter with the`no-data mask` and `cloud mask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30790772",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: torch.Size([6, 6, 8, 256, 256])\n",
      "Training Reference Shape: torch.Size([6, 256, 256])\n",
      "Training Mask Shape: torch.Size([6, 256, 256])\n",
      "\n",
      "Validation Data Shape: torch.Size([6, 6, 8, 256, 256])\n",
      "Validation Reference Shape: torch.Size([6, 256, 256])\n",
      "Validation Mask Shape: torch.Size([6, 256, 256])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_train = dataset_train[:config[\"batch_size\"]]\n",
    "print('Training Data Shape:',sample_train[0].shape)\n",
    "print('Training Reference Shape:',sample_train[1].shape)\n",
    "print('Training Mask Shape:',sample_train[2].shape)\n",
    "print()\n",
    "\n",
    "sample_validation = dataset_validation[:config[\"batch_size\"]]\n",
    "print('Validation Data Shape:',sample_validation[0].shape)\n",
    "print('Validation Reference Shape:',sample_validation[1].shape)\n",
    "print('Validation Mask Shape:',sample_validation[2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb87976a",
   "metadata": {},
   "source": [
    "Let's define our dataloader for each dataset.\n",
    "We will double our `batch_size` for validation as no gradient calculation is needed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b04b2a82",
   "metadata": {
    "pycharm": {
     "name": "#%% training dataloader\n"
    }
   },
   "outputs": [],
   "source": [
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    dataset = dataset_train,\n",
    "    batch_size = config[\"batch_size\"],\n",
    "    shuffle = True,\n",
    "    sampler = None,\n",
    "    batch_sampler = None,\n",
    "    num_workers = 0 if platform.system()==\"Windows\" else config[\"threads\"],\n",
    "    collate_fn = None,\n",
    "    pin_memory = False,\n",
    "    drop_last = True,\n",
    "    timeout = 0,\n",
    "    worker_init_fn = None,\n",
    "    multiprocessing_context = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b3f782e",
   "metadata": {
    "pycharm": {
     "name": "#%% validation dataloader\n"
    }
   },
   "outputs": [],
   "source": [
    "dataloader_validation = torch.utils.data.DataLoader(\n",
    "    dataset = dataset_validation,\n",
    "    batch_size = config[\"batch_size\"]*2,\n",
    "    shuffle = False,\n",
    "    sampler = None,\n",
    "    batch_sampler = None,\n",
    "    num_workers = 0 if platform.system()==\"Windows\" else config[\"threads\"],\n",
    "    collate_fn = None,\n",
    "    pin_memory = False,\n",
    "    drop_last = True,\n",
    "    timeout = 0,\n",
    "    worker_init_fn = None,\n",
    "    multiprocessing_context = None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabeb0f4",
   "metadata": {},
   "source": [
    "# Model\n",
    "Now, it's time to initialise our model.\n",
    "We will do that using `importME` since we want to keep flexibility with regard to the model architecture used. That way, changes can easily be made in the Configuaration Notebook without having to modify this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e5049ee",
   "metadata": {
    "pycharm": {
     "name": "#%% import model\n"
    }
   },
   "outputs": [],
   "source": [
    "module_model = importME(config[\"module_model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08264474",
   "metadata": {},
   "source": [
    "Since we are dealing with time-series data in image format, we have chosen a `Convolutional LSTM` architecture as our model. \n",
    "\n",
    "The original paper can be found [here](https://arxiv.org/abs/1506.04214). \n",
    "The model used in this notebook slightly deviates from the paper and the implementation can be found [here](https://github.com/ndrplz/ConvLSTM_pytorch).\n",
    "\n",
    "The dynamics implemented in the used model can be described as:\n",
    "\n",
    "[<img src=\"https://user-images.githubusercontent.com/7113894/59357391-15c73e00-8d2b-11e9-8234-9d51a90be5dc.png\">](https://user-images.githubusercontent.com/)\n",
    "\n",
    "When executing the following cell, one can see the small overall model that is currently used alongside with the hpyerparameters that are defined in the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f32710b",
   "metadata": {
    "pycharm": {
     "name": "#%% initialise model\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvLSTM(\n",
       "  (cell_list): ModuleList(\n",
       "    (0): ConvLSTMCell(\n",
       "      (conv): Conv2d(26, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): ConvLSTMCell(\n",
       "      (conv): Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (2): ConvLSTMCell(\n",
       "      (conv): Conv2d(21, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = module_model(**config[\"kwargs_model\"])\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fd30da",
   "metadata": {},
   "source": [
    "Now, we want to augment the model such that it fits in our training pipeline.\n",
    "We will add some IO methods such as saving and loading to it.\n",
    "Further, we will add a method for getting the gradients during training.\n",
    "That will be used for a brainwave monitor.\n",
    "The benefit of that gets clear if you think of changing the architecture used but do not mean to change the IO interface of your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbcbb234",
   "metadata": {
    "pycharm": {
     "name": "#%% general IO\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AugmentME.augment_IO(model,savekey='save',loadkey='load',mode='torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cdfc9ba",
   "metadata": {
    "pycharm": {
     "name": "#%% checkpoint saving\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AugmentME.augment_checkpoint(model,key='save_checkpoint',mode='torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec9633b7",
   "metadata": {
    "pycharm": {
     "name": "#%% gradient method\n"
    }
   },
   "outputs": [],
   "source": [
    "AugmentME.augment_gradient(model,key='get_gradient',mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13285623",
   "metadata": {
    "pycharm": {
     "name": "#%% number of parameters\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AugmentME.augment_Ntheta(model,key=\"get_Ntheta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b54ce6",
   "metadata": {},
   "source": [
    "As a test if the augmenting worked, we want to have a look at the number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c23732d3",
   "metadata": {
    "pycharm": {
     "name": "#%% number of parameters\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 48440\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of parameters:\",model.get_Ntheta())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbba136c",
   "metadata": {},
   "source": [
    "# Training\n",
    "Before we can start training our model, we have to define a loss function.\n",
    "We will keep it as flexible as the model itself and use `importME`. \n",
    "\n",
    "As we deal with a regression task we use a classical `MSE Loss` function. However, it is important to also take the mask into account that we get for each batch in addition to `x` and `y`. The loss fuction can be modified such that no loss is computed for those pixels where the mask has a value of 1. \n",
    "\n",
    "We have implemented such a custom loss called `MSELossMasked` which can be found in `libs\\loss.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61741159",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = importME(config[\"module_loss\"])(**config[\"kwargs_loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8230bafc",
   "metadata": {},
   "source": [
    "No optimization without an optimizer! \n",
    "Due to corresponding device issues, we have to send our model to the device before we define our optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c19daf7",
   "metadata": {
    "pycharm": {
     "name": "#%% send model to device to avoid device errors\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvLSTM(\n",
       "  (cell_list): ModuleList(\n",
       "    (0): ConvLSTMCell(\n",
       "      (conv): Conv2d(26, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): ConvLSTMCell(\n",
       "      (conv): Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (2): ConvLSTMCell(\n",
       "      (conv): Conv2d(21, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(config[\"device\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1071d8d1",
   "metadata": {},
   "source": [
    "Now, we can define our optimizer with the parameters already been sent to our chosen device!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45a4c812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: False\n",
       "    lr: 7e-05\n",
       "    maximize: False\n",
       "    weight_decay: 1e-06\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = importME(config[\"module_optimizer\"])(model.parameters(),**config[\"kwargs_optimizer\"])\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eca0145",
   "metadata": {},
   "source": [
    "## Sanity Check\n",
    "\n",
    "When training a NN is makes sense to perform simple debugging steps before running the model for hours!\n",
    "A very simple idea to do so is to overfit a small subset of our data.\n",
    "**Overfitting a single sample** verifies that the loss function works properly and **overfitting on a single batch** helps us to catch a large number of bugs early!\n",
    "\n",
    "In our case, we optimize the model on one single batch for 100 iterations and see that our loss goes towards 0!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6812a5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overfitting to a single batch for 100 steps...\n",
      "Iteration: 10, Loss: 0.2248678207397461\n",
      "Iteration: 20, Loss: 0.21632389724254608\n",
      "Iteration: 30, Loss: 0.20345477759838104\n",
      "Iteration: 40, Loss: 0.1812230348587036\n",
      "Iteration: 50, Loss: 0.1417338252067566\n",
      "Iteration: 60, Loss: 0.08976586163043976\n",
      "Iteration: 70, Loss: 0.07031788676977158\n",
      "Iteration: 80, Loss: 0.07202398031949997\n",
      "Iteration: 90, Loss: 0.06893713772296906\n",
      "Iteration: 100, Loss: 0.06867506355047226\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get a batch from the dataloader\n",
    "x, y, mask = next(iter(dataloader_train))\n",
    "# send it to correct device\n",
    "x = x.to(config[\"device\"])\n",
    "y = y.to(config[\"device\"])\n",
    "mask = mask.to(config[\"device\"])\n",
    "# append losses for visualization\n",
    "loss_history = []\n",
    "print('Overfitting to a single batch for 100 steps...')\n",
    "for i in range(100):\n",
    "    out, _ = model.forward(x)\n",
    "    pred = out[0][:, -1, ...].squeeze().to(config[\"device\"])\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_function(pred, y, mask)\n",
    "    loss_history.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (i+1)%10 == 0:\n",
    "        print(f'Iteration: {i+1}, Loss: {loss}')\n",
    "# plot the loss function\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel('Iterations', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81601344",
   "metadata": {},
   "source": [
    "To assess the performance of our model, we load some metrics. Similar to the loss function, we use the `Masked MSE Loss` function as our first metric and a `Squared Variance Error` to also take the variance into account. The implementatin of both metrics can be found in `libs\\metrics.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0bd3dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = importME(config[\"module_metric\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0274f836",
   "metadata": {},
   "source": [
    "Of course, we would like to track the proceeding of our training procedure.\n",
    "Hence, we define a tensorboard [SummaryWriter](https://tensorboardx.readthedocs.io/en/latest/tensorboard.html#tensorboardX.SummaryWriter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2792bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(config[\"dir_tensorboard\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41f3d85",
   "metadata": {},
   "source": [
    "Anyway, we would like to make our experiment reproducible.\n",
    "Thus, we set the seeds such that all random number generation and shuffling is done in a deterministic manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62823fe7",
   "metadata": {
    "pycharm": {
     "name": "#%% reproducibility\n"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(config[\"seed\"])\n",
    "torch.manual_seed(config[\"seed\"])\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93120cc7",
   "metadata": {},
   "source": [
    "In case of a premature exit of the training procedure, we insert a resume flag here.\n",
    "It enables the user to start with the chosen checkpoint or automatically choose the most recent one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e0b69bc",
   "metadata": {
    "pycharm": {
     "name": "#%% resume flag\n"
    }
   },
   "outputs": [],
   "source": [
    "resume = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4c1a98f",
   "metadata": {
    "pycharm": {
     "name": "#%% resume case\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvLSTM(\n",
       "  (cell_list): ModuleList(\n",
       "    (0): ConvLSTMCell(\n",
       "      (conv): Conv2d(26, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): ConvLSTMCell(\n",
       "      (conv): Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (2): ConvLSTMCell(\n",
       "      (conv): Conv2d(21, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if resume:\n",
    "    if resume==True:\n",
    "        resume = os.path.join(config[\"dir_checkpoints\"],natsort.natsorted(os.listdir(config[\"dir_checkpoints\"]))[-1])\n",
    "    else:\n",
    "        resume = resume\n",
    "    \n",
    "    print(f'Loading Checkpoint {resume}!')\n",
    "    checkpoint = torch.load(resume,map_location=config[\"device\"])\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    loss = checkpoint['loss']\n",
    "    bestloss = checkpoint['bestloss']\n",
    "    epoch_ = checkpoint['epoch']+1\n",
    "    logstep_ = checkpoint['logstep']\n",
    "else:\n",
    "    epoch_ = 0\n",
    "    logstep_ = 0\n",
    "    bestloss = np.inf\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7125bc",
   "metadata": {},
   "source": [
    "Let's start the training loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "259d1e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "[2023-01-26T17-39-16] Training Step: 1/2370 0.0, \tbatch_size: 6 \tLoss: 0.1289\n",
      "[2023-01-26T17-39-16] Training Step: 2/2370 0.1, \tbatch_size: 6 \tLoss: 0.2031\n",
      "[2023-01-26T17-39-16] Training Step: 3/2370 0.2, \tbatch_size: 6 \tLoss: 0.2088\n",
      "[2023-01-26T17-39-17] Training Step: 4/2370 0.3, \tbatch_size: 6 \tLoss: 0.3447\n",
      "[2023-01-26T17-39-17] Training Step: 5/2370 0.4, \tbatch_size: 6 \tLoss: 0.2457\n",
      "[2023-01-26T17-39-18] Training Step: 6/2370 0.5, \tbatch_size: 6 \tLoss: 0.3078\n",
      "[2023-01-26T17-39-19] Training Step: 7/2370 0.6, \tbatch_size: 6 \tLoss: 0.3059\n",
      "[2023-01-26T17-39-19] Training Step: 8/2370 0.7, \tbatch_size: 6 \tLoss: 0.3067\n",
      "[2023-01-26T17-39-20] Training Step: 9/2370 0.8, \tbatch_size: 6 \tLoss: 0.3130\n",
      "[2023-01-26T17-39-20] Training Step: 10/2370 0.9, \tbatch_size: 6 \tLoss: 0.3389\n",
      "[2023-01-26T17-39-21] Training Step: 11/2370 0.10, \tbatch_size: 6 \tLoss: 0.3953\n",
      "[2023-01-26T17-39-21] Training Step: 12/2370 0.11, \tbatch_size: 6 \tLoss: 0.2961\n",
      "[2023-01-26T17-39-21] Training Step: 13/2370 0.12, \tbatch_size: 6 \tLoss: 0.3546\n",
      "[2023-01-26T17-39-22] Training Step: 14/2370 0.13, \tbatch_size: 6 \tLoss: 0.2906\n",
      "[2023-01-26T17-39-22] Training Step: 15/2370 0.14, \tbatch_size: 6 \tLoss: 0.2993\n",
      "[2023-01-26T17-39-23] Training Step: 16/2370 0.15, \tbatch_size: 6 \tLoss: 0.3029\n",
      "[2023-01-26T17-39-23] Training Step: 17/2370 0.16, \tbatch_size: 6 \tLoss: 0.4477\n",
      "[2023-01-26T17-39-23] Training Step: 18/2370 0.17, \tbatch_size: 6 \tLoss: 0.2850\n",
      "[2023-01-26T17-39-24] Training Step: 19/2370 0.18, \tbatch_size: 6 \tLoss: 0.3380\n",
      "[2023-01-26T17-39-24] Training Step: 20/2370 0.19, \tbatch_size: 6 \tLoss: 0.3548\n",
      "[2023-01-26T17-39-25] Training Step: 21/2370 0.20, \tbatch_size: 6 \tLoss: 0.2246\n",
      "[2023-01-26T17-39-25] Training Step: 22/2370 0.21, \tbatch_size: 6 \tLoss: 0.2449\n",
      "[2023-01-26T17-39-25] Training Step: 23/2370 0.22, \tbatch_size: 6 \tLoss: 0.2808\n",
      "[2023-01-26T17-39-26] Training Step: 24/2370 0.23, \tbatch_size: 6 \tLoss: 0.4067\n",
      "[2023-01-26T17-39-26] Training Step: 25/2370 0.24, \tbatch_size: 6 \tLoss: 0.2217\n",
      "[2023-01-26T17-39-27] Training Step: 26/2370 0.25, \tbatch_size: 6 \tLoss: 0.4816\n",
      "[2023-01-26T17-39-28] Training Step: 27/2370 0.26, \tbatch_size: 6 \tLoss: 0.1985\n",
      "[2023-01-26T17-39-28] Training Step: 28/2370 0.27, \tbatch_size: 6 \tLoss: 0.2389\n",
      "[2023-01-26T17-39-28] Training Step: 29/2370 0.28, \tbatch_size: 6 \tLoss: 0.2590\n",
      "[2023-01-26T17-39-29] Training Step: 30/2370 0.29, \tbatch_size: 6 \tLoss: 0.3679\n",
      "[2023-01-26T17-39-29] Training Step: 31/2370 0.30, \tbatch_size: 6 \tLoss: 0.3555\n",
      "[2023-01-26T17-39-30] Training Step: 32/2370 0.31, \tbatch_size: 6 \tLoss: 0.3624\n",
      "[2023-01-26T17-39-30] Training Step: 33/2370 0.32, \tbatch_size: 6 \tLoss: 0.3968\n",
      "[2023-01-26T17-39-30] Training Step: 34/2370 0.33, \tbatch_size: 6 \tLoss: 0.2660\n",
      "[2023-01-26T17-39-31] Training Step: 35/2370 0.34, \tbatch_size: 6 \tLoss: 0.3285\n",
      "[2023-01-26T17-39-31] Training Step: 36/2370 0.35, \tbatch_size: 6 \tLoss: 0.3482\n",
      "[2023-01-26T17-39-31] Training Step: 37/2370 0.36, \tbatch_size: 6 \tLoss: 0.2617\n",
      "[2023-01-26T17-39-32] Training Step: 38/2370 0.37, \tbatch_size: 6 \tLoss: 0.3203\n",
      "[2023-01-26T17-39-32] Training Step: 39/2370 0.38, \tbatch_size: 6 \tLoss: 0.3846\n",
      "[2023-01-26T17-39-33] Training Step: 40/2370 0.39, \tbatch_size: 6 \tLoss: 0.2087\n",
      "[2023-01-26T17-39-33] Training Step: 41/2370 0.40, \tbatch_size: 6 \tLoss: 0.2080\n",
      "[2023-01-26T17-39-34] Training Step: 42/2370 0.41, \tbatch_size: 6 \tLoss: 0.2796\n",
      "[2023-01-26T17-39-34] Training Step: 43/2370 0.42, \tbatch_size: 6 \tLoss: 0.2185\n",
      "[2023-01-26T17-39-35] Training Step: 44/2370 0.43, \tbatch_size: 6 \tLoss: 0.2867\n",
      "[2023-01-26T17-39-35] Training Step: 45/2370 0.44, \tbatch_size: 6 \tLoss: 0.3468\n",
      "[2023-01-26T17-39-36] Training Step: 46/2370 0.45, \tbatch_size: 6 \tLoss: 0.2965\n",
      "[2023-01-26T17-39-36] Training Step: 47/2370 0.46, \tbatch_size: 6 \tLoss: 0.3621\n",
      "[2023-01-26T17-39-36] Training Step: 48/2370 0.47, \tbatch_size: 6 \tLoss: 0.3077\n",
      "[2023-01-26T17-39-37] Training Step: 49/2370 0.48, \tbatch_size: 6 \tLoss: 0.3413\n",
      "[2023-01-26T17-39-37] Training Step: 50/2370 0.49, \tbatch_size: 6 \tLoss: 0.3193\n",
      "[2023-01-26T17-39-38] Training Step: 51/2370 0.50, \tbatch_size: 6 \tLoss: 0.3730\n",
      "[2023-01-26T17-39-38] Training Step: 52/2370 0.51, \tbatch_size: 6 \tLoss: 0.3247\n",
      "[2023-01-26T17-39-38] Training Step: 53/2370 0.52, \tbatch_size: 6 \tLoss: 0.2096\n",
      "[2023-01-26T17-39-39] Training Step: 54/2370 0.53, \tbatch_size: 6 \tLoss: 0.3064\n",
      "[2023-01-26T17-39-39] Training Step: 55/2370 0.54, \tbatch_size: 6 \tLoss: 0.3353\n",
      "[2023-01-26T17-39-39] Training Step: 56/2370 0.55, \tbatch_size: 6 \tLoss: 0.2863\n",
      "[2023-01-26T17-39-40] Training Step: 57/2370 0.56, \tbatch_size: 6 \tLoss: 0.3311\n",
      "[2023-01-26T17-39-40] Training Step: 58/2370 0.57, \tbatch_size: 6 \tLoss: 0.2705\n",
      "[2023-01-26T17-39-41] Training Step: 59/2370 0.58, \tbatch_size: 6 \tLoss: 0.3288\n",
      "[2023-01-26T17-39-42] Training Step: 60/2370 0.59, \tbatch_size: 6 \tLoss: 0.1965\n",
      "[2023-01-26T17-39-42] Training Step: 61/2370 0.60, \tbatch_size: 6 \tLoss: 0.2727\n",
      "[2023-01-26T17-39-42] Training Step: 62/2370 0.61, \tbatch_size: 6 \tLoss: 0.3256\n",
      "[2023-01-26T17-39-43] Training Step: 63/2370 0.62, \tbatch_size: 6 \tLoss: 0.1998\n",
      "[2023-01-26T17-39-43] Training Step: 64/2370 0.63, \tbatch_size: 6 \tLoss: 0.2583\n",
      "[2023-01-26T17-39-44] Training Step: 65/2370 0.64, \tbatch_size: 6 \tLoss: 0.2826\n",
      "[2023-01-26T17-39-44] Training Step: 66/2370 0.65, \tbatch_size: 6 \tLoss: 0.1733\n",
      "[2023-01-26T17-39-44] Training Step: 67/2370 0.66, \tbatch_size: 6 \tLoss: 0.1322\n",
      "[2023-01-26T17-39-45] Training Step: 68/2370 0.67, \tbatch_size: 6 \tLoss: 0.1849\n",
      "[2023-01-26T17-39-45] Training Step: 69/2370 0.68, \tbatch_size: 6 \tLoss: 0.1045\n",
      "[2023-01-26T17-39-46] Training Step: 70/2370 0.69, \tbatch_size: 6 \tLoss: 0.2388\n",
      "[2023-01-26T17-39-46] Training Step: 71/2370 0.70, \tbatch_size: 6 \tLoss: 0.2029\n",
      "[2023-01-26T17-39-46] Training Step: 72/2370 0.71, \tbatch_size: 6 \tLoss: 0.1590\n",
      "[2023-01-26T17-39-47] Training Step: 73/2370 0.72, \tbatch_size: 6 \tLoss: 0.1442\n",
      "[2023-01-26T17-39-47] Training Step: 74/2370 0.73, \tbatch_size: 6 \tLoss: 0.1679\n",
      "[2023-01-26T17-39-48] Training Step: 75/2370 0.74, \tbatch_size: 6 \tLoss: 0.1323\n",
      "[2023-01-26T17-39-49] Training Step: 76/2370 0.75, \tbatch_size: 6 \tLoss: 0.1277\n",
      "[2023-01-26T17-39-49] Training Step: 77/2370 0.76, \tbatch_size: 6 \tLoss: 0.1221\n",
      "[2023-01-26T17-39-49] Training Step: 78/2370 0.77, \tbatch_size: 6 \tLoss: 0.1333\n",
      "[2023-01-26T17-39-50] Training Step: 79/2370 0.78, \tbatch_size: 6 \tLoss: 0.1102\n",
      "[2023-01-26T17-39-50] Training Step: 80/2370 0.79, \tbatch_size: 6 \tLoss: 0.1114\n",
      "[2023-01-26T17-39-51] Training Step: 81/2370 0.80, \tbatch_size: 6 \tLoss: 0.0841\n",
      "[2023-01-26T17-39-51] Training Step: 82/2370 0.81, \tbatch_size: 6 \tLoss: 0.0641\n",
      "[2023-01-26T17-39-51] Training Step: 83/2370 0.82, \tbatch_size: 6 \tLoss: 0.0964\n",
      "[2023-01-26T17-39-52] Training Step: 84/2370 0.83, \tbatch_size: 6 \tLoss: 0.0953\n",
      "[2023-01-26T17-39-52] Training Step: 85/2370 0.84, \tbatch_size: 6 \tLoss: 0.0681\n",
      "[2023-01-26T17-39-53] Training Step: 86/2370 0.85, \tbatch_size: 6 \tLoss: 0.0791\n",
      "[2023-01-26T17-39-53] Training Step: 87/2370 0.86, \tbatch_size: 6 \tLoss: 0.0760\n",
      "[2023-01-26T17-39-53] Training Step: 88/2370 0.87, \tbatch_size: 6 \tLoss: 0.0452\n",
      "[2023-01-26T17-39-54] Training Step: 89/2370 0.88, \tbatch_size: 6 \tLoss: 0.0713\n",
      "[2023-01-26T17-39-54] Training Step: 90/2370 0.89, \tbatch_size: 6 \tLoss: 0.0561\n",
      "[2023-01-26T17-39-55] Training Step: 91/2370 0.90, \tbatch_size: 6 \tLoss: 0.1408\n",
      "[2023-01-26T17-39-56] Training Step: 92/2370 0.91, \tbatch_size: 6 \tLoss: 0.0628\n",
      "[2023-01-26T17-39-56] Training Step: 93/2370 0.92, \tbatch_size: 6 \tLoss: 0.0792\n",
      "[2023-01-26T17-39-56] Training Step: 94/2370 0.93, \tbatch_size: 6 \tLoss: 0.0884\n",
      "[2023-01-26T17-39-57] Training Step: 95/2370 0.94, \tbatch_size: 6 \tLoss: 0.0597\n",
      "[2023-01-26T17-39-57] Training Step: 96/2370 0.95, \tbatch_size: 6 \tLoss: 0.0940\n",
      "[2023-01-26T17-39-58] Training Step: 97/2370 0.96, \tbatch_size: 6 \tLoss: 0.1267\n",
      "[2023-01-26T17-39-58] Training Step: 98/2370 0.97, \tbatch_size: 6 \tLoss: 0.0881\n",
      "[2023-01-26T17-39-58] Training Step: 99/2370 0.98, \tbatch_size: 6 \tLoss: 0.0614\n",
      "[2023-01-26T17-39-59] Training Step: 100/2370 0.99, \tbatch_size: 6 \tLoss: 0.0886\n",
      "[2023-01-26T17-39-59] Training Step: 101/2370 0.100, \tbatch_size: 6 \tLoss: 0.1004\n",
      "[2023-01-26T17-39-59] Training Step: 102/2370 0.101, \tbatch_size: 6 \tLoss: 0.1098\n",
      "[2023-01-26T17-40-00] Training Step: 103/2370 0.102, \tbatch_size: 6 \tLoss: 0.0941\n",
      "[2023-01-26T17-40-00] Training Step: 104/2370 0.103, \tbatch_size: 6 \tLoss: 0.0491\n",
      "[2023-01-26T17-40-01] Training Step: 105/2370 0.104, \tbatch_size: 6 \tLoss: 0.1157\n",
      "[2023-01-26T17-40-01] Training Step: 106/2370 0.105, \tbatch_size: 6 \tLoss: 0.0818\n",
      "[2023-01-26T17-40-02] Training Step: 107/2370 0.106, \tbatch_size: 6 \tLoss: 0.0773\n",
      "[2023-01-26T17-40-02] Training Step: 108/2370 0.107, \tbatch_size: 6 \tLoss: 0.1322\n",
      "[2023-01-26T17-40-03] Training Step: 109/2370 0.108, \tbatch_size: 6 \tLoss: 0.1105\n",
      "[2023-01-26T17-40-03] Training Step: 110/2370 0.109, \tbatch_size: 6 \tLoss: 0.1538\n",
      "[2023-01-26T17-40-04] Training Step: 111/2370 0.110, \tbatch_size: 6 \tLoss: 0.1236\n",
      "[2023-01-26T17-40-04] Training Step: 112/2370 0.111, \tbatch_size: 6 \tLoss: 0.0750\n",
      "[2023-01-26T17-40-04] Training Step: 113/2370 0.112, \tbatch_size: 6 \tLoss: 0.0773\n",
      "[2023-01-26T17-40-05] Training Step: 114/2370 0.113, \tbatch_size: 6 \tLoss: 0.0684\n",
      "[2023-01-26T17-40-05] Training Step: 115/2370 0.114, \tbatch_size: 6 \tLoss: 0.1380\n",
      "[2023-01-26T17-40-06] Training Step: 116/2370 0.115, \tbatch_size: 6 \tLoss: 0.0776\n",
      "[2023-01-26T17-40-06] Training Step: 117/2370 0.116, \tbatch_size: 6 \tLoss: 0.0663\n",
      "[2023-01-26T17-40-06] Training Step: 118/2370 0.117, \tbatch_size: 6 \tLoss: 0.0702\n",
      "[2023-01-26T17-40-07] Training Step: 119/2370 0.118, \tbatch_size: 6 \tLoss: 0.0723\n",
      "[2023-01-26T17-40-07] Training Step: 120/2370 0.119, \tbatch_size: 6 \tLoss: 0.0802\n",
      "[2023-01-26T17-40-08] Training Step: 121/2370 0.120, \tbatch_size: 6 \tLoss: 0.0399\n",
      "[2023-01-26T17-40-08] Training Step: 122/2370 0.121, \tbatch_size: 6 \tLoss: 0.0505\n",
      "[2023-01-26T17-40-09] Training Step: 123/2370 0.122, \tbatch_size: 6 \tLoss: 0.0751\n",
      "[2023-01-26T17-40-09] Training Step: 124/2370 0.123, \tbatch_size: 6 \tLoss: 0.1570\n",
      "[2023-01-26T17-40-10] Training Step: 125/2370 0.124, \tbatch_size: 6 \tLoss: 0.0575\n",
      "[2023-01-26T17-40-10] Training Step: 126/2370 0.125, \tbatch_size: 6 \tLoss: 0.0783\n",
      "[2023-01-26T17-40-10] Training Step: 127/2370 0.126, \tbatch_size: 6 \tLoss: 0.0676\n",
      "[2023-01-26T17-40-11] Training Step: 128/2370 0.127, \tbatch_size: 6 \tLoss: 0.0733\n",
      "[2023-01-26T17-40-11] Training Step: 129/2370 0.128, \tbatch_size: 6 \tLoss: 0.1579\n",
      "[2023-01-26T17-40-12] Training Step: 130/2370 0.129, \tbatch_size: 6 \tLoss: 0.0653\n",
      "[2023-01-26T17-40-12] Training Step: 131/2370 0.130, \tbatch_size: 6 \tLoss: 0.0582\n",
      "[2023-01-26T17-40-12] Training Step: 132/2370 0.131, \tbatch_size: 6 \tLoss: 0.0719\n",
      "[2023-01-26T17-40-13] Training Step: 133/2370 0.132, \tbatch_size: 6 \tLoss: 0.0923\n",
      "[2023-01-26T17-40-13] Training Step: 134/2370 0.133, \tbatch_size: 6 \tLoss: 0.1469\n",
      "[2023-01-26T17-40-14] Training Step: 135/2370 0.134, \tbatch_size: 6 \tLoss: 0.0745\n",
      "[2023-01-26T17-40-14] Training Step: 136/2370 0.135, \tbatch_size: 6 \tLoss: 0.0892\n",
      "[2023-01-26T17-40-14] Training Step: 137/2370 0.136, \tbatch_size: 6 \tLoss: 0.1022\n",
      "[2023-01-26T17-40-15] Training Step: 138/2370 0.137, \tbatch_size: 6 \tLoss: 0.1204\n",
      "[2023-01-26T17-40-16] Training Step: 139/2370 0.138, \tbatch_size: 6 \tLoss: 0.0665\n",
      "[2023-01-26T17-40-16] Training Step: 140/2370 0.139, \tbatch_size: 6 \tLoss: 0.0439\n",
      "[2023-01-26T17-40-17] Training Step: 141/2370 0.140, \tbatch_size: 6 \tLoss: 0.1125\n",
      "[2023-01-26T17-40-17] Training Step: 142/2370 0.141, \tbatch_size: 6 \tLoss: 0.0941\n",
      "[2023-01-26T17-40-17] Training Step: 143/2370 0.142, \tbatch_size: 6 \tLoss: 0.0888\n",
      "[2023-01-26T17-40-18] Training Step: 144/2370 0.143, \tbatch_size: 6 \tLoss: 0.1168\n",
      "[2023-01-26T17-40-18] Training Step: 145/2370 0.144, \tbatch_size: 6 \tLoss: 0.0896\n",
      "[2023-01-26T17-40-19] Training Step: 146/2370 0.145, \tbatch_size: 6 \tLoss: 0.0620\n",
      "[2023-01-26T17-40-19] Training Step: 147/2370 0.146, \tbatch_size: 6 \tLoss: 0.0780\n",
      "[2023-01-26T17-40-19] Training Step: 148/2370 0.147, \tbatch_size: 6 \tLoss: 0.0864\n",
      "[2023-01-26T17-40-20] Training Step: 149/2370 0.148, \tbatch_size: 6 \tLoss: 0.1002\n",
      "[2023-01-26T17-40-20] Training Step: 150/2370 0.149, \tbatch_size: 6 \tLoss: 0.0607\n",
      "[2023-01-26T17-40-20] Training Step: 151/2370 0.150, \tbatch_size: 6 \tLoss: 0.0698\n",
      "[2023-01-26T17-40-21] Training Step: 152/2370 0.151, \tbatch_size: 6 \tLoss: 0.0808\n",
      "[2023-01-26T17-40-21] Training Step: 153/2370 0.152, \tbatch_size: 6 \tLoss: 0.0897\n",
      "[2023-01-26T17-40-22] Training Step: 154/2370 0.153, \tbatch_size: 6 \tLoss: 0.0849\n",
      "[2023-01-26T17-40-22] Training Step: 155/2370 0.154, \tbatch_size: 6 \tLoss: 0.0740\n",
      "[2023-01-26T17-40-23] Training Step: 156/2370 0.155, \tbatch_size: 6 \tLoss: 0.0810\n",
      "[2023-01-26T17-40-23] Training Step: 157/2370 0.156, \tbatch_size: 6 \tLoss: 0.1355\n",
      "[2023-01-26T17-40-24] Training Step: 158/2370 0.157, \tbatch_size: 6 \tLoss: 0.0663\n",
      "[2023-01-26T17-40-24] Training Step: 159/2370 0.158, \tbatch_size: 6 \tLoss: 0.0876\n",
      "[2023-01-26T17-40-25] Training Step: 160/2370 0.159, \tbatch_size: 6 \tLoss: 0.1014\n",
      "[2023-01-26T17-40-25] Training Step: 161/2370 0.160, \tbatch_size: 6 \tLoss: 0.0670\n",
      "[2023-01-26T17-40-25] Training Step: 162/2370 0.161, \tbatch_size: 6 \tLoss: 0.0706\n",
      "[2023-01-26T17-40-26] Training Step: 163/2370 0.162, \tbatch_size: 6 \tLoss: 0.0688\n",
      "[2023-01-26T17-40-26] Training Step: 164/2370 0.163, \tbatch_size: 6 \tLoss: 0.1223\n",
      "[2023-01-26T17-40-26] Training Step: 165/2370 0.164, \tbatch_size: 6 \tLoss: 0.0611\n",
      "[2023-01-26T17-40-27] Training Step: 166/2370 0.165, \tbatch_size: 6 \tLoss: 0.0654\n",
      "[2023-01-26T17-40-27] Training Step: 167/2370 0.166, \tbatch_size: 6 \tLoss: 0.0841\n",
      "[2023-01-26T17-40-28] Training Step: 168/2370 0.167, \tbatch_size: 6 \tLoss: 0.0586\n",
      "[2023-01-26T17-40-28] Training Step: 169/2370 0.168, \tbatch_size: 6 \tLoss: 0.1174\n",
      "[2023-01-26T17-40-28] Training Step: 170/2370 0.169, \tbatch_size: 6 \tLoss: 0.0905\n",
      "[2023-01-26T17-40-29] Training Step: 171/2370 0.170, \tbatch_size: 6 \tLoss: 0.0796\n",
      "[2023-01-26T17-40-29] Training Step: 172/2370 0.171, \tbatch_size: 6 \tLoss: 0.1052\n",
      "[2023-01-26T17-40-30] Training Step: 173/2370 0.172, \tbatch_size: 6 \tLoss: 0.0703\n",
      "[2023-01-26T17-40-31] Training Step: 174/2370 0.173, \tbatch_size: 6 \tLoss: 0.0748\n",
      "[2023-01-26T17-40-31] Training Step: 175/2370 0.174, \tbatch_size: 6 \tLoss: 0.0663\n",
      "[2023-01-26T17-40-31] Training Step: 176/2370 0.175, \tbatch_size: 6 \tLoss: 0.0652\n",
      "[2023-01-26T17-40-32] Training Step: 177/2370 0.176, \tbatch_size: 6 \tLoss: 0.1359\n",
      "[2023-01-26T17-40-32] Training Step: 178/2370 0.177, \tbatch_size: 6 \tLoss: 0.0437\n",
      "[2023-01-26T17-40-33] Training Step: 179/2370 0.178, \tbatch_size: 6 \tLoss: 0.0441\n",
      "[2023-01-26T17-40-33] Training Step: 180/2370 0.179, \tbatch_size: 6 \tLoss: 0.0819\n",
      "[2023-01-26T17-40-33] Training Step: 181/2370 0.180, \tbatch_size: 6 \tLoss: 0.0780\n",
      "[2023-01-26T17-40-34] Training Step: 182/2370 0.181, \tbatch_size: 6 \tLoss: 0.0687\n",
      "[2023-01-26T17-40-34] Training Step: 183/2370 0.182, \tbatch_size: 6 \tLoss: 0.0607\n",
      "[2023-01-26T17-40-34] Training Step: 184/2370 0.183, \tbatch_size: 6 \tLoss: 0.0499\n",
      "[2023-01-26T17-40-35] Training Step: 185/2370 0.184, \tbatch_size: 6 \tLoss: 0.0829\n",
      "[2023-01-26T17-40-35] Training Step: 186/2370 0.185, \tbatch_size: 6 \tLoss: 0.1130\n",
      "[2023-01-26T17-40-36] Training Step: 187/2370 0.186, \tbatch_size: 6 \tLoss: 0.0616\n",
      "[2023-01-26T17-40-36] Training Step: 188/2370 0.187, \tbatch_size: 6 \tLoss: 0.0815\n",
      "[2023-01-26T17-40-36] Training Step: 189/2370 0.188, \tbatch_size: 6 \tLoss: 0.0807\n",
      "[2023-01-26T17-40-37] Training Step: 190/2370 0.189, \tbatch_size: 6 \tLoss: 0.0860\n",
      "[2023-01-26T17-40-38] Training Step: 191/2370 0.190, \tbatch_size: 6 \tLoss: 0.1143\n",
      "[2023-01-26T17-40-38] Training Step: 192/2370 0.191, \tbatch_size: 6 \tLoss: 0.0572\n",
      "[2023-01-26T17-40-39] Training Step: 193/2370 0.192, \tbatch_size: 6 \tLoss: 0.0570\n",
      "[2023-01-26T17-40-39] Training Step: 194/2370 0.193, \tbatch_size: 6 \tLoss: 0.0801\n",
      "[2023-01-26T17-40-39] Training Step: 195/2370 0.194, \tbatch_size: 6 \tLoss: 0.0409\n",
      "[2023-01-26T17-40-40] Training Step: 196/2370 0.195, \tbatch_size: 6 \tLoss: 0.1141\n",
      "[2023-01-26T17-40-40] Training Step: 197/2370 0.196, \tbatch_size: 6 \tLoss: 0.0471\n",
      "[2023-01-26T17-40-41] Training Step: 198/2370 0.197, \tbatch_size: 6 \tLoss: 0.0807\n",
      "[2023-01-26T17-40-41] Training Step: 199/2370 0.198, \tbatch_size: 6 \tLoss: 0.0593\n",
      "[2023-01-26T17-40-41] Training Step: 200/2370 0.199, \tbatch_size: 6 \tLoss: 0.0821\n",
      "[2023-01-26T17-40-42] Training Step: 201/2370 0.200, \tbatch_size: 6 \tLoss: 0.1148\n",
      "[2023-01-26T17-40-42] Training Step: 202/2370 0.201, \tbatch_size: 6 \tLoss: 0.0961\n",
      "[2023-01-26T17-40-42] Training Step: 203/2370 0.202, \tbatch_size: 6 \tLoss: 0.1385\n",
      "[2023-01-26T17-40-43] Training Step: 204/2370 0.203, \tbatch_size: 6 \tLoss: 0.0892\n",
      "[2023-01-26T17-40-43] Training Step: 205/2370 0.204, \tbatch_size: 6 \tLoss: 0.1031\n",
      "[2023-01-26T17-40-44] Training Step: 206/2370 0.205, \tbatch_size: 6 \tLoss: 0.0655\n",
      "[2023-01-26T17-40-44] Training Step: 207/2370 0.206, \tbatch_size: 6 \tLoss: 0.0552\n",
      "[2023-01-26T17-40-45] Training Step: 208/2370 0.207, \tbatch_size: 6 \tLoss: 0.0672\n",
      "[2023-01-26T17-40-45] Training Step: 209/2370 0.208, \tbatch_size: 6 \tLoss: 0.0677\n",
      "[2023-01-26T17-40-46] Training Step: 210/2370 0.209, \tbatch_size: 6 \tLoss: 0.1101\n",
      "[2023-01-26T17-40-46] Training Step: 211/2370 0.210, \tbatch_size: 6 \tLoss: 0.0531\n",
      "[2023-01-26T17-40-47] Training Step: 212/2370 0.211, \tbatch_size: 6 \tLoss: 0.0715\n",
      "[2023-01-26T17-40-47] Training Step: 213/2370 0.212, \tbatch_size: 6 \tLoss: 0.0867\n",
      "[2023-01-26T17-40-47] Training Step: 214/2370 0.213, \tbatch_size: 6 \tLoss: 0.0639\n",
      "[2023-01-26T17-40-48] Training Step: 215/2370 0.214, \tbatch_size: 6 \tLoss: 0.0781\n",
      "[2023-01-26T17-40-48] Training Step: 216/2370 0.215, \tbatch_size: 6 \tLoss: 0.0930\n",
      "[2023-01-26T17-40-48] Training Step: 217/2370 0.216, \tbatch_size: 6 \tLoss: 0.1275\n",
      "[2023-01-26T17-40-49] Training Step: 218/2370 0.217, \tbatch_size: 6 \tLoss: 0.0790\n",
      "[2023-01-26T17-40-49] Training Step: 219/2370 0.218, \tbatch_size: 6 \tLoss: 0.0621\n",
      "[2023-01-26T17-40-50] Training Step: 220/2370 0.219, \tbatch_size: 6 \tLoss: 0.0608\n",
      "[2023-01-26T17-40-50] Training Step: 221/2370 0.220, \tbatch_size: 6 \tLoss: 0.1237\n",
      "[2023-01-26T17-40-51] Training Step: 222/2370 0.221, \tbatch_size: 6 \tLoss: 0.0502\n",
      "[2023-01-26T17-40-51] Training Step: 223/2370 0.222, \tbatch_size: 6 \tLoss: 0.0547\n",
      "[2023-01-26T17-40-52] Training Step: 224/2370 0.223, \tbatch_size: 6 \tLoss: 0.0635\n",
      "[2023-01-26T17-40-52] Training Step: 225/2370 0.224, \tbatch_size: 6 \tLoss: 0.0687\n",
      "[2023-01-26T17-40-52] Training Step: 226/2370 0.225, \tbatch_size: 6 \tLoss: 0.0523\n",
      "[2023-01-26T17-40-53] Training Step: 227/2370 0.226, \tbatch_size: 6 \tLoss: 0.0880\n",
      "[2023-01-26T17-40-53] Training Step: 228/2370 0.227, \tbatch_size: 6 \tLoss: 0.1132\n",
      "[2023-01-26T17-40-53] Training Step: 229/2370 0.228, \tbatch_size: 6 \tLoss: 0.1371\n",
      "[2023-01-26T17-40-54] Training Step: 230/2370 0.229, \tbatch_size: 6 \tLoss: 0.0698\n",
      "[2023-01-26T17-40-54] Training Step: 231/2370 0.230, \tbatch_size: 6 \tLoss: 0.0649\n",
      "[2023-01-26T17-40-55] Training Step: 232/2370 0.231, \tbatch_size: 6 \tLoss: 0.0655\n",
      "[2023-01-26T17-40-55] Training Step: 233/2370 0.232, \tbatch_size: 6 \tLoss: 0.0892\n",
      "[2023-01-26T17-40-56] Training Step: 234/2370 0.233, \tbatch_size: 6 \tLoss: 0.0629\n",
      "[2023-01-26T17-40-56] Training Step: 235/2370 0.234, \tbatch_size: 6 \tLoss: 0.0840\n",
      "[2023-01-26T17-40-57] Training Step: 236/2370 0.235, \tbatch_size: 6 \tLoss: 0.0572\n",
      "[2023-01-26T17-40-57] Training Step: 237/2370 0.236, \tbatch_size: 6 \tLoss: 0.0601\n",
      "\n",
      "[2023-01-26T17-41-07] Validation Step: 1/23, \tbatch_size: 12 \tLoss: 0.0817\n",
      "[2023-01-26T17-41-07] Validation Step: 2/23, \tbatch_size: 12 \tLoss: 0.0885\n",
      "[2023-01-26T17-41-08] Validation Step: 3/23, \tbatch_size: 12 \tLoss: 0.0603\n",
      "[2023-01-26T17-41-08] Validation Step: 4/23, \tbatch_size: 12 \tLoss: 0.0836\n",
      "[2023-01-26T17-41-09] Validation Step: 5/23, \tbatch_size: 12 \tLoss: 0.0828\n",
      "[2023-01-26T17-41-09] Validation Step: 6/23, \tbatch_size: 12 \tLoss: 0.0603\n",
      "[2023-01-26T17-41-09] Validation Step: 7/23, \tbatch_size: 12 \tLoss: 0.0745\n",
      "[2023-01-26T17-41-10] Validation Step: 8/23, \tbatch_size: 12 \tLoss: 0.0729\n",
      "[2023-01-26T17-41-10] Validation Step: 9/23, \tbatch_size: 12 \tLoss: 0.0638\n",
      "[2023-01-26T17-41-10] Validation Step: 10/23, \tbatch_size: 12 \tLoss: 0.0887\n",
      "[2023-01-26T17-41-11] Validation Step: 11/23, \tbatch_size: 12 \tLoss: 0.0722\n",
      "[2023-01-26T17-41-11] Validation Step: 12/23, \tbatch_size: 12 \tLoss: 0.0581\n",
      "[2023-01-26T17-41-13] Validation Step: 13/23, \tbatch_size: 12 \tLoss: 0.0678\n",
      "[2023-01-26T17-41-13] Validation Step: 14/23, \tbatch_size: 12 \tLoss: 0.0714\n",
      "[2023-01-26T17-41-13] Validation Step: 15/23, \tbatch_size: 12 \tLoss: 0.0893\n",
      "[2023-01-26T17-41-14] Validation Step: 16/23, \tbatch_size: 12 \tLoss: 0.0667\n",
      "[2023-01-26T17-41-14] Validation Step: 17/23, \tbatch_size: 12 \tLoss: 0.0767\n",
      "[2023-01-26T17-41-14] Validation Step: 18/23, \tbatch_size: 12 \tLoss: 0.0706\n",
      "[2023-01-26T17-41-14] Validation Step: 19/23, \tbatch_size: 12 \tLoss: 0.0720\n",
      "[2023-01-26T17-41-14] Validation Step: 20/23, \tbatch_size: 12 \tLoss: 0.0694\n",
      "[2023-01-26T17-41-14] Validation Step: 21/23, \tbatch_size: 12 \tLoss: 0.0741\n",
      "[2023-01-26T17-41-15] Validation Step: 22/23, \tbatch_size: 12 \tLoss: 0.0686\n",
      "[2023-01-26T17-41-15] Validation Step: 23/23, \tbatch_size: 12 \tLoss: 0.0766\n",
      "[2023-01-26T17-41-15] Validation: \tTotal Loss: 0.0735\n",
      "\n",
      "New best validation loss! Storing checkpoint and model!\n",
      "saveME_checkpoint: start saving checkpoint!\n",
      "saveME_checkpoint: saved\n",
      "saveME_torch: start saving of the model for later inference only!\n",
      "saveME_torch: saved\n",
      "saveME_torch: start saving of the entire model!\n",
      "saveME_torch: saved\n",
      "[2023-01-26T17-41-36] Training Step: 238/2370 1.0, \tbatch_size: 6 \tLoss: 0.0641\n",
      "[2023-01-26T17-41-36] Training Step: 239/2370 1.1, \tbatch_size: 6 \tLoss: 0.0716\n",
      "[2023-01-26T17-41-37] Training Step: 240/2370 1.2, \tbatch_size: 6 \tLoss: 0.0792\n",
      "[2023-01-26T17-41-37] Training Step: 241/2370 1.3, \tbatch_size: 6 \tLoss: 0.0920\n",
      "[2023-01-26T17-41-38] Training Step: 242/2370 1.4, \tbatch_size: 6 \tLoss: 0.0712\n",
      "[2023-01-26T17-41-38] Training Step: 243/2370 1.5, \tbatch_size: 6 \tLoss: 0.0839\n",
      "[2023-01-26T17-41-39] Training Step: 244/2370 1.6, \tbatch_size: 6 \tLoss: 0.0986\n",
      "[2023-01-26T17-41-39] Training Step: 245/2370 1.7, \tbatch_size: 6 \tLoss: 0.0504\n",
      "[2023-01-26T17-41-39] Training Step: 246/2370 1.8, \tbatch_size: 6 \tLoss: 0.0829\n",
      "[2023-01-26T17-41-40] Training Step: 247/2370 1.9, \tbatch_size: 6 \tLoss: 0.0902\n",
      "[2023-01-26T17-41-40] Training Step: 248/2370 1.10, \tbatch_size: 6 \tLoss: 0.0633\n",
      "[2023-01-26T17-41-41] Training Step: 249/2370 1.11, \tbatch_size: 6 \tLoss: 0.1154\n",
      "[2023-01-26T17-41-41] Training Step: 250/2370 1.12, \tbatch_size: 6 \tLoss: 0.0668\n",
      "[2023-01-26T17-41-41] Training Step: 251/2370 1.13, \tbatch_size: 6 \tLoss: 0.0820\n",
      "[2023-01-26T17-41-42] Training Step: 252/2370 1.14, \tbatch_size: 6 \tLoss: 0.0679\n",
      "[2023-01-26T17-41-42] Training Step: 253/2370 1.15, \tbatch_size: 6 \tLoss: 0.0601\n",
      "[2023-01-26T17-41-43] Training Step: 254/2370 1.16, \tbatch_size: 6 \tLoss: 0.0703\n",
      "[2023-01-26T17-41-43] Training Step: 255/2370 1.17, \tbatch_size: 6 \tLoss: 0.0780\n",
      "[2023-01-26T17-41-44] Training Step: 256/2370 1.18, \tbatch_size: 6 \tLoss: 0.0665\n",
      "[2023-01-26T17-41-44] Training Step: 257/2370 1.19, \tbatch_size: 6 \tLoss: 0.0692\n",
      "[2023-01-26T17-41-45] Training Step: 258/2370 1.20, \tbatch_size: 6 \tLoss: 0.0799\n",
      "[2023-01-26T17-41-45] Training Step: 259/2370 1.21, \tbatch_size: 6 \tLoss: 0.0738\n",
      "[2023-01-26T17-41-45] Training Step: 260/2370 1.22, \tbatch_size: 6 \tLoss: 0.0966\n",
      "[2023-01-26T17-41-46] Training Step: 261/2370 1.23, \tbatch_size: 6 \tLoss: 0.0675\n",
      "[2023-01-26T17-41-46] Training Step: 262/2370 1.24, \tbatch_size: 6 \tLoss: 0.0891\n",
      "[2023-01-26T17-41-47] Training Step: 263/2370 1.25, \tbatch_size: 6 \tLoss: 0.0691\n",
      "[2023-01-26T17-41-47] Training Step: 264/2370 1.26, \tbatch_size: 6 \tLoss: 0.0706\n",
      "[2023-01-26T17-41-47] Training Step: 265/2370 1.27, \tbatch_size: 6 \tLoss: 0.0739\n",
      "[2023-01-26T17-41-48] Training Step: 266/2370 1.28, \tbatch_size: 6 \tLoss: 0.1042\n",
      "[2023-01-26T17-41-48] Training Step: 267/2370 1.29, \tbatch_size: 6 \tLoss: 0.0806\n",
      "[2023-01-26T17-41-49] Training Step: 268/2370 1.30, \tbatch_size: 6 \tLoss: 0.1190\n",
      "[2023-01-26T17-41-49] Training Step: 269/2370 1.31, \tbatch_size: 6 \tLoss: 0.0825\n",
      "[2023-01-26T17-41-49] Training Step: 270/2370 1.32, \tbatch_size: 6 \tLoss: 0.0756\n",
      "[2023-01-26T17-41-50] Training Step: 271/2370 1.33, \tbatch_size: 6 \tLoss: 0.0640\n",
      "[2023-01-26T17-41-50] Training Step: 272/2370 1.34, \tbatch_size: 6 \tLoss: 0.0654\n",
      "[2023-01-26T17-41-51] Training Step: 273/2370 1.35, \tbatch_size: 6 \tLoss: 0.0435\n",
      "[2023-01-26T17-41-51] Training Step: 274/2370 1.36, \tbatch_size: 6 \tLoss: 0.1071\n",
      "[2023-01-26T17-41-52] Training Step: 275/2370 1.37, \tbatch_size: 6 \tLoss: 0.1200\n",
      "[2023-01-26T17-41-52] Training Step: 276/2370 1.38, \tbatch_size: 6 \tLoss: 0.0574\n",
      "[2023-01-26T17-41-53] Training Step: 277/2370 1.39, \tbatch_size: 6 \tLoss: 0.0696\n",
      "[2023-01-26T17-41-53] Training Step: 278/2370 1.40, \tbatch_size: 6 \tLoss: 0.0590\n",
      "[2023-01-26T17-41-53] Training Step: 279/2370 1.41, \tbatch_size: 6 \tLoss: 0.0891\n",
      "[2023-01-26T17-41-54] Training Step: 280/2370 1.42, \tbatch_size: 6 \tLoss: 0.0763\n",
      "[2023-01-26T17-41-54] Training Step: 281/2370 1.43, \tbatch_size: 6 \tLoss: 0.0812\n",
      "[2023-01-26T17-41-55] Training Step: 282/2370 1.44, \tbatch_size: 6 \tLoss: 0.0562\n",
      "[2023-01-26T17-41-55] Training Step: 283/2370 1.45, \tbatch_size: 6 \tLoss: 0.0618\n",
      "[2023-01-26T17-41-55] Training Step: 284/2370 1.46, \tbatch_size: 6 \tLoss: 0.0808\n",
      "[2023-01-26T17-41-56] Training Step: 285/2370 1.47, \tbatch_size: 6 \tLoss: 0.1014\n",
      "[2023-01-26T17-41-56] Training Step: 286/2370 1.48, \tbatch_size: 6 \tLoss: 0.0565\n",
      "[2023-01-26T17-41-56] Training Step: 287/2370 1.49, \tbatch_size: 6 \tLoss: 0.0563\n",
      "[2023-01-26T17-41-57] Training Step: 288/2370 1.50, \tbatch_size: 6 \tLoss: 0.0997\n",
      "[2023-01-26T17-41-57] Training Step: 289/2370 1.51, \tbatch_size: 6 \tLoss: 0.1013\n",
      "[2023-01-26T17-41-58] Training Step: 290/2370 1.52, \tbatch_size: 6 \tLoss: 0.0635\n",
      "[2023-01-26T17-41-59] Training Step: 291/2370 1.53, \tbatch_size: 6 \tLoss: 0.0612\n",
      "[2023-01-26T17-41-59] Training Step: 292/2370 1.54, \tbatch_size: 6 \tLoss: 0.1282\n",
      "[2023-01-26T17-41-59] Training Step: 293/2370 1.55, \tbatch_size: 6 \tLoss: 0.0455\n",
      "[2023-01-26T17-42-00] Training Step: 294/2370 1.56, \tbatch_size: 6 \tLoss: 0.0743\n",
      "[2023-01-26T17-42-00] Training Step: 295/2370 1.57, \tbatch_size: 6 \tLoss: 0.0841\n",
      "[2023-01-26T17-42-01] Training Step: 296/2370 1.58, \tbatch_size: 6 \tLoss: 0.0681\n",
      "[2023-01-26T17-42-01] Training Step: 297/2370 1.59, \tbatch_size: 6 \tLoss: 0.0374\n",
      "[2023-01-26T17-42-01] Training Step: 298/2370 1.60, \tbatch_size: 6 \tLoss: 0.0697\n",
      "[2023-01-26T17-42-02] Training Step: 299/2370 1.61, \tbatch_size: 6 \tLoss: 0.0685\n",
      "[2023-01-26T17-42-02] Training Step: 300/2370 1.62, \tbatch_size: 6 \tLoss: 0.0420\n",
      "[2023-01-26T17-42-02] Training Step: 301/2370 1.63, \tbatch_size: 6 \tLoss: 0.0926\n",
      "[2023-01-26T17-42-03] Training Step: 302/2370 1.64, \tbatch_size: 6 \tLoss: 0.0702\n",
      "[2023-01-26T17-42-03] Training Step: 303/2370 1.65, \tbatch_size: 6 \tLoss: 0.0697\n",
      "[2023-01-26T17-42-04] Training Step: 304/2370 1.66, \tbatch_size: 6 \tLoss: 0.0861\n",
      "[2023-01-26T17-42-04] Training Step: 305/2370 1.67, \tbatch_size: 6 \tLoss: 0.0783\n",
      "[2023-01-26T17-42-04] Training Step: 306/2370 1.68, \tbatch_size: 6 \tLoss: 0.1228\n",
      "[2023-01-26T17-42-05] Training Step: 307/2370 1.69, \tbatch_size: 6 \tLoss: 0.1022\n",
      "[2023-01-26T17-42-06] Training Step: 308/2370 1.70, \tbatch_size: 6 \tLoss: 0.0608\n",
      "[2023-01-26T17-42-06] Training Step: 309/2370 1.71, \tbatch_size: 6 \tLoss: 0.0491\n",
      "[2023-01-26T17-42-07] Training Step: 310/2370 1.72, \tbatch_size: 6 \tLoss: 0.1424\n",
      "[2023-01-26T17-42-07] Training Step: 311/2370 1.73, \tbatch_size: 6 \tLoss: 0.0800\n",
      "[2023-01-26T17-42-07] Training Step: 312/2370 1.74, \tbatch_size: 6 \tLoss: 0.1366\n",
      "[2023-01-26T17-42-08] Training Step: 313/2370 1.75, \tbatch_size: 6 \tLoss: 0.1516\n",
      "[2023-01-26T17-42-08] Training Step: 314/2370 1.76, \tbatch_size: 6 \tLoss: 0.1075\n",
      "[2023-01-26T17-42-08] Training Step: 315/2370 1.77, \tbatch_size: 6 \tLoss: 0.0668\n",
      "[2023-01-26T17-42-09] Training Step: 316/2370 1.78, \tbatch_size: 6 \tLoss: 0.0752\n",
      "[2023-01-26T17-42-09] Training Step: 317/2370 1.79, \tbatch_size: 6 \tLoss: 0.0555\n",
      "[2023-01-26T17-42-10] Training Step: 318/2370 1.80, \tbatch_size: 6 \tLoss: 0.1097\n",
      "[2023-01-26T17-42-10] Training Step: 319/2370 1.81, \tbatch_size: 6 \tLoss: 0.0810\n",
      "[2023-01-26T17-42-10] Training Step: 320/2370 1.82, \tbatch_size: 6 \tLoss: 0.0809\n",
      "[2023-01-26T17-42-11] Training Step: 321/2370 1.83, \tbatch_size: 6 \tLoss: 0.0765\n",
      "[2023-01-26T17-42-11] Training Step: 322/2370 1.84, \tbatch_size: 6 \tLoss: 0.1199\n",
      "[2023-01-26T17-42-12] Training Step: 323/2370 1.85, \tbatch_size: 6 \tLoss: 0.1020\n",
      "[2023-01-26T17-42-12] Training Step: 324/2370 1.86, \tbatch_size: 6 \tLoss: 0.0770\n",
      "[2023-01-26T17-42-13] Training Step: 325/2370 1.87, \tbatch_size: 6 \tLoss: 0.0987\n",
      "[2023-01-26T17-42-13] Training Step: 326/2370 1.88, \tbatch_size: 6 \tLoss: 0.0946\n",
      "[2023-01-26T17-42-14] Training Step: 327/2370 1.89, \tbatch_size: 6 \tLoss: 0.0607\n",
      "[2023-01-26T17-42-14] Training Step: 328/2370 1.90, \tbatch_size: 6 \tLoss: 0.0520\n",
      "[2023-01-26T17-42-14] Training Step: 329/2370 1.91, \tbatch_size: 6 \tLoss: 0.0965\n",
      "[2023-01-26T17-42-15] Training Step: 330/2370 1.92, \tbatch_size: 6 \tLoss: 0.0765\n",
      "[2023-01-26T17-42-15] Training Step: 331/2370 1.93, \tbatch_size: 6 \tLoss: 0.0692\n",
      "[2023-01-26T17-42-16] Training Step: 332/2370 1.94, \tbatch_size: 6 \tLoss: 0.1358\n",
      "[2023-01-26T17-42-16] Training Step: 333/2370 1.95, \tbatch_size: 6 \tLoss: 0.0784\n",
      "[2023-01-26T17-42-16] Training Step: 334/2370 1.96, \tbatch_size: 6 \tLoss: 0.0682\n",
      "[2023-01-26T17-42-17] Training Step: 335/2370 1.97, \tbatch_size: 6 \tLoss: 0.0951\n",
      "[2023-01-26T17-42-17] Training Step: 336/2370 1.98, \tbatch_size: 6 \tLoss: 0.0739\n",
      "[2023-01-26T17-42-18] Training Step: 337/2370 1.99, \tbatch_size: 6 \tLoss: 0.0546\n",
      "[2023-01-26T17-42-18] Training Step: 338/2370 1.100, \tbatch_size: 6 \tLoss: 0.1411\n",
      "[2023-01-26T17-42-18] Training Step: 339/2370 1.101, \tbatch_size: 6 \tLoss: 0.0492\n",
      "[2023-01-26T17-42-19] Training Step: 340/2370 1.102, \tbatch_size: 6 \tLoss: 0.0655\n",
      "[2023-01-26T17-42-19] Training Step: 341/2370 1.103, \tbatch_size: 6 \tLoss: 0.0407\n",
      "[2023-01-26T17-42-20] Training Step: 342/2370 1.104, \tbatch_size: 6 \tLoss: 0.0701\n",
      "[2023-01-26T17-42-20] Training Step: 343/2370 1.105, \tbatch_size: 6 \tLoss: 0.0709\n",
      "[2023-01-26T17-42-21] Training Step: 344/2370 1.106, \tbatch_size: 6 \tLoss: 0.0825\n",
      "[2023-01-26T17-42-21] Training Step: 345/2370 1.107, \tbatch_size: 6 \tLoss: 0.0650\n",
      "[2023-01-26T17-42-22] Training Step: 346/2370 1.108, \tbatch_size: 6 \tLoss: 0.0893\n",
      "[2023-01-26T17-42-22] Training Step: 347/2370 1.109, \tbatch_size: 6 \tLoss: 0.0608\n",
      "[2023-01-26T17-42-22] Training Step: 348/2370 1.110, \tbatch_size: 6 \tLoss: 0.0705\n",
      "[2023-01-26T17-42-23] Training Step: 349/2370 1.111, \tbatch_size: 6 \tLoss: 0.0831\n",
      "[2023-01-26T17-42-23] Training Step: 350/2370 1.112, \tbatch_size: 6 \tLoss: 0.1026\n",
      "[2023-01-26T17-42-24] Training Step: 351/2370 1.113, \tbatch_size: 6 \tLoss: 0.0615\n",
      "[2023-01-26T17-42-24] Training Step: 352/2370 1.114, \tbatch_size: 6 \tLoss: 0.0783\n",
      "[2023-01-26T17-42-24] Training Step: 353/2370 1.115, \tbatch_size: 6 \tLoss: 0.0765\n",
      "[2023-01-26T17-42-25] Training Step: 354/2370 1.116, \tbatch_size: 6 \tLoss: 0.0891\n",
      "[2023-01-26T17-42-25] Training Step: 355/2370 1.117, \tbatch_size: 6 \tLoss: 0.0448\n",
      "[2023-01-26T17-42-25] Training Step: 356/2370 1.118, \tbatch_size: 6 \tLoss: 0.1368\n",
      "[2023-01-26T17-42-26] Training Step: 357/2370 1.119, \tbatch_size: 6 \tLoss: 0.0467\n",
      "[2023-01-26T17-42-26] Training Step: 358/2370 1.120, \tbatch_size: 6 \tLoss: 0.0700\n",
      "[2023-01-26T17-42-27] Training Step: 359/2370 1.121, \tbatch_size: 6 \tLoss: 0.0866\n",
      "[2023-01-26T17-42-28] Training Step: 360/2370 1.122, \tbatch_size: 6 \tLoss: 0.0683\n",
      "[2023-01-26T17-42-28] Training Step: 361/2370 1.123, \tbatch_size: 6 \tLoss: 0.0711\n",
      "[2023-01-26T17-42-28] Training Step: 362/2370 1.124, \tbatch_size: 6 \tLoss: 0.0824\n",
      "[2023-01-26T17-42-29] Training Step: 363/2370 1.125, \tbatch_size: 6 \tLoss: 0.1071\n",
      "[2023-01-26T17-42-29] Training Step: 364/2370 1.126, \tbatch_size: 6 \tLoss: 0.0724\n",
      "[2023-01-26T17-42-30] Training Step: 365/2370 1.127, \tbatch_size: 6 \tLoss: 0.1138\n",
      "[2023-01-26T17-42-30] Training Step: 366/2370 1.128, \tbatch_size: 6 \tLoss: 0.0671\n",
      "[2023-01-26T17-42-30] Training Step: 367/2370 1.129, \tbatch_size: 6 \tLoss: 0.1010\n",
      "[2023-01-26T17-42-31] Training Step: 368/2370 1.130, \tbatch_size: 6 \tLoss: 0.1215\n",
      "[2023-01-26T17-42-31] Training Step: 369/2370 1.131, \tbatch_size: 6 \tLoss: 0.0861\n",
      "[2023-01-26T17-42-32] Training Step: 370/2370 1.132, \tbatch_size: 6 \tLoss: 0.1340\n",
      "[2023-01-26T17-42-32] Training Step: 371/2370 1.133, \tbatch_size: 6 \tLoss: 0.0770\n",
      "[2023-01-26T17-42-32] Training Step: 372/2370 1.134, \tbatch_size: 6 \tLoss: 0.0772\n",
      "[2023-01-26T17-42-33] Training Step: 373/2370 1.135, \tbatch_size: 6 \tLoss: 0.0677\n",
      "[2023-01-26T17-42-33] Training Step: 374/2370 1.136, \tbatch_size: 6 \tLoss: 0.0624\n",
      "[2023-01-26T17-42-33] Training Step: 375/2370 1.137, \tbatch_size: 6 \tLoss: 0.0710\n",
      "[2023-01-26T17-42-34] Training Step: 376/2370 1.138, \tbatch_size: 6 \tLoss: 0.0723\n",
      "[2023-01-26T17-42-35] Training Step: 377/2370 1.139, \tbatch_size: 6 \tLoss: 0.0821\n",
      "[2023-01-26T17-42-35] Training Step: 378/2370 1.140, \tbatch_size: 6 \tLoss: 0.0925\n",
      "[2023-01-26T17-42-36] Training Step: 379/2370 1.141, \tbatch_size: 6 \tLoss: 0.0580\n",
      "[2023-01-26T17-42-36] Training Step: 380/2370 1.142, \tbatch_size: 6 \tLoss: 0.0698\n",
      "[2023-01-26T17-42-36] Training Step: 381/2370 1.143, \tbatch_size: 6 \tLoss: 0.0689\n",
      "[2023-01-26T17-42-37] Training Step: 382/2370 1.144, \tbatch_size: 6 \tLoss: 0.0851\n",
      "[2023-01-26T17-42-37] Training Step: 383/2370 1.145, \tbatch_size: 6 \tLoss: 0.0596\n",
      "[2023-01-26T17-42-38] Training Step: 384/2370 1.146, \tbatch_size: 6 \tLoss: 0.0723\n",
      "[2023-01-26T17-42-38] Training Step: 385/2370 1.147, \tbatch_size: 6 \tLoss: 0.0956\n",
      "[2023-01-26T17-42-38] Training Step: 386/2370 1.148, \tbatch_size: 6 \tLoss: 0.0866\n",
      "[2023-01-26T17-42-39] Training Step: 387/2370 1.149, \tbatch_size: 6 \tLoss: 0.0583\n",
      "[2023-01-26T17-42-39] Training Step: 388/2370 1.150, \tbatch_size: 6 \tLoss: 0.0714\n",
      "[2023-01-26T17-42-39] Training Step: 389/2370 1.151, \tbatch_size: 6 \tLoss: 0.1110\n",
      "[2023-01-26T17-42-40] Training Step: 390/2370 1.152, \tbatch_size: 6 \tLoss: 0.0499\n",
      "[2023-01-26T17-42-40] Training Step: 391/2370 1.153, \tbatch_size: 6 \tLoss: 0.1221\n",
      "[2023-01-26T17-42-41] Training Step: 392/2370 1.154, \tbatch_size: 6 \tLoss: 0.0581\n",
      "[2023-01-26T17-42-41] Training Step: 393/2370 1.155, \tbatch_size: 6 \tLoss: 0.1445\n",
      "[2023-01-26T17-42-42] Training Step: 394/2370 1.156, \tbatch_size: 6 \tLoss: 0.0512\n",
      "[2023-01-26T17-42-42] Training Step: 395/2370 1.157, \tbatch_size: 6 \tLoss: 0.1078\n",
      "[2023-01-26T17-42-43] Training Step: 396/2370 1.158, \tbatch_size: 6 \tLoss: 0.0564\n",
      "[2023-01-26T17-42-43] Training Step: 397/2370 1.159, \tbatch_size: 6 \tLoss: 0.0670\n",
      "[2023-01-26T17-42-44] Training Step: 398/2370 1.160, \tbatch_size: 6 \tLoss: 0.1760\n",
      "[2023-01-26T17-42-44] Training Step: 399/2370 1.161, \tbatch_size: 6 \tLoss: 0.0991\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_340059/3496743859.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     69\u001B[0m         \u001B[0mwriter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_histogram\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'GradientsTraining/AllParams'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_gradient\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'vec'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mglobal_step\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlogstep\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbins\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m50\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwalltime\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_bins\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mgrad\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_gradient\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'named params'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"cpu\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdetach\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 71\u001B[0;31m             \u001B[0mwriter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_histogram\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'NamedGradientsTraining/{name}'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mglobal_step\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlogstep\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbins\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m50\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwalltime\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_bins\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     72\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     73\u001B[0m     \u001B[0;31m#%%% intermediate evaluation of validation set\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/treecurrent2/lib/python3.8/site-packages/tensorboardX/writer.py\u001B[0m in \u001B[0;36madd_histogram\u001B[0;34m(self, tag, values, global_step, bins, walltime, max_bins)\u001B[0m\n\u001B[1;32m    561\u001B[0m             \u001B[0mbins\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdefault_bins\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    562\u001B[0m         self._get_file_writer().add_summary(\n\u001B[0;32m--> 563\u001B[0;31m             histogram(tag, values, bins, max_bins=max_bins), global_step, walltime)\n\u001B[0m\u001B[1;32m    564\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_comet_logger\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlog_histogram\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtag\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mglobal_step\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    565\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/treecurrent2/lib/python3.8/site-packages/tensorboardX/summary.py\u001B[0m in \u001B[0;36mhistogram\u001B[0;34m(name, values, bins, max_bins)\u001B[0m\n\u001B[1;32m    207\u001B[0m     \u001B[0mname\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_clean_tag\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    208\u001B[0m     \u001B[0mvalues\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmake_np\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 209\u001B[0;31m     \u001B[0mhist\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmake_histogram\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbins\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_bins\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    210\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mSummary\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mSummary\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mValue\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtag\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhisto\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhist\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    211\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/treecurrent2/lib/python3.8/site-packages/tensorboardX/summary.py\u001B[0m in \u001B[0;36mmake_histogram\u001B[0;34m(values, bins, max_bins)\u001B[0m\n\u001B[1;32m    216\u001B[0m         \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'The input has no element.'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    217\u001B[0m     \u001B[0mvalues\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalues\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 218\u001B[0;31m     \u001B[0mcounts\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlimits\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhistogram\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbins\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbins\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    219\u001B[0m     \u001B[0mnum_bins\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcounts\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    220\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mmax_bins\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mnum_bins\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0mmax_bins\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<__array_function__ internals>\u001B[0m in \u001B[0;36mhistogram\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/treecurrent2/lib/python3.8/site-packages/numpy/lib/histograms.py\u001B[0m in \u001B[0;36mhistogram\u001B[0;34m(a, bins, range, normed, weights, density)\u001B[0m\n\u001B[1;32m    791\u001B[0m     \u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweights\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_ravel_and_check_weights\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweights\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    792\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 793\u001B[0;31m     \u001B[0mbin_edges\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0muniform_bins\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_get_bin_edges\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbins\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweights\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    794\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    795\u001B[0m     \u001B[0;31m# Histogram is an integer or a float array depending on the weights.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/treecurrent2/lib/python3.8/site-packages/numpy/lib/histograms.py\u001B[0m in \u001B[0;36m_get_bin_edges\u001B[0;34m(a, bins, range, weights)\u001B[0m\n\u001B[1;32m    444\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    445\u001B[0m         \u001B[0;31m# bin edges must be computed\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 446\u001B[0;31m         bin_edges = np.linspace(\n\u001B[0m\u001B[1;32m    447\u001B[0m             \u001B[0mfirst_edge\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlast_edge\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_equal_bins\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    448\u001B[0m             endpoint=True, dtype=bin_type)\n",
      "\u001B[0;32m<__array_function__ internals>\u001B[0m in \u001B[0;36mlinspace\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/treecurrent2/lib/python3.8/site-packages/numpy/core/function_base.py\u001B[0m in \u001B[0;36mlinspace\u001B[0;34m(start, stop, num, endpoint, retstep, dtype, axis)\u001B[0m\n\u001B[1;32m    149\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    150\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0m_mult_inplace\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 151\u001B[0;31m                 \u001B[0my\u001B[0m \u001B[0;34m*=\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    152\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    153\u001B[0m                 \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "print('Start training...')\n",
    "tic = time.time()\n",
    "device = config[\"device\"]\n",
    "logstep = -1+logstep_\n",
    "for epoch in range(config[\"n_epochs\"]-epoch_):\n",
    "    epoch = epoch+epoch_\n",
    "    for step, (x, y, mask) in enumerate(dataloader_train):\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        mask = mask.to(device)\n",
    "        \n",
    "        #%%% clean cache of GPU\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        #%%% compute logstep\n",
    "        logstep = logstep+1\n",
    "\n",
    "        #%%% zero gradients\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # get prediction\n",
    "        out, _ = model(x)\n",
    "        pred = out[0][:, -1, ...].squeeze()\n",
    "\n",
    "        #%%% compute and rescale loss\n",
    "        loss = loss_function(pred, y, mask)\n",
    "\n",
    "        #%%% compute metric\n",
    "        if type(metric)==list:\n",
    "            train_acc = [metric_(pred, y, mask).cpu().detach() for metric_ in metric]\n",
    "        else:\n",
    "            train_acc = metric(pred, y, mask).cpu().detach()\n",
    "        \n",
    "\n",
    "        #%%% compute gradient\n",
    "        loss.backward()\n",
    "\n",
    "        #%%% update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        #%%% printing stuff\n",
    "        print(\n",
    "            \"[{}] Training Step: {:d}/{:d} {:d}.{:d}, \\tbatch_size: {} \\tLoss: {:.4f}\".format(\n",
    "                dt.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\"),\n",
    "                logstep+1,\n",
    "                len(dataloader_train)*config[\"n_epochs\"],\n",
    "                epoch,\n",
    "                step,\n",
    "                config[\"batch_size\"],\n",
    "                loss.mean(),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        #%%% write to tensorboard\n",
    "        #%%%% log loss\n",
    "        writer.add_scalar(f'LossTraining/{type(loss_function).__name__}', loss, global_step=logstep)\n",
    "        \n",
    "        #%%%% log metric\n",
    "        if type(metric)==list:\n",
    "            writer.add_scalars('AccuracyTraining',{metric_.__name__:train_acc_ for metric_,train_acc_ in zip(metric,train_acc)},global_step=logstep)\n",
    "        else:\n",
    "            writer.add_scalar('AccuracyTraining', train_acc, global_step=logstep)\n",
    "        \n",
    "        #%%%% gradients\n",
    "        writer.add_histogram('GradientsTraining/AllParams', model.get_gradient(mode='vec',index=None), global_step=logstep, bins=50, walltime=None, max_bins=100)\n",
    "        for name,grad in model.get_gradient(mode='named params',device=\"cpu\",detach=True):\n",
    "            writer.add_histogram(f'NamedGradientsTraining/{name}', grad, global_step=logstep, bins=50, walltime=None, max_bins=100)\n",
    "        \n",
    "    #%%% intermediate evaluation of validation set\n",
    "    if config[\"eval_freq\"] and (epoch+1)%config[\"eval_freq\"]==0:\n",
    "        print()\n",
    "        model.eval()\n",
    "        loss_val = []\n",
    "        acc_val = []\n",
    "        weights_val = []\n",
    "        \n",
    "        n_plot_validation = 8\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            fig, axis = plt.subplots(nrows=n_plot_validation*2, ncols=dataloader_validation.batch_size,\n",
    "                                     figsize=(3*dataloader_validation.batch_size,2*3*n_plot_validation))\n",
    "            fig.suptitle('Validation Data %i'%logstep)\n",
    "            for step_validation, (x_validation, y_validation, mask_validation) in enumerate(dataloader_validation):\n",
    "                \n",
    "                x_validation = x_validation.to(device)\n",
    "                y_validation = y_validation.to(device)\n",
    "                mask_validation = mask_validation.to(device)\n",
    "                    \n",
    "\n",
    "                #%%%% clean cache of GPU\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                out_validation, _ = model.forward(x_validation)\n",
    "                pred_validation = out_validation[0][:, -1, ...].squeeze()\n",
    "\n",
    "\n",
    "                #%%% compute loss\n",
    "                loss_validation = loss_function(pred_validation, y_validation, mask_validation)\n",
    "                \n",
    "                #%%%% compute metric\n",
    "                if type(metric)==list:\n",
    "                    validation_acc = [metric_(pred_validation, y_validation, mask_validation).cpu().detach() for metric_ in metric]\n",
    "                else:\n",
    "                    validation_acc = metric(pred_validation, y_validation, mask_validation).cpu().detach()\n",
    "                #%%%% printing stuff\n",
    "                print(\n",
    "                    \"[{}] Validation Step: {:d}/{:d}, \\tbatch_size: {} \\tLoss: {:.4f}\".format(\n",
    "                        dt.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\"),\n",
    "                        step_validation+1,\n",
    "                        len(dataloader_validation),\n",
    "                        dataloader_validation.batch_size,\n",
    "                        loss_validation.mean(),\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "                #%%%% visualize the predictions from the validation set and compare it to the reference for several\n",
    "                #%%%% timestamps to visually see how the predictions get closer to the reference over time\n",
    "                if step_validation < n_plot_validation:\n",
    "                    axis[step_validation*2][0].set_ylabel(\"Prediction\")\n",
    "                    axis[step_validation*2+1][0].set_ylabel(\"Reference\")\n",
    "                    for i in range(dataloader_validation.batch_size):\n",
    "                        \n",
    "                        axis[step_validation*2][i].imshow(pred_validation[i].squeeze().cpu().detach(),\n",
    "                                                          vmin=-1,vmax=1,cmap=\"Greens\")\n",
    "                        axis[step_validation*2][i].set_xticks([])\n",
    "                        axis[step_validation*2][i].set_yticks([])\n",
    "\n",
    "                        axis[step_validation*2+1][i].imshow(y_validation[i].squeeze().cpu().detach().numpy(),\n",
    "                                                            vmin=-1,vmax=1,cmap=\"Greens\")\n",
    "                        axis[step_validation*2+1][i].set_xticks([])\n",
    "                        axis[step_validation*2+1][i].set_yticks([])\n",
    "                    \n",
    "                #%%%% collect loss and accuracy\n",
    "                loss_val.append(loss_validation.cpu().detach().numpy())\n",
    "                acc_val.append(validation_acc)\n",
    "                weights_val.append(torch.count_nonzero(mask_validation).cpu().detach().numpy())\n",
    "\n",
    "            #%%%% total loss and accuracy\n",
    "            total = np.sum([np.sum(weight_) for weight_ in weights_val])\n",
    "            loss_val_total = np.sum([weight_/total*loss_ for weight_,loss_ in zip(weights_val,loss_val)])\n",
    "            if type(metric)==list:\n",
    "                acc_val_total = [np.sum([weight_/total*acc_[i] for weight_,acc_ in zip(weights_val,acc_val)]) for i in range(len(metric))]\n",
    "            else:\n",
    "                acc_val_total = np.sum([weight_/total*acc_ for weight_,acc_ in zip(weights_val,acc_val)])\n",
    "            \n",
    "            # print total values\n",
    "            print(\n",
    "                \"[{}] Validation: \\tTotal Loss: {:.4f}\".format(\n",
    "                    dt.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\"),\n",
    "                    loss_val_total,\n",
    "                    {metric_.__name__:validation_acc_ for metric_,validation_acc_ in zip(metric,acc_val_total)} if type(metric)==list else acc_val_total\n",
    "                )\n",
    "            )\n",
    "\n",
    "            #%%%% write to tensorboard\n",
    "            #%%%%% log loss\n",
    "            writer.add_scalar(f'LossValidation/{type(loss_function).__name__}', loss_val_total, global_step=logstep)\n",
    "\n",
    "            #%%%%% log metric\n",
    "            if type(metric)==list:\n",
    "                writer.add_scalars('AccuracyValidation',{metric_.__name__:validation_acc_ for metric_,validation_acc_ in zip(metric,acc_val_total)},global_step=logstep)\n",
    "            else:\n",
    "                writer.add_scalar('AccuracyValidation', acc_val_total, global_step=logstep)\n",
    "            \n",
    "            #%%%%% log figure\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(fname=os.path.join(config[\"dir_imgs_validation\"],\"PredictionValidation_%i\"%logstep), dpi=\"figure\")\n",
    "            writer.add_figure(tag=\"PredictionValidation\", figure=fig, global_step=logstep, close=True, walltime=None)\n",
    "\n",
    "        model.train()\n",
    "        print()\n",
    "        #%%% checkpoint for best validation loss\n",
    "        if config[\"checkpoint_bestloss\"] and bestloss>loss_val_total:\n",
    "            print(\"New best validation loss! Storing checkpoint and model!\")\n",
    "            model.save_checkpoint(\n",
    "                savename = os.path.join(config[\"dir_checkpoints\"],'checkpoint_bestloss.tar'),\n",
    "                epoch = epoch,\n",
    "                logstep = logstep,\n",
    "                optimizer_state_dict = optimizer.state_dict(),\n",
    "                loss = loss,\n",
    "                bestloss = loss_val_total\n",
    "            )\n",
    "            model.save(savename=os.path.join(config[\"dir_results\"],config[\"model_savename_inference_bestloss\"]),mode='inference')\n",
    "            model.save(savename=os.path.join(config[\"dir_results\"],config[\"model_savename_bestloss\"]),mode='entirely')\n",
    "            bestloss = loss_val_total\n",
    "\n",
    "    #%%% checkpoint\n",
    "    if config[\"checkpoint_freq\"] and (epoch+1)%config[\"checkpoint_freq\"]==0:\n",
    "        model.save_checkpoint(\n",
    "            savename = os.path.join(config[\"dir_checkpoints\"],f'checkpoint_{logstep}_{epoch}_{step}.tar'),\n",
    "            epoch = epoch,\n",
    "            logstep = logstep,\n",
    "            optimizer_state_dict = optimizer.state_dict(),\n",
    "            loss = loss,\n",
    "            bestloss = loss_val_total\n",
    "        )\n",
    "        \n",
    "print(f\"Training took {time.time() - tic} s for {config['n_epochs']-epoch_} epochs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09450db2",
   "metadata": {
    "pycharm": {
     "name": "#%% save model\n"
    }
   },
   "outputs": [],
   "source": [
    "print('saving final checkpoint!')\n",
    "model.save_checkpoint(savename=os.path.join(config[\"dir_checkpoints\"],f'checkpoint_{logstep}_{epoch}_{step}.tar'), epoch=epoch, logstep=logstep, optimizer_state_dict=optimizer.state_dict(), loss=loss)\n",
    "print('saving inference model')\n",
    "model.save(savename=os.path.join(config[\"dir_results\"],config[\"model_savename_inference\"]),mode='inference')\n",
    "print('saving entire model')\n",
    "model.save(savename=os.path.join(config[\"dir_results\"],config[\"model_savename\"]),mode='entirely')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
