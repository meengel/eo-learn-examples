{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f84f86f",
   "metadata": {},
   "source": [
    "# Testing\n",
    "In this notebook, we will test the model of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c981409",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### Michael Engel ### 2022-04-25 ### main.ipynb ###\n",
    "### adapted by Niklas Eisl, Colin Moldenhauer, 2022/23 ###\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import platform\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from eolearn.core import FeatureType\n",
    "\n",
    "from libs.ConfigME import Config, importME, get_most_recent_config\n",
    "from libs.QuantileScaler_eolearn import QuantileScaler_eolearn_tdigest\n",
    "from libs.Dataset_eolearn import Dataset_eolearn\n",
    "from libs import AugmentME\n",
    "\n",
    "print(\"Working Directory:\",os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2484bf33",
   "metadata": {},
   "source": [
    "# Config\n",
    "First, we load our configuration file which provides all information we need throughout the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6449852a",
   "metadata": {
    "pycharm": {
     "name": "#%% load configuration file\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "config_name = get_most_recent_config(\".\", pattern=\"config_.*[.]dill\", mode=\"m\")\n",
    "config = Config.LOAD(config_name)\n",
    "print(\"loaded config:\", config_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacabf47",
   "metadata": {},
   "source": [
    "# Batch Size\n",
    "As we deal with high dimensional data and several time stamps, it is important to choose a reasonably low batch size. A too small batch size on the other hand will result in highly stochastic gradients. We have found a batch size of 6 to work well for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd709875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen batch_size: 6\n"
     ]
    }
   ],
   "source": [
    "print(f'Chosen batch_size: {config[\"batch_size\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeeeccb",
   "metadata": {},
   "source": [
    "# Quantile Scaling\n",
    "As discussed in the second notebook, we want to apply quantile scaling to our data.\n",
    "We load the scaler that we have already defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36e5a8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler = QuantileScaler_eolearn_tdigest.LOAD(os.path.join(config[\"dir_results\"],config[\"savename_scaler\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35f34c",
   "metadata": {},
   "source": [
    "# Dataloader\n",
    "First, we need to get the paths for all samples within our training and validation datasets, respectively. More specifically, we create a list of paths that will then be passed to the `Dataset_eolearn` class which prepares the data in a way such that the dataloader can load it into the batches that we use during training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8ba8cac",
   "metadata": {
    "pycharm": {
     "name": "#%% training samples\n"
    }
   },
   "outputs": [],
   "source": [
    "paths_test = [os.path.join(config[\"dir_test\"], file).replace(\"\\\\\",\"/\") for file in os.listdir(config[\"dir_test\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa4709a",
   "metadata": {},
   "source": [
    "Now, we are ready to define our datasets using the `Dataset_eolearn` class!\n",
    "\n",
    "Remember that PyTorch asks for the shape `[batch_size x channels x timestamps x height x width]`.\n",
    "The `Quantile\n",
    "_eolearn_tdigest` handles this by setting `transform=Torchify(1)`.\n",
    "For the reference and the mask, we use the `Torchify` class as provided from the `Dataset_eolearn` package, too.\n",
    "\n",
    "So befor we initialize the Datasets, let's briefly have a look at the `Torchify` class. In a nutshell, this class handles our final transforms such that Pytorch can use the data for training. This includes rearranging of dimensions and removing of `NaN` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def torchify(array):\n",
    "    return np.moveaxis(array, -1, 0)\n",
    "\n",
    "def nan_to_value(array, value=0):\n",
    "    nan_loc = np.isnan(array)\n",
    "    array[nan_loc] = value\n",
    "    return array\n",
    "\n",
    "\n",
    "class Torchify():\n",
    "    def __init__(self,squeeze=False, nanvalue=0):\n",
    "        self.squeeze = squeeze\n",
    "        self.nanvalue = nanvalue\n",
    "    def __call__(self,array):\n",
    "        array_ = torchify(array)\n",
    "        array_ = nan_to_value(array_, value=self.nanvalue)\n",
    "\n",
    "        if self.squeeze==True:\n",
    "            return array_.squeeze()\n",
    "        elif type(self.squeeze)==int:\n",
    "            return array_.squeeze(self.squeeze)\n",
    "        else:\n",
    "            return array_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% torchify\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0328d8fe",
   "metadata": {
    "pycharm": {
     "name": "#%% training dataset\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_test = Dataset_eolearn(\n",
    "    paths = paths_test,\n",
    "    feature_data = (FeatureType.DATA, \"data\"),\n",
    "    feature_reference = (FeatureType.DATA, \"reference\"),\n",
    "    feature_mask = (FeatureType.MASK, \"mask_reference\"),\n",
    "\n",
    "    transform_data = Scaler,\n",
    "    transform_reference = Torchify(squeeze=1, nanvalue=0),\n",
    "    transform_mask = Torchify(squeeze=1, nanvalue=0),\n",
    "    \n",
    "    return_idx = False,\n",
    "    return_path = False,\n",
    "\n",
    "    torchdevice = None,\n",
    "    torchtype_data = torch.FloatTensor,\n",
    "    torchtype_reference = torch.FloatTensor,\n",
    "    torchtype_mask = torch.FloatTensor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cec2844",
   "metadata": {},
   "source": [
    "Let's test our datasets! \n",
    "\n",
    "As we can see, each batch of our input data `x` consists of \n",
    "- 6 samples, \n",
    "- 6 channels (where the channels correpond to the downloaded bands `B02`, `B03`, `B04`, `B08`, `B8A` and `B11`),\n",
    "- 8 consecutive time stamps\n",
    "- and a spatial resolution of `256x256` for each patch.\n",
    "\n",
    "The corresponding reference `y` collapses the channel and timestamp dimesions and we end up with\n",
    "- 6 samples\n",
    "- and a spatial resolution of `256x256` for each patch, where all values are in the range `[-1,1]` to represent the NDVI index.\n",
    "\n",
    "The mask has the same shape as the reference `y` with binary values to filter with the`no-data mask` and `cloud mask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30790772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Shape: torch.Size([6, 6, 8, 256, 256])\n",
      "Test Reference Shape: torch.Size([6, 256, 256])\n",
      "test Mask Shape: torch.Size([6, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "sample_train = dataset_test[:config[\"batch_size\"]]\n",
    "print('Test Data Shape:', sample_train[0].shape)\n",
    "print('Test Reference Shape:', sample_train[1].shape)\n",
    "print('test Mask Shape:', sample_train[2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb87976a",
   "metadata": {},
   "source": [
    "Let's define our dataloader for each dataset.\n",
    "We will double our `batch_size` for testing as no gradient calculation is needed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b04b2a82",
   "metadata": {
    "pycharm": {
     "name": "#%% training dataloader\n"
    }
   },
   "outputs": [],
   "source": [
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    dataset = dataset_test,\n",
    "    batch_size = config[\"batch_size\"],\n",
    "    shuffle = True,\n",
    "    sampler = None,\n",
    "    batch_sampler = None,\n",
    "    num_workers = 0 if platform.system()==\"Windows\" else config[\"threads\"],\n",
    "    collate_fn = None,\n",
    "    pin_memory = False,\n",
    "    drop_last = True,\n",
    "    timeout = 0,\n",
    "    worker_init_fn = None,\n",
    "    multiprocessing_context = None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabeb0f4",
   "metadata": {},
   "source": [
    "# Model\n",
    "Now, it's time to initialise our model.\n",
    "We will do that using `importME` since we want to keep flexibility with regard to the model architecture used. That way, changes can easily be made in the Configuaration Notebook without having to modify this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e5049ee",
   "metadata": {
    "pycharm": {
     "name": "#%% import model\n"
    }
   },
   "outputs": [],
   "source": [
    "module_model = importME(config[\"module_model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f32710b",
   "metadata": {
    "pycharm": {
     "name": "#%% initialise model\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "ConvLSTM(\n  (cell_list): ModuleList(\n    (0): ConvLSTMCell(\n      (conv): Conv2d(26, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (1): ConvLSTMCell(\n      (conv): Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (2): ConvLSTMCell(\n      (conv): Conv2d(21, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = module_model(**config[\"kwargs_model\"])\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training\n",
    "Before we can start training our model, we have to define a loss function.\n",
    "We will keep it as flexible as the model itself and use `importME`.\n",
    "\n",
    "As we deal with a regression task we use a classical `MSE Loss` function. However, it is important to also take the mask into account that we get for each batch in addition to `x` and `y`. The loss fuction can be modified such that no loss is computed for those pixels where the mask has a value of 1.\n",
    "\n",
    "We have implemented such a custom loss called `MSELossMasked` which can be found in `libs\\loss.py`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61741159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorporating utils!\n"
     ]
    }
   ],
   "source": [
    "loss_function = importME(config[\"module_loss\"])(**config[\"kwargs_loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8230bafc",
   "metadata": {},
   "source": [
    "No optimization without an optimizer! \n",
    "Due to corresponding device issues, we have to send our model to the device before we define our optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c19daf7",
   "metadata": {
    "pycharm": {
     "name": "#%% send model to device to avoid device errors\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "ConvLSTM(\n  (cell_list): ModuleList(\n    (0): ConvLSTMCell(\n      (conv): Conv2d(26, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (1): ConvLSTMCell(\n      (conv): Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n    (2): ConvLSTMCell(\n      (conv): Conv2d(21, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(config[\"device\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1071d8d1",
   "metadata": {},
   "source": [
    "Now, we can define our optimizer with the parameters already been sent to our chosen device!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81601344",
   "metadata": {},
   "source": [
    "# Testing\n",
    "To assess the performance of our model, we load some metrics. Similar to the loss function, we use the `Masked MSE Loss` function as our first metric and a `Squared Variance Error` to also take the variance into account. The implementatin of both metrics can be found in `libs\\metrics.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bd3dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = importME(config[\"module_metric\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Of course, we would like to track the proceeding of our testing procedure.\n",
    "Hence, we define a tensorboard [SummaryWriter](https://tensorboardx.readthedocs.io/en/latest/tensorboard.html#tensorboardX.SummaryWriter)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "writer = SummaryWriter(config[\"dir_tensorboard\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "c41f3d85",
   "metadata": {},
   "source": [
    "Anyway, we would like to make our experiment reproducible.\n",
    "Thus, we set the seeds such that all random number generation and shuffling is done in a deterministic manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62823fe7",
   "metadata": {
    "pycharm": {
     "name": "#%% reproducibility\n"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(config[\"seed\"])\n",
    "torch.manual_seed(config[\"seed\"])\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "After the long training, we would like to test our model on the chosen test tiles.\n",
    "\n",
    "However, we load the model providing the best validation loss.\n",
    "For that, we will use the `BaseClass` from AugmentME."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loadME_torch: start loading of the entire model!\n",
      "loadME_torch: loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AugmentME.BaseClass(mode=\"torch\")\n",
    "model.load(os.path.join(config[\"dir_results\"],config[\"model_savename_bestloss\"]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since the testing script is rather similar to the validation part of our training procedure, we do not discuss this here."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Start testing...')\n",
    "model.eval()\n",
    "losss_test = []\n",
    "accs_test = []\n",
    "weights_test = []\n",
    "with torch.no_grad():\n",
    "    for step_test, (x_test, y_test, mask_test) in enumerate(dataloader_test):\n",
    "        #%%%% clean cache of GPU\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        #%%%% forward pass\n",
    "        out, _ = model(x_test)\n",
    "        pred_test = out[0][:, -1, ...].squeeze()\n",
    "\n",
    "        #%%%% compute loss\n",
    "        loss_test = loss_function(pred_test, y_test, mask_test)\n",
    "\n",
    "        if type(metric)==list:\n",
    "            test_acc = [metric_(pred_test, y_test, mask_test).cpu().detach() for metric_ in metric]\n",
    "        else:\n",
    "            test_acc = metric(pred_test, y_test, mask_test).cpu().detach()\n",
    "\n",
    "        #%%%% printing stuff\n",
    "        print(\n",
    "            \"[{}] Test Step: {:d}/{:d}, \\tbatch_size: {} \\tLoss: {:.4f} \\tAcc: {}\".format(\n",
    "                dt.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\"),\n",
    "                step_test+1,\n",
    "                len(dataloader_test),\n",
    "                dataloader_test.batch_size,\n",
    "                loss_test.mean(),\n",
    "                {metric_.__name__:test_acc_ for metric_,test_acc_ in zip(metric,test_acc)} if type(metric)==list else test_acc\n",
    "            )\n",
    "        )\n",
    "\n",
    "        #%%%% collect loss and accuracy\n",
    "        losss_test.append(loss_test.cpu().detach().numpy())\n",
    "        accs_test.append(test_acc)\n",
    "        weights_test.append(torch.count_nonzero(mask_test).cpu().detach().numpy())\n",
    "\n",
    "        #%% plot\n",
    "        fig, axis = plt.subplots(nrows=2, ncols=dataloader_test.batch_size,\n",
    "                                     figsize=(3*dataloader_test.batch_size,2*3))\n",
    "\n",
    "        axis[0][0].set_ylabel(\"Prediction\")\n",
    "        axis[1][0].set_ylabel(\"Reference\")\n",
    "        for i in range(dataloader_test.batch_size):\n",
    "\n",
    "            axis[0][i].imshow(pred_test[i].squeeze().cpu().detach(), vmin=-1,vmax=1,cmap=\"Greens\")\n",
    "            axis[0][i].set_xticks([])\n",
    "            axis[0][i].set_yticks([])\n",
    "\n",
    "            axis[1][i].imshow(y_test[i].squeeze().cpu().detach().numpy(), vmin=-1,vmax=1,cmap=\"Greens\")\n",
    "            axis[1][i].set_xticks([])\n",
    "            axis[1][i].set_yticks([])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.savefig(fname=os.path.join(config[\"dir_imgs_test\"], \"Test%i\" % step_test), dpi=\"figure\")\n",
    "        writer.add_figure(tag=\"PredictionTest\", figure=fig, global_step=step_test, close=True, walltime=None)\n",
    "\n",
    "    #%%%% total loss and accuracy\n",
    "    total = np.sum([np.sum(weight_) for weight_ in weights_test])\n",
    "    loss_test_total = np.sum([weight_/total*loss_ for weight_,loss_ in zip(weights_test,losss_test)])\n",
    "    if type(metric)==list:\n",
    "        acc_test_total = [np.sum([weight_/total*acc_[i] for weight_,acc_ in zip(weights_test,accs_test)]) for i in range(len(metric))]\n",
    "    else:\n",
    "        acc_test_total = np.sum([weight_/total*acc_ for weight_,acc_ in zip(weights_test,accs_test)])\n",
    "\n",
    "    # print total values\n",
    "    print(\n",
    "        \"[{}] Test: \\tTotal Loss: {:.4f} \\tTotal Acc: {}\".format(\n",
    "            dt.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\"),\n",
    "            loss_test_total,\n",
    "            {metric_.__name__:test_acc_ for metric_,test_acc_ in zip(metric,acc_test_total)} if type(metric)==list else acc_test_total\n",
    "        )\n",
    "    )\n",
    "\n",
    "    #%%% write to tensorboard\n",
    "    #%%%% log loss\n",
    "    writer.add_scalar(f'LossTest/{type(loss_function).__name__}', loss_test_total, global_step=step_test)\n",
    "\n",
    "    #%%%% log metric\n",
    "    if type(metric)==list:\n",
    "        writer.add_scalars('AccuracyTest',{metric_.__name__:test_acc_ for metric_,test_acc_ in zip(metric,acc_test_total)}, global_step=step_test)\n",
    "    else:\n",
    "        writer.add_scalar('AccuracyTest', acc_test_total, global_step=step_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% testing loop\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
