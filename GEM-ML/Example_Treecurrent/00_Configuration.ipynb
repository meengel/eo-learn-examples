{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b2212b4",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "Here, we define the configuration of our segmentation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64be303e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorporating libs!\n"
     ]
    }
   ],
   "source": [
    "### Michael Engel ### 2022-04-25 ### main.ipynb ###\n",
    "### adapted by Niklas Eisl, Colin Moldenhauer, 2022/23 ###\n",
    "import torch.cuda\n",
    "\n",
    "from libs.ConfigME import Config\n",
    "import os\n",
    "import platform\n",
    "import datetime as dt\n",
    "from sentinelhub import SHConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0c8e6e",
   "metadata": {},
   "source": [
    "Now, we can initialize the configuration file with a proper name and identifiers for storing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf5ac1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    name = 'Treecurrent', # name of the project\n",
    "    savename = None, # basic name to store stuff\n",
    "    savename_config = None # name of configuration file\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372cde6d",
   "metadata": {},
   "source": [
    "Our pipeline is defined by 3 notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4de23486",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.file_DataAcquisition = \"01_DataAcquisition.ipynb\"\n",
    "config.file_DataNormalisation = \"02_DataNormalisation.ipynb\"\n",
    "config.file_TrainingValidationTesting = \"03_TrainingValidation.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bea354",
   "metadata": {},
   "source": [
    "Let's define the directories we are working with, i.e. in which directories to store our `EOPatches` and results.\n",
    "By that, we ensure that everything is only defined once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba34709c",
   "metadata": {
    "pycharm": {
     "name": "#%% folder where data necessary for running the notebook is stored such as the geojson of the AOI\n"
    }
   },
   "outputs": [],
   "source": [
    "config.dir_input = os.path.join(os.getcwd(),\"inputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "780b10bf",
   "metadata": {
    "pycharm": {
     "name": "#%% results\n"
    }
   },
   "outputs": [],
   "source": [
    "config.basedir = os.getcwd()\n",
    "config.dir_results = os.path.join(config[\"basedir\"], \"results\", config[\"savename\"])\n",
    "config.dir_checkpoints = os.path.join(config[\"dir_results\"], \"checkpoints\")\n",
    "config.dir_tensorboard = os.path.join(config[\"dir_results\"], \"tensorboard\")\n",
    "config.dir_imgs = os.path.join(config[\"dir_results\"], \"imgs\")\n",
    "config.dir_imgs_validation = os.path.join(config[\"dir_imgs\"], \"PredictionValidation\")\n",
    "config.dir_imgs_test = os.path.join(config[\"dir_imgs\"], \"PredictionTest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aca36dc",
   "metadata": {
    "pycharm": {
     "name": "#%% locations for collected data\n"
    }
   },
   "outputs": [],
   "source": [
    "config.dir_data = os.path.join(config[\"basedir\"], \"data\")\n",
    "config.dir_train = os.path.join(config[\"dir_data\"], \"train\")\n",
    "config.dir_val = os.path.join(config[\"dir_data\"], \"val\")\n",
    "config.dir_test = os.path.join(config[\"dir_data\"], \"test\")\n",
    "\n",
    "config.dir_cache = os.path.join(os.getcwd(),\"cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c67bd0",
   "metadata": {},
   "source": [
    "Let's load our **credentials** for Sentinel Hub from storage. Make sure you have saved your credentials beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c5e1d7a",
   "metadata": {
    "pycharm": {
     "name": "#%% Sentinel Hub credentials\n"
    }
   },
   "outputs": [],
   "source": [
    "config.SHconfig = SHConfig()\n",
    "if not config[\"SHconfig\"].sh_client_id or not config[\"SHconfig\"].sh_client_secret:\n",
    "    print(\"Warning! To use Process API, please provide the credentials (OAuth client ID and client secret).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30fb52f",
   "metadata": {},
   "source": [
    "others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "750ce31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.AOI = os.path.join(config[\"dir_input\"], \"bavaria_south.json\")\n",
    "config.split_percentages = [.7, .1, .2]       # train, val, test percentages of patches\n",
    "config.split_direction = \"v\"                # split the AOI from west (train) to east (test)\n",
    "config.patchpixelwidth = 256\n",
    "\n",
    "config.maxcc = 1            # maximum cloud coverage for training samples\n",
    "config.maxcc_ref = 0.3      # maximum cloud coverage for reference samples\n",
    "config.resolution = 10      # pixel ground resolution\n",
    "\n",
    "config.feature_name = \"data\"                                # feature name for data\n",
    "config.bands = [\"B02\", \"B03\", \"B04\", \"B08\", \"B8A\", \"B11\"]   # required bands for SentinelHub\n",
    "\n",
    "config.time_difference = dt.timedelta(weeks=2)              # minimum time difference between training samples of time series\n",
    "config.time_difference_mosaic = dt.timedelta(days=1)        # mosaicking time difference\n",
    "config.time_diff_ref = dt.timedelta(days=2)                 # minimum time difference between references (choose low for good coverage over the year)\n",
    "config.time_interval = (\"2021-01-01\", \"2022-01-01\")         # time interval to pick reference timestamps\n",
    "config.num_observations = 8                                 # time series length (excluding reference)\n",
    "\n",
    "config.threads = 1 if platform.system()==\"Windows\" else 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f3280",
   "metadata": {},
   "source": [
    "general ML parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acc8683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.n_epochs = 10\n",
    "config.batch_size = 6\n",
    "config.checkpoint_bestloss = True\n",
    "config.checkpoint_freq = 2\n",
    "config.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "config.eval_freq = 1\n",
    "config.seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1beeda0",
   "metadata": {},
   "source": [
    "model specific ML parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be9734f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model_savename = config[\"savename\"]\n",
    "config.model_savename_bestloss = config[\"model_savename\"]+\"_bestloss\"\n",
    "config.model_savename_inference = config[\"savename\"]+\"_inference\"\n",
    "config.model_savename_inference_bestloss = config[\"model_savename_inference\"]+\"_bestloss\"\n",
    "config.module_model = \"models.convlstm.ConvLSTM\"\n",
    "config.kwargs_model = {\n",
    "    \"input_dim\": len(config.bands),\n",
    "    \"hidden_dim\": [20, 20, 1],\n",
    "    \"kernel_size\": (3, 3),\n",
    "    \"num_layers\": 3,\n",
    "    \"reorder_dims\": (0, 2, 1, 3, 4), # -> (b, t, c, h, w) dataloader: b c t w h\n",
    "    \"bias\": True,\n",
    "    \"return_all_layers\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00654b1",
   "metadata": {},
   "source": [
    "Here, we will use the [MSELoss](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss).\n",
    "We will not apply reduction since we would like to apply our mask manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69fb9191",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.module_loss = \"utils.loss.MSELossMasked\"\n",
    "config.kwargs_loss = {\n",
    "    \"size_average\": None,\n",
    "    \"reduce\": None,\n",
    "    \"reduction\": \"mean\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad43326",
   "metadata": {},
   "source": [
    "We will use the standard [Adam Optimizer](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "359f5ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.module_optimizer = \"torch.optim.Adam\"\n",
    "config.kwargs_optimizer = {\n",
    "    \"lr\": 0.00007,\n",
    "    \"betas\": (0.9, 0.999),\n",
    "    \"eps\": 1e-08,\n",
    "    \"weight_decay\": 1e-06,\n",
    "    \"amsgrad\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ad9d8a",
   "metadata": {},
   "source": [
    "For evaluation, we need some metrics, for example the MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "456efe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.module_metric = [\"utils.metrics.masked_mse_loss\", \"utils.metrics.squared_variance_error\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687f5655",
   "metadata": {},
   "source": [
    "For the data normalisation, we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daae7323",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.savename_tdigest = config[\"savename\"]+\"_TDigest.npy\" \n",
    "config.savename_scaler = config[\"savename\"]+\"_QuantileScaler.dill\" \n",
    "\n",
    "# quantiles\n",
    "config.scaler_maxquantile = 0.99\n",
    "config.scaler_minquantile = 0.01\n",
    "# special values\n",
    "config.scaler_nanval = [0] * len(config.bands)\n",
    "config.scaler_infval = [0] * len(config.bands)\n",
    "# scale to following interval\n",
    "config.scaler_valmin = 0\n",
    "config.scaler_valmax = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6714ec36",
   "metadata": {},
   "source": [
    "We may not forget to store our configuration file to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6c49f7",
   "metadata": {
    "pycharm": {
     "name": "#%%% check directories\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "config.checkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bc0a3a",
   "metadata": {
    "pycharm": {
     "name": "#%%% check files\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "config.checkfile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426d46e8",
   "metadata": {
    "pycharm": {
     "name": "#%%% check modules\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "config.checkmodule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ee0612f",
   "metadata": {
    "pycharm": {
     "name": "#%%% save config\n"
    }
   },
   "outputs": [],
   "source": [
    "file = config.save()\n",
    "file2 = config.save(os.path.join(config[\"dir_results\"],config[\"savename_config\"])) # saving to results folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b98d008",
   "metadata": {
    "pycharm": {
     "name": "#%% print config\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "config.print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
